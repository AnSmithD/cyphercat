{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import copy \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "sys.path.insert(0, '../Utils')\n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import *  \n",
    "from data_downloaders import *\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "batch_size = 128\n",
    "lr_classification = 0.0001\n",
    "lr_inference = 0.001\n",
    "lr_attack = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define series of transforms to pre process images \n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "num_classes = 10\n",
    "\n",
    "# load training set \n",
    "trainset = torchvision.datasets.CIFAR10('../Datasets/', train=True, transform=transform, download=True)\n",
    "testset = torchvision.datasets.CIFAR10('../Datasets/', train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "total_size = len(trainset)\n",
    "split = int(total_size * 0.8)\n",
    "indices = list(range(total_size))\n",
    "\n",
    "\n",
    "D_idx = indices[:40000]\n",
    "D_A_idx = indices[:20000]\n",
    "D_prime_idx = indices[40000:45000]\n",
    "D_prime_A_idx = indices[45000:]\n",
    "\n",
    "eval_train = indices[20000:30000]\n",
    "#eval_out = #testset\n",
    "\n",
    "D_sampler = SubsetRandomSampler(D_idx)\n",
    "D_A_sampler = SubsetRandomSampler(D_A_idx)\n",
    "D_prime_sampler = SubsetRandomSampler(D_prime_idx)\n",
    "D_prime_A_sampler = SubsetRandomSampler(D_prime_A_idx)\n",
    "eval_train_sampler = SubsetRandomSampler(eval_train)\n",
    "\n",
    "'''\n",
    "train_idx = indices[:split]\n",
    "out_idx = indices[split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "out_sampler = SubsetRandomSampler(out_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "outloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=out_sampler, num_workers=2)\n",
    "'''\n",
    "D_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_sampler, num_workers=1)\n",
    "D_A_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_A_sampler, num_workers=1)\n",
    "D_prime_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_prime_sampler, num_workers=1)\n",
    "D_prime_A_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_prime_A_sampler, num_workers=1)\n",
    "eval_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=eval_train_sampler, num_workers=1)\n",
    "eval_out_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "# load test set \n",
    "#testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# helper function to unnormalize and plot image \n",
    "def imshow(img):\n",
    "    img = np.array(img)\n",
    "    img = img / 2 + 0.5\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "# display sample from dataset \n",
    "imgs,labels = iter(D_loader).next()\n",
    "imshow(torchvision.utils.make_grid(imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_onehot(labels, num_classes=10): \n",
    "    one_hot = torch.eye(num_classes)\n",
    "    return one_hot[labels]\n",
    "\n",
    "\n",
    "class inference_attack(nn.Module): \n",
    "    def __init__(self, n_classes): \n",
    "        super(inference_attack, self).__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.prediction_vector_block = nn.Sequential(\n",
    "            nn.Linear(n_classes, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.label_block = nn.Sequential(\n",
    "            nn.Linear(n_classes, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.common_block = nn.Sequential(\n",
    "            nn.Linear(128, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 1)\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, prediction_vector, one_hot_label): \n",
    "        prediction_block_out = self.prediction_vector_block(prediction_vector)\n",
    "        label_block_out = self.label_block(one_hot_label)\n",
    "        #print(prediction_block_out)\n",
    "        #print(label_block_out)\n",
    "\n",
    "        \n",
    "        out = F.sigmoid(self.common_block(torch.cat((prediction_block_out, label_block_out), dim=1)))\n",
    "        return out\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vgg16 = torchvision.models.vgg16(num_classes=10)\n",
    "# vgg16 fix for cifar10 image size \n",
    "vgg16.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#net = resnet18.to(device)\n",
    "net = vgg16.to(device)\n",
    "\n",
    "\n",
    "net.apply(models.weights_init)\n",
    "\n",
    "undefended_net = copy.deepcopy(net)\n",
    "\n",
    "undefended_loss = nn.CrossEntropyLoss()\n",
    "undefended_optim = optim.Adam(undefended_net.parameters(), lr=lr_classification)\n",
    "\n",
    "class_loss = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "class_optim = optim.Adam(net.parameters(), lr=lr_classification)\n",
    "\n",
    "\n",
    "infer_net = inference_attack(num_classes).to(device)\n",
    "infer_net.apply(models.weights_init)\n",
    "\n",
    "infer_loss = nn.BCELoss()\n",
    "infer_optim = optim.Adam(infer_net.parameters(), lr=lr_inference)\n",
    "\n",
    "\n",
    "attack_net = inference_attack(num_classes).to(device)\n",
    "attack_net.apply(models.weights_init)\n",
    "\n",
    "attack_net2 = copy.deepcopy(attack_net)\n",
    "attack2_loss = nn.BCELoss()\n",
    "attack2_optim = optim.Adam(attack_net2.parameters(), lr=lr_attack)\n",
    "\n",
    "attack_loss = nn.BCELoss()\n",
    "attack_optim = optim.Adam(attack_net.parameters(), lr=lr_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_train(inference_net, classification_net, train_set, out_set, test_set, \n",
    "                      infer_optim, infer_loss, class_optim, class_loss, n_epochs, k, privacy_theta):\n",
    "    losses = []\n",
    "\n",
    "    inference_net.train()\n",
    "    classification_net.train()\n",
    "\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        train_top = np.array([])\n",
    "        out_top = np.array([])\n",
    "        \n",
    "        train_p = np.array([])\n",
    "        out_p = np.array([])\n",
    "        \n",
    "        total_inference = 0\n",
    "        total_correct_inference = 0\n",
    "        \n",
    "        inference_losses = np.array([])\n",
    "        classification_losses = np.array([])\n",
    "        \n",
    "        for k_count in range(k): \n",
    "            # train inference network \n",
    "            train_imgs, train_lbls = iter(train_set).next()\n",
    "            train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "            out_imgs, out_lbls = iter(out_set).next()\n",
    "            out_imgs, out_lbls = out_imgs.to(device), out_lbls.to(device)\n",
    "            \n",
    "            mini_batch_size = train_imgs.shape[0]\n",
    "            \n",
    "            train_lbl = torch.ones(mini_batch_size).to(device)\n",
    "            out_lbl = torch.zeros(mini_batch_size).to(device)\n",
    "            \n",
    "            train_posteriors = F.softmax(classification_net(train_imgs), dim=1)\n",
    "            out_posteriors = F.softmax(classification_net(out_imgs), dim=1)\n",
    "            \n",
    "            '''\n",
    "            t_p = train_posteriors.cpu().detach().numpy().flatten()\n",
    "            o_p = out_posteriors.cpu().detach().numpy().flatten()\n",
    "            \n",
    "            train_p = np.concatenate((train_p, t_p))\n",
    "            out_p = np.concatenate((out_p, o_p))\n",
    "            '''\n",
    "            \n",
    "            train_sort, _ = torch.sort(train_posteriors, descending=True)\n",
    "            out_sort, _ = torch.sort(out_posteriors, descending=True)\n",
    "\n",
    "            t_p = train_sort[:,:4].cpu().detach().numpy().flatten()\n",
    "            o_p = out_sort[:,:4].cpu().detach().numpy().flatten()\n",
    "            \n",
    "            train_p = np.concatenate((train_p, t_p))\n",
    "            out_p = np.concatenate((out_p, o_p))\n",
    "                    \n",
    "            train_top = np.concatenate((train_top, train_sort[:,0].cpu().detach().numpy()))\n",
    "            out_top = np.concatenate((out_top, out_sort[:,0].cpu().detach().numpy()))\n",
    "            \n",
    "            infer_optim.zero_grad()\n",
    "\n",
    "            train_inference = torch.squeeze(inference_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "            out_inference = torch.squeeze(inference_net(out_posteriors, label_to_onehot(out_lbls).to(device)))\n",
    "            \n",
    "            total_inference += 2*mini_batch_size\n",
    "            total_correct_inference += torch.sum(train_inference > 0.5).item() + torch.sum(out_inference < 0.5).item()\n",
    "            \n",
    "            \n",
    "            loss_train = infer_loss(train_inference, train_lbl)\n",
    "            loss_out = infer_loss(out_inference, out_lbl)\n",
    "            \n",
    "            loss = privacy_theta * (loss_train + loss_out) / 2 \n",
    "            loss.backward()\n",
    "            \n",
    "            infer_optim.step()\n",
    "            \n",
    "        # train classifiction network \n",
    "        train_imgs, train_lbls = iter(train_set).next()\n",
    "        train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "        \n",
    "        class_optim.zero_grad()\n",
    "\n",
    "        outputs = classification_net(train_imgs)\n",
    "        train_posteriors = F.softmax(outputs, dim=1)\n",
    "\n",
    "\n",
    "        loss_classification = class_loss(outputs, train_lbls)\n",
    "        train_lbl = torch.ones(mini_batch_size).to(device)\n",
    "        \n",
    "        train_inference = torch.squeeze(inference_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "        loss_infer = infer_loss(train_inference, train_lbl)\n",
    "        loss = loss_classification - privacy_theta * loss_infer\n",
    "        \n",
    "        loss.backward()\n",
    "        class_optim.step()\n",
    "        \n",
    "        '''\n",
    "        correct += (train_predictions>=0.5).sum().item()\n",
    "        correct += (out_predictions<0.5).sum().item()\n",
    "        total += train_predictions.size(0) + out_predictions.size(0)\n",
    "        print(\"[%d/%d][%d/%d] loss = %.2f, accuracy = %.2f\" % (epoch, n_epochs, i, len(shadow_train), loss.item(), 100 * correct / total))\n",
    "        '''        \n",
    "        \n",
    "        if epoch % 20 == 0 and epoch != 0: \n",
    "\n",
    "            \n",
    "            plt.figure()\n",
    "            sns.distplot(train_p,label='maximum train posterior')\n",
    "            sns.distplot(out_p,label='maximum out posterior')\n",
    "            #sns.distplot(train_top,label='maximum train posterior')\n",
    "            #sns.distplot(out_top,label='maximum out posterior')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            inference_accuracy = 100 * (total_correct_inference / total_inference)\n",
    "            classification_accuracy = eval_target_net(classification_net, test_set, classes=classes)\n",
    "            print(\"[%d/%d] Inference accuracy = %.2f%%, Classification accuracy = %.2f%%\" % (epoch, n_epochs, inference_accuracy, classification_accuracy))\n",
    "                  \n",
    "        \n",
    "def train_attacker(attack_net, target_net, attack_train, attack_out, optimizer, criterion, n_epochs):\n",
    "    losses = []\n",
    "\n",
    "    target_net.eval()\n",
    "    attack_net.train()\n",
    "    for epoch in range(n_epochs):\n",
    "       \n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        #train_top = np.array([])\n",
    "        #train_top = []\n",
    "        train_top = np.empty((0,2))\n",
    "        out_top = np.empty((0,2))\n",
    "        for i, ((train_imgs, train_lbls), (out_imgs, out_lbls)) in enumerate(zip(attack_train, attack_out)):\n",
    "\n",
    "            #######out_imgs = torch.randn(out_imgs.shape)\n",
    "            if train_imgs.shape[0] != out_imgs.shape[0]: \n",
    "                continue\n",
    "            mini_batch_size = train_imgs.shape[0]\n",
    "            train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "            out_imgs, out_lbls = out_imgs.to(device), out_lbls.to(device)\n",
    "\n",
    "\n",
    "            train_posteriors = F.softmax(target_net(train_imgs.detach()), dim=1)\n",
    "\n",
    "            out_posteriors = F.softmax(target_net(out_imgs.detach()), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_sort, _ = torch.sort(train_posteriors, descending=True)\n",
    "            train_top_k = train_sort.clone().to(device)\n",
    "\n",
    "            out_sort, _ = torch.sort(out_posteriors, descending=True)\n",
    "            out_top_k = out_sort.clone().to(device)\n",
    "\n",
    "            train_top = np.vstack((train_top,train_top_k[:,:2].cpu().detach().numpy()))\n",
    "            out_top = np.vstack((out_top, out_top_k[:,:2].cpu().detach().numpy()))\n",
    "\n",
    "\n",
    "\n",
    "            train_lbl = torch.ones(mini_batch_size).to(device)\n",
    "            out_lbl = torch.zeros(mini_batch_size).to(device)\n",
    "            \n",
    "            \n",
    "            train_inference = torch.squeeze(attack_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "            out_inference = torch.squeeze(attack_net(out_posteriors, label_to_onehot(out_lbls).to(device)))\n",
    "\n",
    "\n",
    "            \n",
    "            loss_train = criterion(train_inference, train_lbl)\n",
    "            loss_out = criterion(out_inference, out_lbl)\n",
    "            loss = (loss_train + loss_out) / 2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "\n",
    "            correct += (train_inference>=0.5).sum().item()\n",
    "            correct += (out_inference<0.5).sum().item()\n",
    "            total += train_inference.size(0) + out_inference.size(0)\n",
    "\n",
    "\n",
    "            print(\"[%d/%d][%d/%d] loss = %.2f, accuracy = %.2f\" % (epoch, n_epochs, i, len(attack_train), loss.item(), 100 * correct / total))\n",
    "\n",
    "\n",
    "        '''\n",
    "        plt.scatter(out_top.T[0,:], out_top.T[1,:], c='b')\n",
    "        plt.scatter(train_top.T[0,:], train_top.T[1,:], c='r')\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        \n",
    "def eval_attacker(attack_net, target_net, attack_train, attack_out):\n",
    "\n",
    "    target_net.eval()\n",
    "    attack_net.eval()\n",
    "       \n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    #train_top = np.empty((0,2))\n",
    "    #out_top = np.empty((0,2))\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i, ((train_imgs, train_lbls), (out_imgs, out_lbls)) in enumerate(zip(attack_train, attack_out)):\n",
    "\n",
    "\n",
    "        mini_batch_size = train_imgs.shape[0]\n",
    "        train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "        out_imgs, out_lbls = out_imgs.to(device), out_lbls.to(device)\n",
    "\n",
    "\n",
    "        train_posteriors = F.softmax(target_net(train_imgs.detach()), dim=1)\n",
    "\n",
    "        out_posteriors = F.softmax(target_net(out_imgs.detach()), dim=1)\n",
    "        \n",
    "        '''\n",
    "        train_sort, _ = torch.sort(train_posteriors, descending=True)\n",
    "        train_top_k = train_sort.clone().to(device)\n",
    "\n",
    "        out_sort, _ = torch.sort(out_posteriors, descending=True)\n",
    "        out_top_k = out_sort.clone().to(device)\n",
    "\n",
    "        train_top = np.vstack((train_top,train_top_k[:,:2].cpu().detach().numpy()))\n",
    "        out_top = np.vstack((out_top, out_top_k[:,:2].cpu().detach().numpy()))\n",
    "        '''\n",
    "        train_inference = torch.squeeze(attack_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "        out_inference = torch.squeeze(attack_net(out_posteriors, label_to_onehot(out_lbls).to(device)))\n",
    "\n",
    "\n",
    "        true_positives += (train_inference >= 0.5).sum().item()\n",
    "        false_positives += (out_inference >= 0.5).sum().item()\n",
    "        false_negatives += (train_inference < 0.5).sum().item()\n",
    "        \n",
    "        correct += (train_inference>=0.5).sum().item()\n",
    "        correct += (out_inference<0.5).sum().item()\n",
    "        total += train_inference.size(0) + out_inference.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total \n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives != 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives !=0 else 0\n",
    "    print(\"accuracy = %.2f, precision = %.2f, recall = %.2f\" % (accuracy, precision, recall))\n",
    "\n",
    "\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adversarial_train(infer_net, net, D_loader, D_prime_loader, eval_out_loader,\n",
    "                      infer_optim, infer_loss, class_optim, class_loss, n_epochs, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attacker(attack_net, net, D_A_loader, D_prime_A_loader, attack_optim, attack_loss, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(undefended_net, D_loader, eval_out_loader, undefended_optim, undefended_loss, n_epochs=100, classes=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attacker(attack_net2, undefended_net, D_A_loader, D_prime_A_loader, attack2_optim, attack2_loss, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAttack performance on Adversarial Regularization Defense Network: \")\n",
    "eval_attacker(attack_net, net, eval_train_loader, eval_out_loader)\n",
    "\n",
    "print(\"\\nAttack performance on normal network: \")\n",
    "eval_attacker(attack_net2, undefended_net, eval_train_loader, eval_out_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAdversarial Regularization network classification accuracy on training set: \")\n",
    "train_accuracy = eval_target_net(net, D_loader, classes=None)\n",
    "\n",
    "print(\"\\nAdversarial Regularization network classification accuracy on test set: \")\n",
    "test_accuracy = eval_target_net(net, eval_out_loader, classes=None)\n",
    "\n",
    "print(\"\\nNormal network classification accuracy on training set: \")\n",
    "train_accuracy = eval_target_net(undefended_net, D_loader, classes=None)\n",
    "\n",
    "print(\"\\nNormal network classification accuracy on test set: \")\n",
    "test_accuracy = eval_target_net(undefended_net, eval_out_loader, classes=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Attack performance on Adversarial Regularization Defense Network: \n",
    "accuracy = 54.68, precision = 0.53, recall = 0.78\n",
    "\n",
    "Attack performance on normal network: \n",
    "accuracy = 65.97, precision = 0.60, recall = 0.95\n",
    "\n",
    "\n",
    "Adversarial Regularization network classification accuracy on training set: \n",
    "\n",
    "Accuracy = 81.12 %\n",
    "\n",
    "\n",
    "\n",
    "Adversarial Regularization network classification accuracy on test set: \n",
    "\n",
    "Accuracy = 68.42 %\n",
    "\n",
    "\n",
    "\n",
    "Normal network classification accuracy on training set: \n",
    "\n",
    "Accuracy = 98.91 %\n",
    "\n",
    "\n",
    "\n",
    "Normal network classification accuracy on test set: \n",
    "\n",
    "Accuracy = 74.12 %\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
