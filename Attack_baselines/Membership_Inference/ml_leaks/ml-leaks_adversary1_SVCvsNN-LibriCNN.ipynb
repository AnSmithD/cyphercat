{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 (default, Jul  6 2018, 19:12:46) \n",
      "[GCC 5.4.0 20160609]\n",
      "Pytorch: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, '../../../Utils/')\n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import * \n",
    "from SVC_Utils import *\n",
    "\n",
    "#audio\n",
    "import librosa as libr\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "k = 3\n",
    "\n",
    "#changed from ML_Leaks to Michael's CNN\n",
    "target_net_type = models.CNN_classifier\n",
    "shadow_net_type = models.CNN_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LibriSpeech data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising LibriSpeechDataset with minimum length = 3s and subsets = ['train-clean-100']\n",
      "Finished indexing data. 27949 usable files found.\n",
      "Finished splitting data.\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "n_seconds = 3\n",
    "n_epochs = 2#25\n",
    "sampling_rate = 16000\n",
    "number_of_mels =128\n",
    "all_data = ['train-clean-100']\n",
    "lr = 0.001\n",
    "\n",
    "### Speech preprocessing\n",
    "\n",
    "class tensorToMFCC:\n",
    "    def __call__(self, y):\n",
    "#         y = y.numpy()\n",
    "        dims = y.shape\n",
    "        y = libr.feature.melspectrogram(np.reshape(y, (dims[1],)), 16000, n_mels=number_of_mels,\n",
    "                               fmax=8000)\n",
    "        y = libr.feature.mfcc(S = libr.power_to_db(y))\n",
    "        y = torch.from_numpy(y)                           \n",
    "        return y.float()\n",
    "    \n",
    "transform  = tensorToMFCC()\n",
    "\n",
    "### Data set\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, './../../../Utils')\n",
    "from datasets import LibriSpeechDataset\n",
    "from datasets import Libri_preload_and_split\n",
    "\n",
    "\n",
    "\n",
    "path = './../../../Classification_baselines/LibriSpeech/data'\n",
    "\n",
    "splits = [0.4, 0.4, 0.2] #input fraction of data you want partitioned\n",
    "attacking = True\n",
    "\n",
    "if sum(splits) != 1:\n",
    "    print('error: splits do not sum to 1.')\n",
    "\n",
    "#Splits data into 2 sets of speakers for target & shadow network, into above defined train:test splits\n",
    "dfs = Libri_preload_and_split(path,all_data,n_seconds,pad=False,cache=True,splits=splits, attacking = attacking)  \n",
    "\n",
    "#target train & test\n",
    "valid_sequence_train = LibriSpeechDataset(path, df = dfs[0], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_out = LibriSpeechDataset(path, df = dfs[1], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_test = LibriSpeechDataset(path, df = dfs[2], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "#shadow train & test\n",
    "valid_sequence_train_shadow = LibriSpeechDataset(path, df = dfs[3], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_out_shadow = LibriSpeechDataset(path, df = dfs[4], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_test_shadow = LibriSpeechDataset(path, df = dfs[5], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders for data for target model & shadow model \n",
    "target_train_loader = DataLoader(valid_sequence_train,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "target_out_loader = DataLoader(valid_sequence_out,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "target_test_loader = DataLoader(valid_sequence_test,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "shadow_train_loader = DataLoader(valid_sequence_train_shadow,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "shadow_out_loader = DataLoader(valid_sequence_out_shadow,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "shadow_test_loader = DataLoader(valid_sequence_test_shadow,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define series of transforms to pre process images \n",
    "# train_transform = torchvision.transforms.Compose([\n",
    "#     #torchvision.transforms.Pad(2),\n",
    "    \n",
    "\n",
    "#     #torchvision.transforms.RandomRotation(10),\n",
    "#     #torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     #torchvision.transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    \n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#     torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "# ])\n",
    "\n",
    "# test_transform = torchvision.transforms.Compose([\n",
    "#     #torchvision.transforms.Pad(2),\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#     torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "# ])\n",
    "    \n",
    "\n",
    "# classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "# # load training set \n",
    "# cifar10_trainset = torchvision.datasets.CIFAR10('../../../Datasets/', train=True, transform=train_transform, download=True)\n",
    "# cifar10_trainloader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# #for svms\n",
    "# sv_cifar10_trainset = torchvision.datasets.CIFAR10('../../../Datasets/', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "# sv_cifar10_trainloader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# # load test set \n",
    "# cifar10_testset = torchvision.datasets.CIFAR10('../../../Datasets/', train=False, transform=test_transform, download=True)\n",
    "# cifar10_testloader = torch.utils.data.DataLoader(cifar10_testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# sv_cifar10_testset = torchvision.datasets.CIFAR10('../../../Datasets/', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "# sv_cifar10_testloader = torch.utils.data.DataLoader(sv_cifar10_testset, batch_size=cifar10_testset.__len__(), shuffle=True, num_workers=2)\n",
    "\n",
    "# # helper function to unnormalize and plot image \n",
    "# def imshow(img):\n",
    "#     img = np.array(img)\n",
    "#     img = img / 2 + 0.5\n",
    "#     img = np.moveaxis(img, 0, -1)\n",
    "#     plt.imshow(img)\n",
    "    \n",
    "# # display sample from dataset \n",
    "# imgs,labels = iter(cifar10_trainloader).next()\n",
    "# imshow(torchvision.utils.make_grid(imgs))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates two non-overlapping subsets of CIFAR10 to train the shadow and target models. We assume the attacker \n",
    "# # has access to data that is similar to but not the same as the data used to train the target.\n",
    "\n",
    "# total_size = len(cifar10_trainset)\n",
    "# split1 = total_size // 4\n",
    "# split2 = split1*2\n",
    "# split3 = split1*3\n",
    "\n",
    "# indices = list(range(total_size))\n",
    "\n",
    "# shadow_train_idx = indices[:split1]\n",
    "# shadow_out_idx = indices[split1:split2]\n",
    "# target_train_idx = indices[split2:split3]\n",
    "# target_out_idx = indices[split3:]\n",
    "\n",
    "\n",
    "# shadow_train_sampler = SubsetRandomSampler(shadow_train_idx)\n",
    "# shadow_out_sampler = SubsetRandomSampler(shadow_out_idx)\n",
    "# target_train_sampler = SubsetRandomSampler(target_train_idx)\n",
    "# target_out_sampler = SubsetRandomSampler(target_out_idx)\n",
    "\n",
    "# shadow_train_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, sampler=shadow_train_sampler, num_workers=1)\n",
    "# shadow_out_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, sampler=shadow_out_sampler, num_workers=1)\n",
    "\n",
    "# #To fit shadow SVM\n",
    "# sv_shadow_train_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=shadow_train_sampler.__len__(), sampler=shadow_train_sampler, num_workers=1)\n",
    "\n",
    "# #attack_train_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=32, sampler=shadow_train_sampler, num_workers=1)\n",
    "\n",
    "# #attack_out_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=32, sampler=shadow_out_sampler, num_workers=1)\n",
    "# target_train_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, sampler=target_train_sampler, num_workers=1)\n",
    "# target_out_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, sampler=target_out_sampler, num_workers=1)\n",
    "\n",
    "# #for svms\n",
    "# sv_target_train_loader = torch.utils.data.DataLoader(sv_cifar10_trainset, batch_size=batch_size, sampler=target_train_sampler, num_workers=1)\n",
    "# sv_target_out_loader = torch.utils.data.DataLoader(sv_cifar10_trainset, batch_size=batch_size, sampler=target_out_sampler, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize/Train Targets\n",
    "The model being attacked; if network, architecture can differ from that of shadow network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "#Initialize NN\n",
    "\n",
    "# change target to this? \n",
    "#classifier = CNN_classifier(20, 512, valid_sequence_test.num_speakers)\n",
    "\n",
    "in_size = 20\n",
    "n_hidden = 512\n",
    "n_classes = valid_sequence_test.num_speakers\n",
    "print(n_classes)\n",
    "\n",
    "target_net = target_net_type(in_size,n_hidden,n_classes).to(device)\n",
    "target_net.apply(models.weights_init)\n",
    "\n",
    "target_loss = nn.CrossEntropyLoss()\n",
    "target_optim = optim.Adam(target_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2]\n",
      "Training:\n",
      "\n",
      "Accuracy = 72.86 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 47.62 %\n",
      "\n",
      "\n",
      "[1/2]\n",
      "Training:\n",
      "\n",
      "Accuracy = 91.42 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 61.09 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train NN\n",
    "#from ML:\n",
    "# train(classifier, train_loader, test_loader, optimizer, criterion, 50, verbose = False)\n",
    "\n",
    "#blend:\n",
    "train(target_net, target_train_loader, target_test_loader, target_optim, target_loss, n_epochs, verbose = False) #classes = range(valid_sequence_test.num_speakers),\n",
    "\n",
    "\n",
    "#here:\n",
    "# train(target_net, target_train_loader, target_test_loader, target_optim, target_loss, n_epochs)#, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 4\n",
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': 'CNN_voice_classifier',\n",
    "            'state_dict': target_net.state_dict(),\n",
    "            'optimizer' : target_optim.state_dict(),\n",
    "        }, False, filename = 'model_weights/CNN_voice_classifier100_target_'+str(epoch)+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold off on adapting SVM for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initialize SVM\n",
    "\n",
    "# # #The stored baseline SVM was fit using all of CIFAR10 training data. To attack for membership inference, use \n",
    "# # #images not in CIFAR10 training data, or fit new classifiers/run source code with subset of CIFAR10.\n",
    "\n",
    "# # '''\n",
    "# # dir='../../../Classification_baselines/CIFAR10'\n",
    "# # target_gen=load_svm(dir, gen=True)\n",
    "# # target_maxacc=load_svm(dir, gen=False)\n",
    "# # '''\n",
    "\n",
    "# # #Training example targets on loaded CIFAR10 target subset:\n",
    "\n",
    "# gen_svm=make_pipeline(PCA(n_components=180), MinMaxScaler(feature_range=(-1,1)), svm.SVC(C=10, gamma=.1, probability=True))\n",
    "# maxacc_svm=make_pipeline(PCA(n_components=180), MinMaxScaler(feature_range=(-1,1)), svm.SVC(C=1, gamma=.01, probability=True))\n",
    "\n",
    "# # sv_target_fit_loader = torch.utils.data.DataLoader(sv_cifar10_trainset, batch_size=target_train_sampler.__len__(), \n",
    "# #                                                    sampler=target_train_sampler, num_workers=1)\n",
    "\n",
    "\n",
    "# tin, tout=load(target_train_loader)\n",
    "\n",
    "# #Train SVM\n",
    "# gen_svm.fit(tin, tout)\n",
    "# maxacc_svm.fit(tin, tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #evaluate SVM targets\n",
    "\n",
    "# classes = range(n_classes)\n",
    "# inp, outp=load(target_test_loader)\n",
    "\n",
    "# print('SVM A (C=', gen_svm.get_params(deep=True)['svc__C'], ', gamma= ',\n",
    "#       gen_svm.get_params(deep=True)['svc__gamma'], '): ')\n",
    "# class_acc(gen_svm.predict_proba(inp), outp, classes)\n",
    "\n",
    "# print('SVM B (C=', maxacc_svm.get_params(deep=True)['svc__C'], ', gamma= ',\n",
    "#       maxacc_svm.get_params(deep=True)['svc__gamma'], '): ')\n",
    "# class_acc(maxacc_svm.predict_proba(inp), outp, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize/Train Shadow Model\n",
    "Shadow model mimics the target network, emulating the target model's differences in prediction probabilities for samples in and out of its dataset. For this attack, only one shadow model is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "#Initialize models\n",
    "\n",
    "n_classes = valid_sequence_test_shadow.num_speakers\n",
    "print(n_classes)\n",
    "\n",
    "#NN\n",
    "shadow_net = shadow_net_type(in_size,n_hidden,n_classes).to(device)\n",
    "shadow_net.apply(models.weights_init)\n",
    "\n",
    "shadow_loss = nn.CrossEntropyLoss()\n",
    "shadow_optim = optim.Adam(shadow_net.parameters(), lr=lr)\n",
    "\n",
    "#SVM\n",
    "# shadowinputs, shadowtargets=load(sv_shadow_train_loader)\n",
    "# shadow_svm=make_pipeline(PCA(n_components=180), MinMaxScaler(feature_range=(-1,1)), \n",
    "#                          svm.SVC(C=1, gamma=.1, probability=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(shadowinputs))\n",
    "# shadowtargets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2]\n",
      "Training:\n",
      "\n",
      "Accuracy = 70.94 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 41.57 %\n",
      "\n",
      "\n",
      "[1/2]\n",
      "Training:\n",
      "\n",
      "Accuracy = 90.73 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 58.98 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train NN\n",
    "\n",
    "# below commented code is for comparison during debugging\n",
    "# target_net = target_net_type(in_size,n_hidden,n_classes).to(device)\n",
    "# target_net.apply(models.weights_init)\n",
    "\n",
    "# target_loss = nn.CrossEntropyLoss()\n",
    "# target_optim = optim.Adam(target_net.parameters(), lr=lr)\n",
    "\n",
    "# train(target_net, target_train_loader, target_test_loader, target_optim, target_loss, n_epochs, verbose = False) #classes = range(valid_sequence_test.num_speakers),\n",
    "\n",
    "\n",
    "train(shadow_net, shadow_train_loader, shadow_test_loader, shadow_optim, shadow_loss, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train SVM\n",
    "# shadow_svm.fit(shadowinputs, shadowtargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Attack Model\n",
    "A binary classifier to determine membership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates two attack nets for comparison.\n",
    "\n",
    "# attack_net_svm = models.mlleaks_mlp(n_in=k).to(device)\n",
    "# attack_net_svm.apply(models.weights_init)\n",
    "\n",
    "attack_net_nn = models.mlleaks_mlp(n_in=k).to(device)\n",
    "attack_net_nn.apply(models.weights_init)\n",
    "\n",
    "attack_loss = nn.BCEWithLogitsLoss() #this one works\n",
    "# attack_loss = nn.BCELoss() # this one doesn't work \n",
    "# attack_optim_svm= optim.Adam(attack_net_svm.parameters(), lr=lr)\n",
    "attack_optim_nn= optim.Adam(attack_net_nn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trains SVM attack model\n",
    "# train_attacker(attack_net_svm, shadow_svm, shadow_train_loader, shadow_out_loader, attack_optim_svm, attack_loss, n_epochs=2, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4][0/174] loss = 0.65, accuracy = 59.38\n",
      "[0/4][1/174] loss = 0.63, accuracy = 62.50\n",
      "[0/4][2/174] loss = 0.67, accuracy = 63.02\n",
      "[0/4][3/174] loss = 0.61, accuracy = 64.45\n",
      "[0/4][4/174] loss = 0.65, accuracy = 64.06\n",
      "[0/4][5/174] loss = 0.63, accuracy = 64.58\n",
      "[0/4][6/174] loss = 0.61, accuracy = 65.40\n",
      "[0/4][7/174] loss = 0.64, accuracy = 65.43\n",
      "[0/4][8/174] loss = 0.58, accuracy = 65.97\n",
      "[0/4][9/174] loss = 0.66, accuracy = 65.31\n",
      "[0/4][10/174] loss = 0.67, accuracy = 65.06\n",
      "[0/4][11/174] loss = 0.65, accuracy = 64.71\n",
      "[0/4][12/174] loss = 0.70, accuracy = 63.94\n",
      "[0/4][13/174] loss = 0.71, accuracy = 63.06\n",
      "[0/4][14/174] loss = 0.62, accuracy = 63.54\n",
      "[0/4][15/174] loss = 0.66, accuracy = 62.89\n",
      "[0/4][16/174] loss = 0.69, accuracy = 62.32\n",
      "[0/4][17/174] loss = 0.65, accuracy = 62.41\n",
      "[0/4][18/174] loss = 0.66, accuracy = 62.58\n",
      "[0/4][19/174] loss = 0.61, accuracy = 62.97\n",
      "[0/4][20/174] loss = 0.69, accuracy = 62.80\n",
      "[0/4][21/174] loss = 0.65, accuracy = 62.43\n",
      "[0/4][22/174] loss = 0.63, accuracy = 62.50\n",
      "[0/4][23/174] loss = 0.68, accuracy = 62.30\n",
      "[0/4][24/174] loss = 0.67, accuracy = 62.31\n",
      "[0/4][25/174] loss = 0.63, accuracy = 62.38\n",
      "[0/4][26/174] loss = 0.64, accuracy = 62.50\n",
      "[0/4][27/174] loss = 0.67, accuracy = 62.33\n",
      "[0/4][28/174] loss = 0.63, accuracy = 62.28\n",
      "[0/4][29/174] loss = 0.66, accuracy = 62.40\n",
      "[0/4][30/174] loss = 0.62, accuracy = 62.55\n",
      "[0/4][31/174] loss = 0.63, accuracy = 62.70\n",
      "[0/4][32/174] loss = 0.71, accuracy = 62.36\n",
      "[0/4][33/174] loss = 0.62, accuracy = 62.50\n",
      "[0/4][34/174] loss = 0.67, accuracy = 62.37\n",
      "[0/4][35/174] loss = 0.64, accuracy = 62.33\n",
      "[0/4][36/174] loss = 0.65, accuracy = 62.33\n",
      "[0/4][37/174] loss = 0.64, accuracy = 62.34\n",
      "[0/4][38/174] loss = 0.60, accuracy = 62.58\n",
      "[0/4][39/174] loss = 0.65, accuracy = 62.54\n",
      "[0/4][40/174] loss = 0.60, accuracy = 62.73\n",
      "[0/4][41/174] loss = 0.63, accuracy = 62.83\n",
      "[0/4][42/174] loss = 0.60, accuracy = 63.08\n",
      "[0/4][43/174] loss = 0.67, accuracy = 62.96\n",
      "[0/4][44/174] loss = 0.62, accuracy = 63.12\n",
      "[0/4][45/174] loss = 0.65, accuracy = 63.01\n",
      "[0/4][46/174] loss = 0.65, accuracy = 63.00\n",
      "[0/4][47/174] loss = 0.71, accuracy = 62.66\n",
      "[0/4][48/174] loss = 0.68, accuracy = 62.60\n",
      "[0/4][49/174] loss = 0.70, accuracy = 62.56\n",
      "[0/4][50/174] loss = 0.60, accuracy = 62.68\n",
      "[0/4][51/174] loss = 0.67, accuracy = 62.62\n",
      "[0/4][52/174] loss = 0.69, accuracy = 62.50\n",
      "[0/4][53/174] loss = 0.63, accuracy = 62.59\n",
      "[0/4][54/174] loss = 0.65, accuracy = 62.67\n",
      "[0/4][55/174] loss = 0.71, accuracy = 62.47\n",
      "[0/4][56/174] loss = 0.66, accuracy = 62.45\n",
      "[0/4][57/174] loss = 0.58, accuracy = 62.58\n",
      "[0/4][58/174] loss = 0.60, accuracy = 62.63\n",
      "[0/4][59/174] loss = 0.72, accuracy = 62.50\n",
      "[0/4][60/174] loss = 0.63, accuracy = 62.58\n",
      "[0/4][61/174] loss = 0.57, accuracy = 62.83\n",
      "[0/4][62/174] loss = 0.62, accuracy = 62.90\n",
      "[0/4][63/174] loss = 0.65, accuracy = 62.87\n",
      "[0/4][64/174] loss = 0.59, accuracy = 62.98\n",
      "[0/4][65/174] loss = 0.67, accuracy = 62.97\n",
      "[0/4][66/174] loss = 0.64, accuracy = 63.01\n",
      "[0/4][67/174] loss = 0.68, accuracy = 62.94\n",
      "[0/4][68/174] loss = 0.65, accuracy = 62.95\n",
      "[0/4][69/174] loss = 0.61, accuracy = 62.99\n",
      "[0/4][70/174] loss = 0.73, accuracy = 62.81\n",
      "[0/4][71/174] loss = 0.69, accuracy = 62.72\n",
      "[0/4][72/174] loss = 0.65, accuracy = 62.80\n",
      "[0/4][73/174] loss = 0.60, accuracy = 62.88\n",
      "[0/4][74/174] loss = 0.64, accuracy = 62.92\n",
      "[0/4][75/174] loss = 0.60, accuracy = 62.99\n",
      "[0/4][76/174] loss = 0.63, accuracy = 63.03\n",
      "[0/4][77/174] loss = 0.63, accuracy = 63.02\n",
      "[0/4][78/174] loss = 0.63, accuracy = 63.05\n",
      "[0/4][79/174] loss = 0.61, accuracy = 63.14\n",
      "[0/4][80/174] loss = 0.67, accuracy = 63.12\n",
      "[0/4][81/174] loss = 0.64, accuracy = 63.15\n",
      "[0/4][82/174] loss = 0.65, accuracy = 63.10\n",
      "[0/4][83/174] loss = 0.64, accuracy = 63.08\n",
      "[0/4][84/174] loss = 0.60, accuracy = 63.18\n",
      "[0/4][85/174] loss = 0.67, accuracy = 63.15\n",
      "[0/4][86/174] loss = 0.61, accuracy = 63.24\n",
      "[0/4][87/174] loss = 0.67, accuracy = 63.14\n",
      "[0/4][88/174] loss = 0.61, accuracy = 63.20\n",
      "[0/4][89/174] loss = 0.73, accuracy = 63.09\n",
      "[0/4][90/174] loss = 0.65, accuracy = 63.10\n",
      "[0/4][91/174] loss = 0.62, accuracy = 63.18\n",
      "[0/4][92/174] loss = 0.64, accuracy = 63.21\n",
      "[0/4][93/174] loss = 0.61, accuracy = 63.25\n",
      "[0/4][94/174] loss = 0.67, accuracy = 63.21\n",
      "[0/4][95/174] loss = 0.66, accuracy = 63.28\n",
      "[0/4][96/174] loss = 0.64, accuracy = 63.31\n",
      "[0/4][97/174] loss = 0.66, accuracy = 63.30\n",
      "[0/4][98/174] loss = 0.67, accuracy = 63.29\n",
      "[0/4][99/174] loss = 0.63, accuracy = 63.36\n",
      "[0/4][100/174] loss = 0.65, accuracy = 63.38\n",
      "[0/4][101/174] loss = 0.65, accuracy = 63.40\n",
      "[0/4][102/174] loss = 0.71, accuracy = 63.32\n",
      "[0/4][103/174] loss = 0.70, accuracy = 63.24\n",
      "[0/4][104/174] loss = 0.65, accuracy = 63.18\n",
      "[0/4][105/174] loss = 0.63, accuracy = 63.21\n",
      "[0/4][106/174] loss = 0.70, accuracy = 63.20\n",
      "[0/4][107/174] loss = 0.71, accuracy = 63.18\n",
      "[0/4][108/174] loss = 0.68, accuracy = 63.13\n",
      "[0/4][109/174] loss = 0.64, accuracy = 63.10\n",
      "[0/4][110/174] loss = 0.64, accuracy = 63.09\n",
      "[0/4][111/174] loss = 0.63, accuracy = 63.14\n",
      "[0/4][112/174] loss = 0.64, accuracy = 63.18\n",
      "[0/4][113/174] loss = 0.66, accuracy = 63.13\n",
      "[0/4][114/174] loss = 0.66, accuracy = 63.14\n",
      "[0/4][115/174] loss = 0.65, accuracy = 63.11\n",
      "[0/4][116/174] loss = 0.62, accuracy = 63.19\n",
      "[0/4][117/174] loss = 0.60, accuracy = 63.24\n",
      "[0/4][118/174] loss = 0.62, accuracy = 63.27\n",
      "[0/4][119/174] loss = 0.68, accuracy = 63.20\n",
      "[0/4][120/174] loss = 0.65, accuracy = 63.20\n",
      "[0/4][121/174] loss = 0.66, accuracy = 63.17\n",
      "[0/4][122/174] loss = 0.63, accuracy = 63.21\n",
      "[0/4][123/174] loss = 0.66, accuracy = 63.24\n",
      "[0/4][124/174] loss = 0.69, accuracy = 63.14\n",
      "[0/4][125/174] loss = 0.62, accuracy = 63.19\n",
      "[0/4][126/174] loss = 0.70, accuracy = 63.12\n",
      "[0/4][127/174] loss = 0.67, accuracy = 63.09\n",
      "[0/4][128/174] loss = 0.68, accuracy = 63.05\n",
      "[0/4][129/174] loss = 0.66, accuracy = 63.04\n",
      "[0/4][130/174] loss = 0.68, accuracy = 63.01\n",
      "[0/4][131/174] loss = 0.64, accuracy = 62.99\n",
      "[0/4][132/174] loss = 0.64, accuracy = 62.98\n",
      "[0/4][133/174] loss = 0.66, accuracy = 62.98\n",
      "[0/4][134/174] loss = 0.64, accuracy = 62.97\n",
      "[0/4][135/174] loss = 0.69, accuracy = 62.94\n",
      "[0/4][136/174] loss = 0.59, accuracy = 62.99\n",
      "[0/4][137/174] loss = 0.68, accuracy = 63.00\n",
      "[0/4][138/174] loss = 0.64, accuracy = 63.01\n",
      "[0/4][139/174] loss = 0.70, accuracy = 62.97\n",
      "[0/4][140/174] loss = 0.66, accuracy = 62.98\n",
      "[0/4][141/174] loss = 0.65, accuracy = 62.97\n",
      "[0/4][142/174] loss = 0.62, accuracy = 62.99\n",
      "[0/4][143/174] loss = 0.56, accuracy = 63.12\n",
      "[0/4][144/174] loss = 0.64, accuracy = 63.11\n",
      "[0/4][145/174] loss = 0.65, accuracy = 63.12\n",
      "[0/4][146/174] loss = 0.64, accuracy = 63.14\n",
      "[0/4][147/174] loss = 0.65, accuracy = 63.14\n",
      "[0/4][148/174] loss = 0.68, accuracy = 63.09\n",
      "[0/4][149/174] loss = 0.73, accuracy = 63.05\n",
      "[0/4][150/174] loss = 0.65, accuracy = 63.03\n",
      "[0/4][151/174] loss = 0.67, accuracy = 62.97\n",
      "[0/4][152/174] loss = 0.62, accuracy = 63.00\n",
      "[0/4][153/174] loss = 0.60, accuracy = 63.07\n",
      "[0/4][154/174] loss = 0.60, accuracy = 63.11\n",
      "[0/4][155/174] loss = 0.67, accuracy = 63.08\n",
      "[0/4][156/174] loss = 0.70, accuracy = 63.02\n",
      "[0/4][157/174] loss = 0.64, accuracy = 63.02\n",
      "[0/4][158/174] loss = 0.69, accuracy = 63.01\n",
      "[0/4][159/174] loss = 0.66, accuracy = 63.00\n",
      "[0/4][160/174] loss = 0.66, accuracy = 62.99\n",
      "[0/4][161/174] loss = 0.66, accuracy = 62.95\n",
      "[0/4][162/174] loss = 0.68, accuracy = 62.89\n",
      "[0/4][163/174] loss = 0.70, accuracy = 62.85\n",
      "[0/4][164/174] loss = 0.63, accuracy = 62.88\n",
      "[0/4][165/174] loss = 0.60, accuracy = 62.94\n",
      "[0/4][166/174] loss = 0.68, accuracy = 62.91\n",
      "[0/4][167/174] loss = 0.66, accuracy = 62.90\n",
      "[0/4][168/174] loss = 0.67, accuracy = 62.84\n",
      "[0/4][169/174] loss = 0.65, accuracy = 62.84\n",
      "[0/4][170/174] loss = 0.68, accuracy = 62.82\n",
      "[0/4][171/174] loss = 0.65, accuracy = 62.85\n",
      "[0/4][172/174] loss = 0.59, accuracy = 62.86\n",
      "[0/4][173/174] loss = 0.61, accuracy = 62.86\n",
      "[1/4][0/174] loss = 0.68, accuracy = 60.94\n",
      "[1/4][1/174] loss = 0.58, accuracy = 65.62\n",
      "[1/4][2/174] loss = 0.62, accuracy = 64.06\n",
      "[1/4][3/174] loss = 0.66, accuracy = 61.72\n",
      "[1/4][4/174] loss = 0.68, accuracy = 60.94\n",
      "[1/4][5/174] loss = 0.61, accuracy = 62.24\n",
      "[1/4][6/174] loss = 0.69, accuracy = 61.16\n",
      "[1/4][7/174] loss = 0.72, accuracy = 60.35\n",
      "[1/4][8/174] loss = 0.69, accuracy = 59.90\n",
      "[1/4][9/174] loss = 0.62, accuracy = 61.09\n",
      "[1/4][10/174] loss = 0.62, accuracy = 61.51\n",
      "[1/4][11/174] loss = 0.71, accuracy = 61.07\n",
      "[1/4][12/174] loss = 0.57, accuracy = 62.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4][13/174] loss = 0.68, accuracy = 61.50\n",
      "[1/4][14/174] loss = 0.69, accuracy = 61.15\n",
      "[1/4][15/174] loss = 0.59, accuracy = 61.72\n",
      "[1/4][16/174] loss = 0.66, accuracy = 61.21\n",
      "[1/4][17/174] loss = 0.65, accuracy = 61.37\n",
      "[1/4][18/174] loss = 0.65, accuracy = 61.43\n",
      "[1/4][19/174] loss = 0.65, accuracy = 61.56\n",
      "[1/4][20/174] loss = 0.67, accuracy = 61.53\n",
      "[1/4][21/174] loss = 0.69, accuracy = 61.65\n",
      "[1/4][22/174] loss = 0.68, accuracy = 61.41\n",
      "[1/4][23/174] loss = 0.63, accuracy = 61.52\n",
      "[1/4][24/174] loss = 0.66, accuracy = 61.38\n",
      "[1/4][25/174] loss = 0.72, accuracy = 61.06\n",
      "[1/4][26/174] loss = 0.68, accuracy = 60.94\n",
      "[1/4][27/174] loss = 0.61, accuracy = 61.27\n",
      "[1/4][28/174] loss = 0.69, accuracy = 61.21\n",
      "[1/4][29/174] loss = 0.63, accuracy = 61.51\n",
      "[1/4][30/174] loss = 0.64, accuracy = 61.74\n",
      "[1/4][31/174] loss = 0.66, accuracy = 61.82\n",
      "[1/4][32/174] loss = 0.64, accuracy = 61.84\n",
      "[1/4][33/174] loss = 0.62, accuracy = 61.99\n",
      "[1/4][34/174] loss = 0.64, accuracy = 62.05\n",
      "[1/4][35/174] loss = 0.70, accuracy = 61.85\n",
      "[1/4][36/174] loss = 0.64, accuracy = 61.87\n",
      "[1/4][37/174] loss = 0.64, accuracy = 61.97\n",
      "[1/4][38/174] loss = 0.66, accuracy = 61.94\n",
      "[1/4][39/174] loss = 0.64, accuracy = 61.95\n",
      "[1/4][40/174] loss = 0.60, accuracy = 62.16\n",
      "[1/4][41/174] loss = 0.66, accuracy = 62.13\n",
      "[1/4][42/174] loss = 0.71, accuracy = 61.85\n",
      "[1/4][43/174] loss = 0.70, accuracy = 61.72\n",
      "[1/4][44/174] loss = 0.63, accuracy = 61.88\n",
      "[1/4][45/174] loss = 0.62, accuracy = 62.09\n",
      "[1/4][46/174] loss = 0.63, accuracy = 62.03\n",
      "[1/4][47/174] loss = 0.68, accuracy = 61.95\n",
      "[1/4][48/174] loss = 0.63, accuracy = 62.02\n",
      "[1/4][49/174] loss = 0.63, accuracy = 62.19\n",
      "[1/4][50/174] loss = 0.69, accuracy = 62.10\n",
      "[1/4][51/174] loss = 0.65, accuracy = 62.11\n",
      "[1/4][52/174] loss = 0.59, accuracy = 62.32\n",
      "[1/4][53/174] loss = 0.65, accuracy = 62.41\n",
      "[1/4][54/174] loss = 0.61, accuracy = 62.56\n",
      "[1/4][55/174] loss = 0.68, accuracy = 62.56\n",
      "[1/4][56/174] loss = 0.66, accuracy = 62.53\n",
      "[1/4][57/174] loss = 0.67, accuracy = 62.45\n",
      "[1/4][58/174] loss = 0.64, accuracy = 62.42\n",
      "[1/4][59/174] loss = 0.72, accuracy = 62.27\n",
      "[1/4][60/174] loss = 0.60, accuracy = 62.35\n",
      "[1/4][61/174] loss = 0.58, accuracy = 62.50\n",
      "[1/4][62/174] loss = 0.57, accuracy = 62.67\n",
      "[1/4][63/174] loss = 0.63, accuracy = 62.65\n",
      "[1/4][64/174] loss = 0.65, accuracy = 62.60\n",
      "[1/4][65/174] loss = 0.65, accuracy = 62.55\n",
      "[1/4][66/174] loss = 0.66, accuracy = 62.52\n",
      "[1/4][67/174] loss = 0.67, accuracy = 62.55\n",
      "[1/4][68/174] loss = 0.69, accuracy = 62.43\n",
      "[1/4][69/174] loss = 0.62, accuracy = 62.52\n",
      "[1/4][70/174] loss = 0.65, accuracy = 62.48\n",
      "[1/4][71/174] loss = 0.58, accuracy = 62.67\n",
      "[1/4][72/174] loss = 0.67, accuracy = 62.61\n",
      "[1/4][73/174] loss = 0.65, accuracy = 62.52\n",
      "[1/4][74/174] loss = 0.71, accuracy = 62.40\n",
      "[1/4][75/174] loss = 0.60, accuracy = 62.56\n",
      "[1/4][76/174] loss = 0.66, accuracy = 62.52\n",
      "[1/4][77/174] loss = 0.66, accuracy = 62.52\n",
      "[1/4][78/174] loss = 0.70, accuracy = 62.48\n",
      "[1/4][79/174] loss = 0.66, accuracy = 62.46\n",
      "[1/4][80/174] loss = 0.58, accuracy = 62.65\n",
      "[1/4][81/174] loss = 0.65, accuracy = 62.63\n",
      "[1/4][82/174] loss = 0.65, accuracy = 62.65\n",
      "[1/4][83/174] loss = 0.64, accuracy = 62.69\n",
      "[1/4][84/174] loss = 0.67, accuracy = 62.63\n",
      "[1/4][85/174] loss = 0.64, accuracy = 62.65\n",
      "[1/4][86/174] loss = 0.62, accuracy = 62.73\n",
      "[1/4][87/174] loss = 0.65, accuracy = 62.70\n",
      "[1/4][88/174] loss = 0.68, accuracy = 62.64\n",
      "[1/4][89/174] loss = 0.66, accuracy = 62.64\n",
      "[1/4][90/174] loss = 0.62, accuracy = 62.65\n",
      "[1/4][91/174] loss = 0.68, accuracy = 62.62\n",
      "[1/4][92/174] loss = 0.64, accuracy = 62.62\n",
      "[1/4][93/174] loss = 0.65, accuracy = 62.58\n",
      "[1/4][94/174] loss = 0.63, accuracy = 62.60\n",
      "[1/4][95/174] loss = 0.54, accuracy = 62.76\n",
      "[1/4][96/174] loss = 0.68, accuracy = 62.73\n",
      "[1/4][97/174] loss = 0.66, accuracy = 62.66\n",
      "[1/4][98/174] loss = 0.62, accuracy = 62.74\n",
      "[1/4][99/174] loss = 0.67, accuracy = 62.75\n",
      "[1/4][100/174] loss = 0.64, accuracy = 62.75\n",
      "[1/4][101/174] loss = 0.64, accuracy = 62.73\n",
      "[1/4][102/174] loss = 0.65, accuracy = 62.74\n",
      "[1/4][103/174] loss = 0.65, accuracy = 62.71\n",
      "[1/4][104/174] loss = 0.59, accuracy = 62.83\n",
      "[1/4][105/174] loss = 0.69, accuracy = 62.78\n",
      "[1/4][106/174] loss = 0.69, accuracy = 62.75\n",
      "[1/4][107/174] loss = 0.63, accuracy = 62.76\n",
      "[1/4][108/174] loss = 0.61, accuracy = 62.82\n",
      "[1/4][109/174] loss = 0.67, accuracy = 62.83\n",
      "[1/4][110/174] loss = 0.66, accuracy = 62.84\n",
      "[1/4][111/174] loss = 0.58, accuracy = 62.90\n",
      "[1/4][112/174] loss = 0.61, accuracy = 62.96\n",
      "[1/4][113/174] loss = 0.67, accuracy = 62.88\n",
      "[1/4][114/174] loss = 0.66, accuracy = 62.85\n",
      "[1/4][115/174] loss = 0.64, accuracy = 62.89\n",
      "[1/4][116/174] loss = 0.62, accuracy = 62.93\n",
      "[1/4][117/174] loss = 0.65, accuracy = 62.98\n",
      "[1/4][118/174] loss = 0.65, accuracy = 62.97\n",
      "[1/4][119/174] loss = 0.56, accuracy = 63.07\n",
      "[1/4][120/174] loss = 0.65, accuracy = 63.07\n",
      "[1/4][121/174] loss = 0.65, accuracy = 63.05\n",
      "[1/4][122/174] loss = 0.70, accuracy = 63.00\n",
      "[1/4][123/174] loss = 0.65, accuracy = 63.02\n",
      "[1/4][124/174] loss = 0.66, accuracy = 63.00\n",
      "[1/4][125/174] loss = 0.69, accuracy = 62.97\n",
      "[1/4][126/174] loss = 0.67, accuracy = 62.96\n",
      "[1/4][127/174] loss = 0.63, accuracy = 62.99\n",
      "[1/4][128/174] loss = 0.67, accuracy = 62.97\n",
      "[1/4][129/174] loss = 0.67, accuracy = 62.96\n",
      "[1/4][130/174] loss = 0.65, accuracy = 62.95\n",
      "[1/4][131/174] loss = 0.64, accuracy = 62.96\n",
      "[1/4][132/174] loss = 0.64, accuracy = 62.98\n",
      "[1/4][133/174] loss = 0.68, accuracy = 62.95\n",
      "[1/4][134/174] loss = 0.66, accuracy = 62.97\n",
      "[1/4][135/174] loss = 0.67, accuracy = 62.97\n",
      "[1/4][136/174] loss = 0.65, accuracy = 63.01\n",
      "[1/4][137/174] loss = 0.70, accuracy = 62.99\n",
      "[1/4][138/174] loss = 0.65, accuracy = 62.96\n",
      "[1/4][139/174] loss = 0.66, accuracy = 62.96\n",
      "[1/4][140/174] loss = 0.58, accuracy = 63.03\n",
      "[1/4][141/174] loss = 0.71, accuracy = 62.98\n",
      "[1/4][142/174] loss = 0.63, accuracy = 63.02\n",
      "[1/4][143/174] loss = 0.61, accuracy = 63.08\n",
      "[1/4][144/174] loss = 0.66, accuracy = 63.09\n",
      "[1/4][145/174] loss = 0.67, accuracy = 63.07\n",
      "[1/4][146/174] loss = 0.75, accuracy = 62.99\n",
      "[1/4][147/174] loss = 0.66, accuracy = 62.99\n",
      "[1/4][148/174] loss = 0.75, accuracy = 62.88\n",
      "[1/4][149/174] loss = 0.59, accuracy = 62.97\n",
      "[1/4][150/174] loss = 0.62, accuracy = 62.99\n",
      "[1/4][151/174] loss = 0.68, accuracy = 62.92\n",
      "[1/4][152/174] loss = 0.67, accuracy = 62.88\n",
      "[1/4][153/174] loss = 0.62, accuracy = 62.93\n",
      "[1/4][154/174] loss = 0.66, accuracy = 62.94\n",
      "[1/4][155/174] loss = 0.63, accuracy = 62.96\n",
      "[1/4][156/174] loss = 0.61, accuracy = 63.00\n",
      "[1/4][157/174] loss = 0.69, accuracy = 62.95\n",
      "[1/4][158/174] loss = 0.66, accuracy = 62.95\n",
      "[1/4][159/174] loss = 0.61, accuracy = 62.99\n",
      "[1/4][160/174] loss = 0.66, accuracy = 62.99\n",
      "[1/4][161/174] loss = 0.64, accuracy = 62.99\n",
      "[1/4][162/174] loss = 0.63, accuracy = 63.01\n",
      "[1/4][163/174] loss = 0.64, accuracy = 63.00\n",
      "[1/4][164/174] loss = 0.65, accuracy = 63.00\n",
      "[1/4][165/174] loss = 0.67, accuracy = 62.97\n",
      "[1/4][166/174] loss = 0.65, accuracy = 62.97\n",
      "[1/4][167/174] loss = 0.65, accuracy = 62.97\n",
      "[1/4][168/174] loss = 0.65, accuracy = 62.96\n",
      "[1/4][169/174] loss = 0.59, accuracy = 63.03\n",
      "[1/4][170/174] loss = 0.61, accuracy = 63.05\n",
      "[1/4][171/174] loss = 0.62, accuracy = 63.08\n",
      "[1/4][172/174] loss = 0.67, accuracy = 63.08\n",
      "[1/4][173/174] loss = 0.65, accuracy = 63.07\n",
      "[2/4][0/174] loss = 0.64, accuracy = 65.62\n",
      "[2/4][1/174] loss = 0.61, accuracy = 64.06\n",
      "[2/4][2/174] loss = 0.65, accuracy = 63.54\n",
      "[2/4][3/174] loss = 0.69, accuracy = 60.55\n",
      "[2/4][4/174] loss = 0.63, accuracy = 61.56\n",
      "[2/4][5/174] loss = 0.63, accuracy = 61.98\n",
      "[2/4][6/174] loss = 0.65, accuracy = 62.28\n",
      "[2/4][7/174] loss = 0.64, accuracy = 62.70\n",
      "[2/4][8/174] loss = 0.64, accuracy = 62.50\n",
      "[2/4][9/174] loss = 0.58, accuracy = 63.91\n",
      "[2/4][10/174] loss = 0.62, accuracy = 63.92\n",
      "[2/4][11/174] loss = 0.64, accuracy = 63.80\n",
      "[2/4][12/174] loss = 0.68, accuracy = 63.70\n",
      "[2/4][13/174] loss = 0.69, accuracy = 63.06\n",
      "[2/4][14/174] loss = 0.65, accuracy = 63.33\n",
      "[2/4][15/174] loss = 0.62, accuracy = 63.48\n",
      "[2/4][16/174] loss = 0.70, accuracy = 62.87\n",
      "[2/4][17/174] loss = 0.69, accuracy = 62.33\n",
      "[2/4][18/174] loss = 0.64, accuracy = 62.42\n",
      "[2/4][19/174] loss = 0.69, accuracy = 62.19\n",
      "[2/4][20/174] loss = 0.69, accuracy = 61.98\n",
      "[2/4][21/174] loss = 0.72, accuracy = 61.58\n",
      "[2/4][22/174] loss = 0.64, accuracy = 61.55\n",
      "[2/4][23/174] loss = 0.64, accuracy = 61.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/4][24/174] loss = 0.66, accuracy = 61.62\n",
      "[2/4][25/174] loss = 0.71, accuracy = 61.54\n",
      "[2/4][26/174] loss = 0.63, accuracy = 61.63\n",
      "[2/4][27/174] loss = 0.71, accuracy = 61.38\n",
      "[2/4][28/174] loss = 0.67, accuracy = 61.26\n",
      "[2/4][29/174] loss = 0.69, accuracy = 61.15\n",
      "[2/4][30/174] loss = 0.70, accuracy = 60.94\n",
      "[2/4][31/174] loss = 0.63, accuracy = 61.04\n",
      "[2/4][32/174] loss = 0.68, accuracy = 60.98\n",
      "[2/4][33/174] loss = 0.64, accuracy = 61.08\n",
      "[2/4][34/174] loss = 0.63, accuracy = 61.25\n",
      "[2/4][35/174] loss = 0.64, accuracy = 61.28\n",
      "[2/4][36/174] loss = 0.66, accuracy = 61.40\n",
      "[2/4][37/174] loss = 0.65, accuracy = 61.47\n",
      "[2/4][38/174] loss = 0.64, accuracy = 61.62\n",
      "[2/4][39/174] loss = 0.73, accuracy = 61.48\n",
      "[2/4][40/174] loss = 0.66, accuracy = 61.55\n",
      "[2/4][41/174] loss = 0.63, accuracy = 61.68\n",
      "[2/4][42/174] loss = 0.63, accuracy = 61.77\n",
      "[2/4][43/174] loss = 0.64, accuracy = 61.79\n",
      "[2/4][44/174] loss = 0.73, accuracy = 61.46\n",
      "[2/4][45/174] loss = 0.62, accuracy = 61.45\n",
      "[2/4][46/174] loss = 0.62, accuracy = 61.50\n",
      "[2/4][47/174] loss = 0.67, accuracy = 61.46\n",
      "[2/4][48/174] loss = 0.65, accuracy = 61.54\n",
      "[2/4][49/174] loss = 0.66, accuracy = 61.62\n",
      "[2/4][50/174] loss = 0.58, accuracy = 61.95\n",
      "[2/4][51/174] loss = 0.64, accuracy = 62.05\n",
      "[2/4][52/174] loss = 0.65, accuracy = 62.00\n",
      "[2/4][53/174] loss = 0.62, accuracy = 62.09\n",
      "[2/4][54/174] loss = 0.63, accuracy = 62.19\n",
      "[2/4][55/174] loss = 0.67, accuracy = 62.11\n",
      "[2/4][56/174] loss = 0.67, accuracy = 62.14\n",
      "[2/4][57/174] loss = 0.61, accuracy = 62.28\n",
      "[2/4][58/174] loss = 0.67, accuracy = 62.31\n",
      "[2/4][59/174] loss = 0.61, accuracy = 62.47\n",
      "[2/4][60/174] loss = 0.59, accuracy = 62.70\n",
      "[2/4][61/174] loss = 0.61, accuracy = 62.78\n",
      "[2/4][62/174] loss = 0.70, accuracy = 62.62\n",
      "[2/4][63/174] loss = 0.64, accuracy = 62.65\n",
      "[2/4][64/174] loss = 0.63, accuracy = 62.72\n",
      "[2/4][65/174] loss = 0.63, accuracy = 62.74\n",
      "[2/4][66/174] loss = 0.62, accuracy = 62.85\n",
      "[2/4][67/174] loss = 0.61, accuracy = 62.96\n",
      "[2/4][68/174] loss = 0.67, accuracy = 63.00\n",
      "[2/4][69/174] loss = 0.58, accuracy = 63.21\n",
      "[2/4][70/174] loss = 0.62, accuracy = 63.27\n",
      "[2/4][71/174] loss = 0.66, accuracy = 63.19\n",
      "[2/4][72/174] loss = 0.58, accuracy = 63.27\n",
      "[2/4][73/174] loss = 0.67, accuracy = 63.20\n",
      "[2/4][74/174] loss = 0.64, accuracy = 63.23\n",
      "[2/4][75/174] loss = 0.67, accuracy = 63.22\n",
      "[2/4][76/174] loss = 0.64, accuracy = 63.31\n",
      "[2/4][77/174] loss = 0.65, accuracy = 63.30\n",
      "[2/4][78/174] loss = 0.67, accuracy = 63.31\n",
      "[2/4][79/174] loss = 0.70, accuracy = 63.24\n",
      "[2/4][80/174] loss = 0.62, accuracy = 63.29\n",
      "[2/4][81/174] loss = 0.62, accuracy = 63.32\n",
      "[2/4][82/174] loss = 0.64, accuracy = 63.29\n",
      "[2/4][83/174] loss = 0.66, accuracy = 63.30\n",
      "[2/4][84/174] loss = 0.65, accuracy = 63.27\n",
      "[2/4][85/174] loss = 0.70, accuracy = 63.19\n",
      "[2/4][86/174] loss = 0.64, accuracy = 63.25\n",
      "[2/4][87/174] loss = 0.63, accuracy = 63.30\n",
      "[2/4][88/174] loss = 0.67, accuracy = 63.27\n",
      "[2/4][89/174] loss = 0.63, accuracy = 63.32\n",
      "[2/4][90/174] loss = 0.68, accuracy = 63.24\n",
      "[2/4][91/174] loss = 0.71, accuracy = 63.15\n",
      "[2/4][92/174] loss = 0.66, accuracy = 63.12\n",
      "[2/4][93/174] loss = 0.65, accuracy = 63.05\n",
      "[2/4][94/174] loss = 0.63, accuracy = 63.06\n",
      "[2/4][95/174] loss = 0.65, accuracy = 63.04\n",
      "[2/4][96/174] loss = 0.64, accuracy = 63.10\n",
      "[2/4][97/174] loss = 0.68, accuracy = 63.03\n",
      "[2/4][98/174] loss = 0.65, accuracy = 62.97\n",
      "[2/4][99/174] loss = 0.67, accuracy = 62.95\n",
      "[2/4][100/174] loss = 0.64, accuracy = 63.03\n",
      "[2/4][101/174] loss = 0.60, accuracy = 63.07\n",
      "[2/4][102/174] loss = 0.65, accuracy = 63.05\n",
      "[2/4][103/174] loss = 0.67, accuracy = 62.97\n",
      "[2/4][104/174] loss = 0.72, accuracy = 62.89\n",
      "[2/4][105/174] loss = 0.66, accuracy = 62.81\n",
      "[2/4][106/174] loss = 0.61, accuracy = 62.82\n",
      "[2/4][107/174] loss = 0.61, accuracy = 62.86\n",
      "[2/4][108/174] loss = 0.62, accuracy = 62.90\n",
      "[2/4][109/174] loss = 0.66, accuracy = 62.87\n",
      "[2/4][110/174] loss = 0.59, accuracy = 62.95\n",
      "[2/4][111/174] loss = 0.66, accuracy = 62.92\n",
      "[2/4][112/174] loss = 0.64, accuracy = 62.91\n",
      "[2/4][113/174] loss = 0.63, accuracy = 62.97\n",
      "[2/4][114/174] loss = 0.69, accuracy = 62.87\n",
      "[2/4][115/174] loss = 0.72, accuracy = 62.78\n",
      "[2/4][116/174] loss = 0.61, accuracy = 62.86\n",
      "[2/4][117/174] loss = 0.73, accuracy = 62.80\n",
      "[2/4][118/174] loss = 0.61, accuracy = 62.85\n",
      "[2/4][119/174] loss = 0.67, accuracy = 62.85\n",
      "[2/4][120/174] loss = 0.63, accuracy = 62.85\n",
      "[2/4][121/174] loss = 0.60, accuracy = 62.90\n",
      "[2/4][122/174] loss = 0.62, accuracy = 62.94\n",
      "[2/4][123/174] loss = 0.67, accuracy = 62.92\n",
      "[2/4][124/174] loss = 0.67, accuracy = 62.90\n",
      "[2/4][125/174] loss = 0.63, accuracy = 62.92\n",
      "[2/4][126/174] loss = 0.68, accuracy = 62.88\n",
      "[2/4][127/174] loss = 0.65, accuracy = 62.90\n",
      "[2/4][128/174] loss = 0.71, accuracy = 62.80\n",
      "[2/4][129/174] loss = 0.74, accuracy = 62.70\n",
      "[2/4][130/174] loss = 0.61, accuracy = 62.75\n",
      "[2/4][131/174] loss = 0.58, accuracy = 62.83\n",
      "[2/4][132/174] loss = 0.68, accuracy = 62.82\n",
      "[2/4][133/174] loss = 0.63, accuracy = 62.81\n",
      "[2/4][134/174] loss = 0.67, accuracy = 62.81\n",
      "[2/4][135/174] loss = 0.59, accuracy = 62.87\n",
      "[2/4][136/174] loss = 0.68, accuracy = 62.84\n",
      "[2/4][137/174] loss = 0.58, accuracy = 62.93\n",
      "[2/4][138/174] loss = 0.70, accuracy = 62.87\n",
      "[2/4][139/174] loss = 0.66, accuracy = 62.85\n",
      "[2/4][140/174] loss = 0.61, accuracy = 62.90\n",
      "[2/4][141/174] loss = 0.59, accuracy = 62.94\n",
      "[2/4][142/174] loss = 0.65, accuracy = 62.95\n",
      "[2/4][143/174] loss = 0.60, accuracy = 62.98\n",
      "[2/4][144/174] loss = 0.63, accuracy = 62.95\n",
      "[2/4][145/174] loss = 0.64, accuracy = 62.98\n",
      "[2/4][146/174] loss = 0.61, accuracy = 63.03\n",
      "[2/4][147/174] loss = 0.63, accuracy = 63.03\n",
      "[2/4][148/174] loss = 0.69, accuracy = 63.01\n",
      "[2/4][149/174] loss = 0.64, accuracy = 63.04\n",
      "[2/4][150/174] loss = 0.60, accuracy = 63.09\n",
      "[2/4][151/174] loss = 0.69, accuracy = 63.07\n",
      "[2/4][152/174] loss = 0.63, accuracy = 63.06\n",
      "[2/4][153/174] loss = 0.65, accuracy = 63.04\n",
      "[2/4][154/174] loss = 0.62, accuracy = 63.06\n",
      "[2/4][155/174] loss = 0.56, accuracy = 63.16\n",
      "[2/4][156/174] loss = 0.71, accuracy = 63.11\n",
      "[2/4][157/174] loss = 0.70, accuracy = 63.09\n",
      "[2/4][158/174] loss = 0.69, accuracy = 63.06\n",
      "[2/4][159/174] loss = 0.67, accuracy = 63.05\n",
      "[2/4][160/174] loss = 0.62, accuracy = 63.06\n",
      "[2/4][161/174] loss = 0.70, accuracy = 63.01\n",
      "[2/4][162/174] loss = 0.63, accuracy = 63.00\n",
      "[2/4][163/174] loss = 0.65, accuracy = 62.98\n",
      "[2/4][164/174] loss = 0.60, accuracy = 63.03\n",
      "[2/4][165/174] loss = 0.66, accuracy = 62.99\n",
      "[2/4][166/174] loss = 0.60, accuracy = 63.06\n",
      "[2/4][167/174] loss = 0.61, accuracy = 63.11\n",
      "[2/4][168/174] loss = 0.68, accuracy = 63.08\n",
      "[2/4][169/174] loss = 0.67, accuracy = 63.06\n",
      "[2/4][170/174] loss = 0.67, accuracy = 63.05\n",
      "[2/4][171/174] loss = 0.67, accuracy = 63.05\n",
      "[2/4][172/174] loss = 0.63, accuracy = 63.05\n",
      "[2/4][173/174] loss = 0.64, accuracy = 63.07\n",
      "[3/4][0/174] loss = 0.63, accuracy = 65.62\n",
      "[3/4][1/174] loss = 0.67, accuracy = 60.94\n",
      "[3/4][2/174] loss = 0.64, accuracy = 61.46\n",
      "[3/4][3/174] loss = 0.59, accuracy = 63.28\n",
      "[3/4][4/174] loss = 0.65, accuracy = 62.81\n",
      "[3/4][5/174] loss = 0.65, accuracy = 62.24\n",
      "[3/4][6/174] loss = 0.65, accuracy = 61.61\n",
      "[3/4][7/174] loss = 0.62, accuracy = 62.50\n",
      "[3/4][8/174] loss = 0.64, accuracy = 62.33\n",
      "[3/4][9/174] loss = 0.66, accuracy = 62.66\n",
      "[3/4][10/174] loss = 0.63, accuracy = 62.64\n",
      "[3/4][11/174] loss = 0.65, accuracy = 62.63\n",
      "[3/4][12/174] loss = 0.69, accuracy = 62.26\n",
      "[3/4][13/174] loss = 0.70, accuracy = 61.72\n",
      "[3/4][14/174] loss = 0.67, accuracy = 61.56\n",
      "[3/4][15/174] loss = 0.61, accuracy = 62.01\n",
      "[3/4][16/174] loss = 0.67, accuracy = 61.95\n",
      "[3/4][17/174] loss = 0.67, accuracy = 61.89\n",
      "[3/4][18/174] loss = 0.66, accuracy = 61.68\n",
      "[3/4][19/174] loss = 0.65, accuracy = 61.56\n",
      "[3/4][20/174] loss = 0.59, accuracy = 62.13\n",
      "[3/4][21/174] loss = 0.58, accuracy = 62.64\n",
      "[3/4][22/174] loss = 0.60, accuracy = 63.18\n",
      "[3/4][23/174] loss = 0.65, accuracy = 63.15\n",
      "[3/4][24/174] loss = 0.66, accuracy = 63.12\n",
      "[3/4][25/174] loss = 0.62, accuracy = 63.28\n",
      "[3/4][26/174] loss = 0.67, accuracy = 63.25\n",
      "[3/4][27/174] loss = 0.62, accuracy = 63.45\n",
      "[3/4][28/174] loss = 0.58, accuracy = 63.79\n",
      "[3/4][29/174] loss = 0.68, accuracy = 63.54\n",
      "[3/4][30/174] loss = 0.65, accuracy = 63.36\n",
      "[3/4][31/174] loss = 0.65, accuracy = 63.23\n",
      "[3/4][32/174] loss = 0.64, accuracy = 63.35\n",
      "[3/4][33/174] loss = 0.65, accuracy = 63.37\n",
      "[3/4][34/174] loss = 0.67, accuracy = 63.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/4][35/174] loss = 0.61, accuracy = 63.45\n",
      "[3/4][36/174] loss = 0.71, accuracy = 63.26\n",
      "[3/4][37/174] loss = 0.61, accuracy = 63.45\n",
      "[3/4][38/174] loss = 0.67, accuracy = 63.38\n",
      "[3/4][39/174] loss = 0.70, accuracy = 63.36\n",
      "[3/4][40/174] loss = 0.64, accuracy = 63.34\n",
      "[3/4][41/174] loss = 0.67, accuracy = 63.28\n",
      "[3/4][42/174] loss = 0.59, accuracy = 63.52\n",
      "[3/4][43/174] loss = 0.64, accuracy = 63.57\n",
      "[3/4][44/174] loss = 0.64, accuracy = 63.47\n",
      "[3/4][45/174] loss = 0.66, accuracy = 63.49\n",
      "[3/4][46/174] loss = 0.65, accuracy = 63.43\n",
      "[3/4][47/174] loss = 0.67, accuracy = 63.35\n",
      "[3/4][48/174] loss = 0.57, accuracy = 63.55\n",
      "[3/4][49/174] loss = 0.72, accuracy = 63.19\n",
      "[3/4][50/174] loss = 0.65, accuracy = 63.24\n",
      "[3/4][51/174] loss = 0.63, accuracy = 63.22\n",
      "[3/4][52/174] loss = 0.60, accuracy = 63.18\n",
      "[3/4][53/174] loss = 0.67, accuracy = 63.08\n",
      "[3/4][54/174] loss = 0.62, accuracy = 63.12\n",
      "[3/4][55/174] loss = 0.66, accuracy = 63.11\n",
      "[3/4][56/174] loss = 0.68, accuracy = 63.10\n",
      "[3/4][57/174] loss = 0.55, accuracy = 63.39\n",
      "[3/4][58/174] loss = 0.66, accuracy = 63.29\n",
      "[3/4][59/174] loss = 0.69, accuracy = 63.18\n",
      "[3/4][60/174] loss = 0.69, accuracy = 63.09\n",
      "[3/4][61/174] loss = 0.65, accuracy = 63.08\n",
      "[3/4][62/174] loss = 0.66, accuracy = 63.00\n",
      "[3/4][63/174] loss = 0.65, accuracy = 63.01\n",
      "[3/4][64/174] loss = 0.64, accuracy = 63.08\n",
      "[3/4][65/174] loss = 0.61, accuracy = 63.14\n",
      "[3/4][66/174] loss = 0.63, accuracy = 63.20\n",
      "[3/4][67/174] loss = 0.57, accuracy = 63.35\n",
      "[3/4][68/174] loss = 0.62, accuracy = 63.47\n",
      "[3/4][69/174] loss = 0.71, accuracy = 63.37\n",
      "[3/4][70/174] loss = 0.70, accuracy = 63.23\n",
      "[3/4][71/174] loss = 0.61, accuracy = 63.39\n",
      "[3/4][72/174] loss = 0.63, accuracy = 63.46\n",
      "[3/4][73/174] loss = 0.67, accuracy = 63.41\n",
      "[3/4][74/174] loss = 0.62, accuracy = 63.44\n",
      "[3/4][75/174] loss = 0.65, accuracy = 63.38\n",
      "[3/4][76/174] loss = 0.64, accuracy = 63.47\n",
      "[3/4][77/174] loss = 0.67, accuracy = 63.40\n",
      "[3/4][78/174] loss = 0.74, accuracy = 63.27\n",
      "[3/4][79/174] loss = 0.64, accuracy = 63.22\n",
      "[3/4][80/174] loss = 0.69, accuracy = 63.16\n",
      "[3/4][81/174] loss = 0.64, accuracy = 63.13\n",
      "[3/4][82/174] loss = 0.63, accuracy = 63.12\n",
      "[3/4][83/174] loss = 0.67, accuracy = 63.11\n",
      "[3/4][84/174] loss = 0.69, accuracy = 63.03\n",
      "[3/4][85/174] loss = 0.62, accuracy = 63.06\n",
      "[3/4][86/174] loss = 0.62, accuracy = 63.11\n",
      "[3/4][87/174] loss = 0.67, accuracy = 63.09\n",
      "[3/4][88/174] loss = 0.66, accuracy = 63.06\n",
      "[3/4][89/174] loss = 0.63, accuracy = 63.06\n",
      "[3/4][90/174] loss = 0.62, accuracy = 63.08\n",
      "[3/4][91/174] loss = 0.61, accuracy = 63.18\n",
      "[3/4][92/174] loss = 0.68, accuracy = 63.12\n",
      "[3/4][93/174] loss = 0.64, accuracy = 63.13\n",
      "[3/4][94/174] loss = 0.58, accuracy = 63.24\n",
      "[3/4][95/174] loss = 0.64, accuracy = 63.23\n",
      "[3/4][96/174] loss = 0.67, accuracy = 63.21\n",
      "[3/4][97/174] loss = 0.62, accuracy = 63.22\n",
      "[3/4][98/174] loss = 0.59, accuracy = 63.30\n",
      "[3/4][99/174] loss = 0.66, accuracy = 63.28\n",
      "[3/4][100/174] loss = 0.64, accuracy = 63.27\n",
      "[3/4][101/174] loss = 0.69, accuracy = 63.17\n",
      "[3/4][102/174] loss = 0.69, accuracy = 63.11\n",
      "[3/4][103/174] loss = 0.63, accuracy = 63.13\n",
      "[3/4][104/174] loss = 0.63, accuracy = 63.14\n",
      "[3/4][105/174] loss = 0.70, accuracy = 63.10\n",
      "[3/4][106/174] loss = 0.69, accuracy = 63.07\n",
      "[3/4][107/174] loss = 0.61, accuracy = 63.14\n",
      "[3/4][108/174] loss = 0.60, accuracy = 63.19\n",
      "[3/4][109/174] loss = 0.60, accuracy = 63.22\n",
      "[3/4][110/174] loss = 0.68, accuracy = 63.19\n",
      "[3/4][111/174] loss = 0.69, accuracy = 63.13\n",
      "[3/4][112/174] loss = 0.65, accuracy = 63.14\n",
      "[3/4][113/174] loss = 0.58, accuracy = 63.24\n",
      "[3/4][114/174] loss = 0.60, accuracy = 63.34\n",
      "[3/4][115/174] loss = 0.66, accuracy = 63.29\n",
      "[3/4][116/174] loss = 0.64, accuracy = 63.34\n",
      "[3/4][117/174] loss = 0.62, accuracy = 63.32\n",
      "[3/4][118/174] loss = 0.65, accuracy = 63.29\n",
      "[3/4][119/174] loss = 0.62, accuracy = 63.32\n",
      "[3/4][120/174] loss = 0.69, accuracy = 63.29\n",
      "[3/4][121/174] loss = 0.65, accuracy = 63.29\n",
      "[3/4][122/174] loss = 0.69, accuracy = 63.24\n",
      "[3/4][123/174] loss = 0.65, accuracy = 63.21\n",
      "[3/4][124/174] loss = 0.70, accuracy = 63.19\n",
      "[3/4][125/174] loss = 0.64, accuracy = 63.19\n",
      "[3/4][126/174] loss = 0.70, accuracy = 63.12\n",
      "[3/4][127/174] loss = 0.64, accuracy = 63.11\n",
      "[3/4][128/174] loss = 0.64, accuracy = 63.13\n",
      "[3/4][129/174] loss = 0.67, accuracy = 63.12\n",
      "[3/4][130/174] loss = 0.68, accuracy = 63.08\n",
      "[3/4][131/174] loss = 0.64, accuracy = 63.08\n",
      "[3/4][132/174] loss = 0.60, accuracy = 63.13\n",
      "[3/4][133/174] loss = 0.70, accuracy = 63.11\n",
      "[3/4][134/174] loss = 0.71, accuracy = 63.01\n",
      "[3/4][135/174] loss = 0.71, accuracy = 62.93\n",
      "[3/4][136/174] loss = 0.64, accuracy = 62.92\n",
      "[3/4][137/174] loss = 0.68, accuracy = 62.90\n",
      "[3/4][138/174] loss = 0.62, accuracy = 62.90\n",
      "[3/4][139/174] loss = 0.64, accuracy = 62.91\n",
      "[3/4][140/174] loss = 0.69, accuracy = 62.90\n",
      "[3/4][141/174] loss = 0.69, accuracy = 62.85\n",
      "[3/4][142/174] loss = 0.70, accuracy = 62.82\n",
      "[3/4][143/174] loss = 0.62, accuracy = 62.83\n",
      "[3/4][144/174] loss = 0.66, accuracy = 62.83\n",
      "[3/4][145/174] loss = 0.69, accuracy = 62.80\n",
      "[3/4][146/174] loss = 0.67, accuracy = 62.82\n",
      "[3/4][147/174] loss = 0.62, accuracy = 62.81\n",
      "[3/4][148/174] loss = 0.64, accuracy = 62.81\n",
      "[3/4][149/174] loss = 0.67, accuracy = 62.79\n",
      "[3/4][150/174] loss = 0.62, accuracy = 62.82\n",
      "[3/4][151/174] loss = 0.67, accuracy = 62.81\n",
      "[3/4][152/174] loss = 0.65, accuracy = 62.80\n",
      "[3/4][153/174] loss = 0.62, accuracy = 62.86\n",
      "[3/4][154/174] loss = 0.64, accuracy = 62.89\n",
      "[3/4][155/174] loss = 0.58, accuracy = 62.94\n",
      "[3/4][156/174] loss = 0.63, accuracy = 62.96\n",
      "[3/4][157/174] loss = 0.65, accuracy = 62.97\n",
      "[3/4][158/174] loss = 0.62, accuracy = 63.02\n",
      "[3/4][159/174] loss = 0.71, accuracy = 62.98\n",
      "[3/4][160/174] loss = 0.68, accuracy = 62.95\n",
      "[3/4][161/174] loss = 0.65, accuracy = 62.92\n",
      "[3/4][162/174] loss = 0.67, accuracy = 62.88\n",
      "[3/4][163/174] loss = 0.67, accuracy = 62.90\n",
      "[3/4][164/174] loss = 0.56, accuracy = 62.97\n",
      "[3/4][165/174] loss = 0.66, accuracy = 62.98\n",
      "[3/4][166/174] loss = 0.63, accuracy = 63.01\n",
      "[3/4][167/174] loss = 0.72, accuracy = 62.96\n",
      "[3/4][168/174] loss = 0.75, accuracy = 62.88\n",
      "[3/4][169/174] loss = 0.68, accuracy = 62.85\n",
      "[3/4][170/174] loss = 0.61, accuracy = 62.87\n",
      "[3/4][171/174] loss = 0.61, accuracy = 62.95\n",
      "[3/4][172/174] loss = 0.64, accuracy = 62.91\n",
      "[3/4][173/174] loss = 0.57, accuracy = 62.92\n"
     ]
    }
   ],
   "source": [
    "#Trains NN attack model\n",
    "#to do: change epochs to 50\n",
    "train_attacker(attack_net_nn, shadow_net, shadow_train_loader, shadow_out_loader, attack_optim_nn, attack_loss, n_epochs=4, k=k)\n",
    "\n",
    "#original:\n",
    "# train_attacker(attack_net_nn, shadow_net, shadow_train_loader, shadow_out_loader, attack_optim_nn, attack_loss, n_epochs=50, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Attack Nets\n",
    "How well the trained attack models classify a sample as in or out of a target model's training dataset, and how performance is affected by target hyperparameters and which models attack which targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#attack net trained on svm shadow model on svm target, C=10, gamma=.1\n",
    "# eval_attack_net(attack_net_svm, gen_svm, sv_target_train_loader, sv_target_out_loader, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack net trained on svm shadow model on svm target, C=1, gamma=.01\n",
    "# eval_attack_net(attack_net_svm, maxacc_svm, sv_target_train_loader, sv_target_out_loader, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 60.25, precision = 0.59, recall = 0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attack net trained on nn shadow model on nn target\n",
    "eval_attack_net(attack_net_nn, target_net, target_train_loader, target_out_loader, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack net trained on nn shadow model on svm target, C=10, gamma=.1\n",
    "# eval_attack_net(attack_net_nn, gen_svm, sv_target_train_loader, sv_target_out_loader, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
