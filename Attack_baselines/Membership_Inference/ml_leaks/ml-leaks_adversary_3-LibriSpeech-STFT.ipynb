{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Leaks Adversary 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 (default, Jul  6 2018, 19:12:46) \n",
      "[GCC 5.4.0 20160609]\n",
      "Pytorch: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "sys.path.insert(0, '../../../Utils/')\n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import * \n",
    "\n",
    "#audio\n",
    "import librosa as libr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising LibriSpeechDataset with minimum length = 3s and subsets = ['train-clean-100']\n",
      "Finished indexing data. 27949 usable files found.\n",
      "12407\n",
      "3170\n",
      "12372\n",
      "0\n",
      "Finished splitting data.\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "n_seconds = 3\n",
    "sampling_rate = 16000\n",
    "number_of_mels =128\n",
    "all_data = ['train-clean-100']\n",
    "lr = 0.001\n",
    "\n",
    "### Speech preprocessing\n",
    "\n",
    "class tensorToMFCC:\n",
    "    def __call__(self, y):\n",
    "#         y = y.numpy()\n",
    "        dims = y.shape\n",
    "        y = libr.feature.melspectrogram(np.reshape(y, (dims[1],)), 16000, n_mels=number_of_mels,\n",
    "                               fmax=8000)\n",
    "        y = libr.feature.mfcc(S = libr.power_to_db(y))\n",
    "        y = torch.from_numpy(y)                           \n",
    "        return y.float()\n",
    "    \n",
    "    \n",
    "class STFT:\n",
    "    def __call__(self,y):\n",
    "        dims = y.shape\n",
    "        y = np.abs(libr.core.stft(np.reshape(y, (dims[1],))))\n",
    "        y = torch.from_numpy(y).permute(1,0)\n",
    "        return y.float()\n",
    "    \n",
    "    \n",
    "transform  = STFT()\n",
    "\n",
    "### Data set\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, './../../../Utils')\n",
    "from datasets import LibriSpeechDataset\n",
    "from datasets import Libri_preload_and_split\n",
    "\n",
    "path = './../../../Classification_baselines/LibriSpeech/data/'\n",
    "\n",
    "splits = [0.8, 0.2] #input fraction of data you want partitioned. Train, test fraction\n",
    "attacking = 3 #0 for no attack, 1 for attack 1, 3 for attack 3\n",
    "# attacking means data for a target & shadow network.\n",
    "# This will also split \"out data\" from totally different speakers -- data none of the \n",
    "# other networks have seen, for training & testing the attack network. This will be\n",
    "# an equivalent amount of data to the train split as defined about\n",
    "\n",
    "if sum(splits) != 1:\n",
    "    print('error: splits do not sum to 1.')\n",
    "\n",
    "#Splits data into 2 sets of speakers for target & shadow network, into above defined train:test splits\n",
    "dfs = Libri_preload_and_split(path,all_data,n_seconds,pad=False,cache=True,splits=splits, attacking = attacking)  \n",
    "\n",
    "#target train & test\n",
    "valid_sequence_train = LibriSpeechDataset(path, df = dfs[0], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_test = LibriSpeechDataset(path, df = dfs[1], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "#shadow train & test\n",
    "\n",
    "valid_sequence_out = LibriSpeechDataset(path, df = dfs[2], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders for data for target model & shadow model \n",
    "target_train_loader = DataLoader(valid_sequence_train,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "target_out_loader = DataLoader(valid_sequence_out,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "target_test_loader = DataLoader(valid_sequence_test,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Leaks Adversary 3 (Membership Inference Attack) \n",
    "### https://arxiv.org/abs/1806.01246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "# the model being attacked (architecture can be different than shadow)\n",
    "target_net_type = models.STFT_CNN_classifier\n",
    "\n",
    "in_size = 94# 20 forMFCC,  94 for STFT\n",
    "n_hidden = 512\n",
    "n_classes = valid_sequence_test.num_speakers\n",
    "print(n_classes)\n",
    "\n",
    "target_net = target_net_type(in_size,n_hidden,n_classes).to(device)\n",
    "target_net.apply(models.weights_init)\n",
    "\n",
    "#target_net.avgpool = nn.AvgPool2d(2, stride=1)\n",
    "#target_net = models.mlleaks_cnn().to(device)\n",
    "\n",
    "target_loss = nn.CrossEntropyLoss()\n",
    "target_optim = optim.Adam(target_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25]\n",
      "Training:\n",
      "\n",
      "Accuracy = 63.32 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 50.66 %\n",
      "\n",
      "\n",
      "[1/25]\n",
      "Training:\n",
      "\n",
      "Accuracy = 86.24 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 72.93 %\n",
      "\n",
      "\n",
      "[2/25]\n",
      "Training:\n",
      "\n",
      "Accuracy = 92.74 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 79.97 %\n",
      "\n",
      "\n",
      "[3/25]\n",
      "Training:\n",
      "\n",
      "Accuracy = 94.17 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 81.51 %\n",
      "\n",
      "\n",
      "[4/25]\n",
      "Training:\n",
      "\n",
      "Accuracy = 94.60 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 81.64 %\n",
      "\n",
      "\n",
      "[5/25]\n",
      "Training:\n",
      "\n",
      "Accuracy = 96.66 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 85.49 %\n",
      "\n",
      "\n",
      "[6/25]\n",
      "Training:\n"
     ]
    }
   ],
   "source": [
    "train(target_net, target_train_loader, target_test_loader, target_optim, target_loss, n_epochs, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 24\n",
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': 'CNN_voice_classifier',\n",
    "            'state_dict': target_net.state_dict(),\n",
    "            'optimizer' : target_optim.state_dict(),\n",
    "        }, False, filename = 'model_weights/CNN_voice_classifier100STFT_attack3_'+str(epoch)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_membership_inference(target_net, target_train_loader, target_out_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #other model:\n",
    "# in_sizeFT = 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
