{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 (default, Jul  6 2018, 19:12:46) \n",
      "[GCC 5.4.0 20160609]\n",
      "Pytorch: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, '../../../Utils/')\n",
    "sys.path.insert(0, '../../../')\n",
    "import cyphercat as cc\n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import * \n",
    "from SVC_Utils import *\n",
    "\n",
    "#audio\n",
    "import librosa as libr\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "k = 3\n",
    "\n",
    "pretrained = True #run this with networks that have already been trained\n",
    "\n",
    "transform_type = 'SFTF' #either STFT or MFCC  \n",
    "\n",
    "data = 'Libri' #'Libri' or 'VOiCES'\n",
    "defense = 'dimen_reduc_top3_breakpost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speech preprocessing\n",
    "\n",
    "class tensorToMFCC:\n",
    "    def __call__(self, y):\n",
    "#         y = y.numpy()\n",
    "        dims = y.shape\n",
    "        y = libr.feature.melspectrogram(np.reshape(y, (dims[1],)), 16000, n_mels=number_of_mels,\n",
    "                               fmax=8000)\n",
    "        y = libr.feature.mfcc(S = libr.power_to_db(y))\n",
    "        y = torch.from_numpy(y)                           \n",
    "        return y.float()\n",
    "\n",
    "class STFT:\n",
    "    def __call__(self,y):\n",
    "        dims = y.shape\n",
    "        y = np.abs(libr.core.stft(np.reshape(y, (dims[1],))))\n",
    "        y = torch.from_numpy(y).permute(1,0)\n",
    "        return y.float()\n",
    "\n",
    "if transform_type == 'SFTF':\n",
    "    target_net_type = cc.ft_cnn_classifer\n",
    "    shadow_net_type = cc.ft_cnn_classifer\n",
    "    in_size = 94# 20 forMFCC,  94 for STFT\n",
    "    transform  = STFT() ## STFT or MFCC\n",
    "elif transform_type == 'MFCC':\n",
    "    transform  = tensorToMFCC()\n",
    "    target_net_type = cc.MFCC_cnn_classifier\n",
    "    shadow_net_type = cc.MFCC_cnn_classifier\n",
    "    in_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "n_seconds = 3\n",
    "n_epochs = 50\n",
    "shadow_epochs = 15\n",
    "n_epochs_attack = 100\n",
    "sampling_rate = 16000\n",
    "number_of_mels =128\n",
    "lr = 0.001\n",
    "\n",
    "# attacking means data for a target & shadow network.\n",
    "# This will also split \"out data\" from totally different speakers -- data none of the \n",
    "# other networks have seen, for training & testing the attack network. This will be\n",
    "# an equivalent amount of data to the train split as defined about\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, './../../../Utils')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load audio data: VOiCES or LibriSpeech, & Split into valid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading splits\n",
      "Initialising LibriSpeechDataset with minimum length = 3s and subset = train-clean-100\n",
      "\t Finished indexing train-clean-100. 27949 usable files found.\n",
      "\t Finished indexing test-clean. 2225 usable files found.\n",
      "Build/load speaker membership inference splits\n",
      "Found default speaker splits, loading dataframe\n",
      "Build/load sample membership inference splits\n",
      "Found default sample splits, loading dataframe\n",
      "\n",
      " ------- Speaker split statistics ------- \n",
      "\t\t ---- Split 0 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 63\t\t 5539\n",
      "Female:\t\t 62\t\t 5573\n",
      "Total:\t\t 125\t\t 11112\n",
      "\t\t ---- Split 1 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 63\t\t 1414\n",
      "Female:\t\t 62\t\t 1427\n",
      "Total:\t\t 125\t\t 2841\n",
      "\t\t ---- Split 2 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 31\t\t 3519\n",
      "Female:\t\t 31\t\t 3478\n",
      "Total:\t\t 62\t\t 6997\n",
      "\t\t ---- Split 3 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 32\t\t 3462\n",
      "Female:\t\t 32\t\t 3537\n",
      "Total:\t\t 64\t\t 6999\n",
      "\t\t ---- Split 4 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 16\t\t 1414\n",
      "Female:\t\t 16\t\t 1427\n",
      "Total:\t\t 32\t\t 2841\n",
      "\t\t ---- Split 5 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 20\t\t 1084\n",
      "Female:\t\t 20\t\t 1141\n",
      "Total:\t\t 40\t\t 2225\n",
      " ---------------------------------------- \n",
      "\n",
      " ------- Sample split statistics -------- \n",
      "\t\t ---- Split 0 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 63\t\t 5539\n",
      "Female:\t\t 62\t\t 5573\n",
      "Total:\t\t 125\t\t 11112\n",
      "\t\t ---- Split 1 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 63\t\t 1414\n",
      "Female:\t\t 62\t\t 1427\n",
      "Total:\t\t 125\t\t 2841\n",
      "\t\t ---- Split 2 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 63\t\t 3471\n",
      "Female:\t\t 63\t\t 3490\n",
      "Total:\t\t 126\t\t 6961\n",
      "\t\t ---- Split 3 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 63\t\t 3510\n",
      "Female:\t\t 63\t\t 3525\n",
      "Total:\t\t 126\t\t 7035\n",
      "\t\t ---- Split 4 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 16\t\t 1414\n",
      "Female:\t\t 16\t\t 1427\n",
      "Total:\t\t 32\t\t 2841\n",
      " ---------------------------------------- \n",
      "\n",
      "Finished splitting data.\n",
      "Initializing dataset\n",
      "Succesfully loaded libri-speech\n"
     ]
    }
   ],
   "source": [
    "print('Loading splits')\n",
    "subset = 'room-1'\n",
    "if data == 'Libri':\n",
    "    [dfs, sample_df] = cc.Libri_preload_and_split()\n",
    "    print('Initializing dataset')\n",
    "    valid_sequence_train_target = cc.LibriSpeechDataset(df=dfs[0], transform = transform)\n",
    "    valid_sequence_test_target = cc.LibriSpeechDataset(df=dfs[1], transform = transform)\n",
    "    valid_sequence_train_shadow = cc.LibriSpeechDataset(df=dfs[2], transform = transform)\n",
    "    valid_sequence_test_shadow = cc.LibriSpeechDataset(df=dfs[3], transform = transform)\n",
    "    valid_sequence_attack_in = cc.LibriSpeechDataset(df=dfs[4], transform = transform)\n",
    "    valid_sequence_attack_out = cc.LibriSpeechDataset(df=dfs[5], transform = transform)\n",
    "\n",
    "    print('Succesfully loaded libri-speech')\n",
    "elif data == 'VOiCES':\n",
    "    [dfs, sample_df] = cc.Voices_preload_and_split(subset = subset)\n",
    "    print('Initializing dataset')\n",
    "    valid_sequence_train_target = cc.Voices_dataset(df=dfs[0], transform = transform)\n",
    "    valid_sequence_test_target = cc.Voices_dataset(df=dfs[1], transform = transform)\n",
    "    valid_sequence_train_shadow = cc.Voices_dataset(df=dfs[2], transform = transform)\n",
    "    valid_sequence_test_shadow = cc.Voices_dataset(df=dfs[3], transform = transform)\n",
    "    valid_sequence_attack_in = cc.Voices_dataset(df=dfs[4], transform = transform)\n",
    "    valid_sequence_attack_out = cc.Voices_dataset(df=dfs[5], transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # to look at the index file:\n",
    "\n",
    "# # #look at splits file for reference\n",
    "# dff = pd.read_csv(os.getcwd()+'/../../../Datasets/splits/libri-train-clean-100/libri_4.csv')\n",
    "# print(dff.head())\n",
    "# dff2 = pd.read_csv(os.getcwd()+'/../../../Datasets/splits/VOiCES-room-1/VOiCES_0.csv')\n",
    "# print(dff2.head())\n",
    "\n",
    "\n",
    "# # df = pd.read_csv(os.getcwd()+'/../../../Datasets/VOiCES-room-1.index.csv')\n",
    "# # df.head()\n",
    "\n",
    "# # g = df.groupby(['id','Section']).groups\n",
    "\n",
    "# # dfn = pd.DataFrame(columns = ['id','Section'])\n",
    "# # idx = 0\n",
    "# # for key in g.keys():\n",
    "# #     dfn.at[idx,'id']=key[0]\n",
    "# #     dfn.at[idx,'Section']=key[1]\n",
    "# #     idx +=1\n",
    "\n",
    "# # print(len(np.unique(df.id)), 'speakers')\n",
    "# # print(len(df), 'files')\n",
    "# # print(dfn.groupby('id').count().min()[0], 'tracks min')\n",
    "# # print(dfn.groupby('id').count().max()[0], 'tracks max')\n",
    "# # print(dfn.groupby('id').count().mean()[0], 'tracks mean')\n",
    "\n",
    "# # print('min speaker minutes',df.groupby('id').mean()['speaker_minutes'].min())\n",
    "# # print('max speaker minutes',df.groupby('id').mean()['speaker_minutes'].max())\n",
    "# # print('mean speaker minutes',df.groupby('id').mean()['speaker_minutes'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = [.2,.8]\n",
    "# df1 = pd.DataFrame(columns = df.columns)\n",
    "# df2 = pd.DataFrame(columns = df.columns)\n",
    "# # For each speaker, identify unique segments: \n",
    "# for spkr_id in df.id.unique():\n",
    "#     mini_df = df[df['id'] == spkr_id]\n",
    "#     # Identify segments:\n",
    "#     n_seg = len(mini_df.Section.unique())\n",
    "#     seg1 = round(splits[0]*n_seg)\n",
    "#     # Segments are not ordered in a particular way, so just pick the first few for seg1\n",
    "#     seg1s = mini_df.Section.unique()[:seg1]\n",
    "#     df1 = df1.append(mini_df[mini_df['Section'].isin(seg1s)])\n",
    "#     df2 = df2.append(mini_df[~mini_df['Section'].isin(seg1s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Loaders for data for target model & shadow model \n",
    "target_train_loader = DataLoader(valid_sequence_train_target,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8,\n",
    "                    drop_last = True\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "target_test_loader = DataLoader(valid_sequence_test_target,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "shadow_train_loader = DataLoader(valid_sequence_train_shadow,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8,\n",
    "                    drop_last = True\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "shadow_test_loader = DataLoader(valid_sequence_test_shadow,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "test_loader_in = DataLoader(valid_sequence_attack_in,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "test_loader_out = DataLoader(valid_sequence_attack_out,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table with summary\n",
    "\n",
    "summary_file = 'summary.pkl'\n",
    "columns = ['Data','Transform','Training epochs', '# speakers','Train accuracy', 'Test accuracy', \n",
    "           'Attack type', 'Defense','Attack Accuracy', 'Attack Precision','Attack Recall', 'Thresholds']\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "df_idx = len(df)\n",
    "\n",
    "#set a bunch of known values\n",
    "df.at[df_idx,'Transform'] =transform_type\n",
    "df.at[df_idx,'Training epochs'] = n_epochs\n",
    "df.at[df_idx,'Attack type'] = 1\n",
    "df.at[df_idx,'Defense'] = defense\n",
    "df.at[df_idx,'Data'] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize/Train Targets\n",
    "The model being attacked; if network, architecture can differ from that of shadow network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125  speakers\n"
     ]
    }
   ],
   "source": [
    "#Initialize NN\n",
    "\n",
    "#in_size defined above\n",
    "n_hidden = 512\n",
    "n_classes = valid_sequence_test_target.num_speakers\n",
    "print(n_classes,' speakers')\n",
    "df.at[df_idx,'# speakers']=n_classes\n",
    "\n",
    "\n",
    "target_net = target_net_type(n_classes).to(device)\n",
    "target_net.apply(models.weights_init)\n",
    "\n",
    "target_loss = nn.CrossEntropyLoss()\n",
    "target_optim = optim.Adam(target_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_weights/CNN_voice_classifierLibri_target_SFTF49.pth.tar\n",
      "Succesfully loaded checkpoint \n",
      "Dataset: Libri \n",
      "Epoch: 14 \n",
      "Loss: None           \n",
      "Accuracy: [99.15345821325649, 94.68497008095741]\n"
     ]
    }
   ],
   "source": [
    "#file name for this set of hyperparameters\n",
    "fn = 'model_weights/CNN_voice_classifier'+data+'_target_'+transform_type+str(n_epochs-1)\n",
    "\n",
    "#Train NN\n",
    "if not pretrained:\n",
    "    train_accuracy, test_accuracy = cc.train(target_net, target_train_loader, target_test_loader, target_optim, target_loss, n_epochs, verbose = False) \n",
    "    df.at[df_idx,'Train accuracy'] =round(train_accuracy,4)/100\n",
    "    df.at[df_idx,'Test accuracy'] = round(test_accuracy,4)/100\n",
    "    cc.save_checkpoint(model = target_net, optimizer = target_optim,\n",
    "                           epoch = n_epochs-1, data_descriptor = data, \n",
    "                           accuracy = [train_accuracy, test_accuracy],\n",
    "                           filename = fn)\n",
    "    \n",
    "else:\n",
    "    fn = fn + '.pth.tar'\n",
    "    print(fn)\n",
    "    cc.load_checkpoint(model = target_net, checkpoint = fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize/Train Shadow Model\n",
    "Shadow model mimics the target network, emulating the target model's differences in prediction probabilities for samples in and out of its dataset. For this attack, only one shadow model is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sequence_train_shadow.num_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimen_reduc_top3_breakpost\n"
     ]
    }
   ],
   "source": [
    "# IF defending:\n",
    "if defense == 'dimen_reduc_top3_breakpost':\n",
    "    print(defense)\n",
    "    target_net = cc.defenses.dimensionality_reduction(model = target_net, n_top = 3, break_posterior = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n shadow speakers 64\n"
     ]
    }
   ],
   "source": [
    "#Initialize models\n",
    "\n",
    "n_classes = valid_sequence_test_shadow.num_speakers\n",
    "print('n shadow speakers',n_classes)\n",
    "\n",
    "#NN\n",
    "shadow_net = shadow_net_type(n_classes).to(device)\n",
    "shadow_net.apply(models.weights_init)\n",
    "\n",
    "shadow_loss = nn.CrossEntropyLoss()\n",
    "shadow_optim = optim.Adam(shadow_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Attack Model\n",
    "A binary classifier to determine membership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Training shadow network ----\n",
      "[0/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 88.26 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.09 %%\n",
      "\n",
      "\n",
      "[1/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 93.42 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.39 %%\n",
      "\n",
      "\n",
      "[2/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 95.56 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.41 %%\n",
      "\n",
      "\n",
      "[3/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 95.50 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.74 %%\n",
      "\n",
      "\n",
      "[4/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 95.60 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.01 %%\n",
      "\n",
      "\n",
      "[5/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.06 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.94 %%\n",
      "\n",
      "\n",
      "[6/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.35 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.43 %%\n",
      "\n",
      "\n",
      "[7/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 96.86 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.17 %%\n",
      "\n",
      "\n",
      "[8/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.04 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.14 %%\n",
      "\n",
      "\n",
      "[9/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.58 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.77 %%\n",
      "\n",
      "\n",
      "[10/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.16 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.01 %%\n",
      "\n",
      "\n",
      "[11/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 96.83 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.37 %%\n",
      "\n",
      "\n",
      "[12/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.48 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.51 %%\n",
      "\n",
      "\n",
      "[13/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.08 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.46 %%\n",
      "\n",
      "\n",
      "[14/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.28 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 1.54 %%\n",
      "\n",
      "\n",
      "---- Training attack network ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fee20931978>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluate attack ----\n"
     ]
    }
   ],
   "source": [
    "# Attack the network: \n",
    "\n",
    "attack_net_nn = models.mlleaks_mlp(n_in=k).to(device)\n",
    "attack_loss = nn.BCEWithLogitsLoss()\n",
    "attack_optim_nn= optim.Adam(attack_net_nn.parameters(), lr=lr)\n",
    "\n",
    "df_pr = cc.ml_leaks1(target=target_net, shadow_model = shadow_net, attacker_model = attack_net_nn,\n",
    "            target_in_loader = test_loader_in, target_out_loader = test_loader_out,\n",
    "            shadow_train_loader = shadow_train_loader, shadow_out_loader=shadow_test_loader,\n",
    "            shadow_optim = shadow_optim, attack_optim = attack_optim_nn, \n",
    "            shadow_criterion = shadow_loss, attack_criterion = attack_loss, \n",
    "            shadow_epochs = shadow_epochs, attack_epochs = n_epochs_attack, retrain = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.525</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.530</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.535</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.540</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.545</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.550</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.555</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.560</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.565</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.570</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.575</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.580</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.585</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.590</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.595</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.600</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.605</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.610</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.615</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.620</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.625</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.630</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.635</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.640</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.645</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.850</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.855</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.860</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.865</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.870</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.875</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.880</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.885</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.890</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.895</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.900</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.905</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.910</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.915</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.920</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.930</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.935</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.940</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.945</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.950</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.955</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.960</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.965</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.970</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.975</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.980</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.985</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.990</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.995</td>\n",
       "      <td>49.832027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Thresholds   Accuracy  Precision  Recall\n",
       "0        0.500  49.832027        0.0     0.0\n",
       "1        0.505  49.832027        0.0     0.0\n",
       "2        0.510  49.832027        0.0     0.0\n",
       "3        0.515  49.832027        0.0     0.0\n",
       "4        0.520  49.832027        0.0     0.0\n",
       "5        0.525  49.832027        0.0     0.0\n",
       "6        0.530  49.832027        0.0     0.0\n",
       "7        0.535  49.832027        0.0     0.0\n",
       "8        0.540  49.832027        0.0     0.0\n",
       "9        0.545  49.832027        0.0     0.0\n",
       "10       0.550  49.832027        0.0     0.0\n",
       "11       0.555  49.832027        0.0     0.0\n",
       "12       0.560  49.832027        0.0     0.0\n",
       "13       0.565  49.832027        0.0     0.0\n",
       "14       0.570  49.832027        0.0     0.0\n",
       "15       0.575  49.832027        0.0     0.0\n",
       "16       0.580  49.832027        0.0     0.0\n",
       "17       0.585  49.832027        0.0     0.0\n",
       "18       0.590  49.832027        0.0     0.0\n",
       "19       0.595  49.832027        0.0     0.0\n",
       "20       0.600  49.832027        0.0     0.0\n",
       "21       0.605  49.832027        0.0     0.0\n",
       "22       0.610  49.832027        0.0     0.0\n",
       "23       0.615  49.832027        0.0     0.0\n",
       "24       0.620  49.832027        0.0     0.0\n",
       "25       0.625  49.832027        0.0     0.0\n",
       "26       0.630  49.832027        0.0     0.0\n",
       "27       0.635  49.832027        0.0     0.0\n",
       "28       0.640  49.832027        0.0     0.0\n",
       "29       0.645  49.832027        0.0     0.0\n",
       "..         ...        ...        ...     ...\n",
       "70       0.850  49.832027        0.0     0.0\n",
       "71       0.855  49.832027        0.0     0.0\n",
       "72       0.860  49.832027        0.0     0.0\n",
       "73       0.865  49.832027        0.0     0.0\n",
       "74       0.870  49.832027        0.0     0.0\n",
       "75       0.875  49.832027        0.0     0.0\n",
       "76       0.880  49.832027        0.0     0.0\n",
       "77       0.885  49.832027        0.0     0.0\n",
       "78       0.890  49.832027        0.0     0.0\n",
       "79       0.895  49.832027        0.0     0.0\n",
       "80       0.900  49.832027        0.0     0.0\n",
       "81       0.905  49.832027        0.0     0.0\n",
       "82       0.910  49.832027        0.0     0.0\n",
       "83       0.915  49.832027        0.0     0.0\n",
       "84       0.920  49.832027        0.0     0.0\n",
       "85       0.925  49.832027        0.0     0.0\n",
       "86       0.930  49.832027        0.0     0.0\n",
       "87       0.935  49.832027        0.0     0.0\n",
       "88       0.940  49.832027        0.0     0.0\n",
       "89       0.945  49.832027        0.0     0.0\n",
       "90       0.950  49.832027        0.0     0.0\n",
       "91       0.955  49.832027        0.0     0.0\n",
       "92       0.960  49.832027        0.0     0.0\n",
       "93       0.965  49.832027        0.0     0.0\n",
       "94       0.970  49.832027        0.0     0.0\n",
       "95       0.975  49.832027        0.0     0.0\n",
       "96       0.980  49.832027        0.0     0.0\n",
       "97       0.985  49.832027        0.0     0.0\n",
       "98       0.990  49.832027        0.0     0.0\n",
       "99       0.995  49.832027        0.0     0.0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ascertain best results\n",
    "\n",
    "df.at[df_idx,'Attack Precision'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Precision.values[0],4)\n",
    "df.at[df_idx,'Attack Recall'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Recall.values[0],4)\n",
    "df.at[df_idx,'Attack Accuracy'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Accuracy.values[0],4)/100\n",
    "df.at[df_idx,'Threshold'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Thresholds.values[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to table\n",
    "\n",
    "try:\n",
    "    df_summ = pd.read_pickle(summary_file)\n",
    "    print('Loading summary file')\n",
    "\n",
    "except:\n",
    "    print('Creating new summary file')\n",
    "\n",
    "# Append row you created\n",
    "df_summ = df_summ.append(df) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated df\n",
    "df_summ.to_pickle(summary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Attack Nets\n",
    "How well the trained attack models classify a sample as in or out of a target model's training dataset, and how performance is affected by target hyperparameters and which models attack which targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col0 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col1 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col2 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col3 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col4 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col5 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col6 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col7 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col8 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col9 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }    #T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col10 {\n",
       "            font-size:  16pt;\n",
       "            column-size:  24pt;\n",
       "            width:  100px;\n",
       "        }</style>  \n",
       "<table id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2b\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"col_heading level0 col0\" >Transform</th> \n",
       "        <th class=\"col_heading level0 col1\" >Training epochs</th> \n",
       "        <th class=\"col_heading level0 col2\" ># speakers</th> \n",
       "        <th class=\"col_heading level0 col3\" >Train accuracy</th> \n",
       "        <th class=\"col_heading level0 col4\" >Test accuracy</th> \n",
       "        <th class=\"col_heading level0 col5\" >Attack type</th> \n",
       "        <th class=\"col_heading level0 col6\" >Attack Precision</th> \n",
       "        <th class=\"col_heading level0 col7\" >Attack Recall</th> \n",
       "        <th class=\"col_heading level0 col8\" >Attack Accuracy</th> \n",
       "        <th class=\"col_heading level0 col9\" >Defense</th> \n",
       "        <th class=\"col_heading level0 col10\" >Data</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col0\" class=\"data row0 col0\" >SFTF</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col1\" class=\"data row0 col1\" >50</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col2\" class=\"data row0 col2\" >125</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col3\" class=\"data row0 col3\" >99.52%</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col4\" class=\"data row0 col4\" >94.97%</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col5\" class=\"data row0 col5\" >1</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col6\" class=\"data row0 col6\" >85.85%</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col7\" class=\"data row0 col7\" >90.76%</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col8\" class=\"data row0 col8\" >87.86%</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col9\" class=\"data row0 col9\" >None</td> \n",
       "        <td id=\"T_2e82683e_15d5_11e9_80af_0a58ac1ffe2brow0_col10\" class=\"data row0 col10\" >Libri</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fed9c797400>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['# speakers'] =df['# speakers'].astype(float)\n",
    "df['Training epochs'] =df['Training epochs'].astype(float)\n",
    "df['Attack type'] =df['Attack type'].astype(float)\n",
    "\n",
    "#style table\n",
    "import seaborn as sns\n",
    "\n",
    "cg = sns.light_palette(\"green\", as_cmap=True)\n",
    "cm = sns.light_palette(\"magenta\", as_cmap=True)\n",
    "bl = sns.light_palette(\"blue\", as_cmap=True)\n",
    "orr = sns.light_palette(\"orange\", as_cmap=True)\n",
    "gr = sns.light_palette(\"gray\", as_cmap=True)\n",
    "\n",
    "# df.style.bar(subset=['Train accuracy', 'Test accuracy'], align='mid', color=['#d65f5f', '#5fba7d'])\n",
    "s = df.style.\\\n",
    "    format({\"Attack Precision\": \"{:.2%}\",\"Attack Recall\": \"{:.2%}\",\"Attack Accuracy\": \"{:.2%}\"}).\\\n",
    "    format({\"Train accuracy\": \"{:.2%}\",\"Test accuracy\": \"{:.2%}\"}).\\\n",
    "    hide_index().\\\n",
    "\n",
    "    set_properties(**{'font-size': \"16pt\",'column-size':\"24pt\",'width': '100px'})\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    background_gradient(cmap=cg,subset=['Train accuracy', 'Test accuracy']).\\\n",
    "    background_gradient(cmap=bl,subset=['Precision', 'Recall']).\\\n",
    "    background_gradient(cmap=orr,subset=['Training epochs']).\\\n",
    "    background_gradient(cmap=gr,subset=['Attack type']).\\\n",
    "    background_gradient(cmap=cm,subset=['# speakers']).\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
