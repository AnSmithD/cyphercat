{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "device=torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainset.__len__(),\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=testset.__len__(),\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataloader,transform_list):\n",
    "    for data in dataloader:\n",
    "        x,y=data\n",
    "    x=x.view(x.shape[0],-1)\n",
    "    for i in transform_list:\n",
    "        i.fit(x)\n",
    "        x=i.transform(x)\n",
    "    y=y.numpy()\n",
    "    return x,y\n",
    "def accuracy(preds,targs,training=False):\n",
    "    p=torch.from_numpy(preds)\n",
    "    t=torch.from_numpy(targs)\n",
    "    correct = (torch.eq(t,p)).sum().item()\n",
    "    accuracy=100*(correct/len(preds))\n",
    "    if training is False:\n",
    "        print('overall testing accuracy: ',accuracy)\n",
    "    else:\n",
    "        print('overall training accuracy: ',accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "components=180\n",
    "pca=PCA(n_components=components)\n",
    "scaling = MinMaxScaler(feature_range=(-1,1))\n",
    "tlist=[]\n",
    "tlist.append(pca);tlist.append(scaling)\n",
    "C_range = np.logspace(-2,2,5) #[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n",
    "gamma_range = np.logspace(-3, 1, 5) #[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininputs,traintargets=process(trainloader,tlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testinputs,testtargets=process(testloader,tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(traininputs));print(type(traintargets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifiers = []\n",
    "\n",
    "for c in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        svcrbf=svm.SVC(C=c,kernel='rbf',gamma=gamma)\n",
    "        svc=make_pipeline(pca,scaling,svcrbf)\n",
    "        classifiers.append([gamma,c,svc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=svm.SVC()\n",
    "gs_parameters={'gamma':gamma_range,'C':C_range}\n",
    "gs=GridSearchCV(svc,gs_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01]), 'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(traininputs,traintargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_accuracies=[]\n",
    "classif_idx=0;\n",
    "for j in range(5):\n",
    "    for data in trainloader:\n",
    "        traininputs,traintargets=data;\n",
    "        traininputs=flatten(traininputs)\n",
    "        classifiers[classif_idx][2]=classifiers[classif_idx][2].fit(traininputs,traintargets)\n",
    "        train_accuracies.append(accuracy(classifiers[classif_idx][2].predict(traininputs),traintargets,training=True))\n",
    "        print(classifiers[classif_idx])\n",
    "        classif_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=gs.predict(testinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try: rbf kernel, c/gamma values, pca/svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "classaccuracy=np.zeros(len(classes))\n",
    "ntargets=testtargets.cpu().numpy()\n",
    "for i in range(len(ntargets)):\n",
    "    if TestPredictions[i]==ntargets[i]:\n",
    "        classaccuracy[ntargets[i]]=classaccuracy[ntargets[i]]+1\n",
    "classaccuracy=classaccuracy/10\n",
    "for i in range(len(classes)):\n",
    "    print('class accuracy:',classes[i],',',classaccuracy[i],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(TestPredictions,ntargets)\n",
    "print(classes)\n",
    "print(cm);type(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing_accuracies=[]\n",
    "for data in testloader:\n",
    "    testinputs, testtargets=data;\n",
    "    testinputs=flatten(testinputs)\n",
    "for i in classifiers:\n",
    "    x=accuracy(i[2].predict(testinputs),testtargets)\n",
    "    testing_accuracies.append([i,x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(testing_accuracies[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(trainset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valtrainloader = torch.utils.data.DataLoader(trainset, batch_size=trainset.__len__(),shuffle=True, num_workers=2)\n",
    "valsvcrbf=svm.SVC(C=.1,gamma=.1,kernel='rbf')\n",
    "valsvc=make_pipeline(pca,scaling,valsvcrbf)\n",
    "for data in valtrainloader:\n",
    "    valinputs,valtargets=data;\n",
    "    valinputs=flatten(valinputs)\n",
    "valsvc.fit(valinputs,valtargets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_model=[valsvc, accuracy(valsvc.predict(valinputs),valtargets)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy(valsvc.predict(testinputs),testtargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc=svm.SVC(C=1,gamma=.1,kernel='rbf');\n",
    "psvc=make_pipeline(pca,scaling,svc)\n",
    "psvc.fit(valinputs,valtargets)\n",
    "x=[accuracy(psvc.predict(testinputs),testtargets),psvc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall testing accuracy:  19.66\n"
     ]
    }
   ],
   "source": [
    "x=accuracy(preds,testtargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
