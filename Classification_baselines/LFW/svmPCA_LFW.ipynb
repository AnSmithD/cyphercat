{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader as dl\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage import io\n",
    "\n",
    "import os, shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Utils/',\n",
       " '../../Utils/',\n",
       " '',\n",
       " '/usr/local/lib/python36.zip',\n",
       " '/usr/local/lib/python3.6',\n",
       " '/usr/local/lib/python3.6/lib-dynload',\n",
       " '/usr/local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/site-packages/xgboost-0.72-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/mvisaya/.ipython']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('../../Utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/usr/local/lib/python36.zip',\n",
       " '/usr/local/lib/python3.6',\n",
       " '/usr/local/lib/python3.6/lib-dynload',\n",
       " '/usr/local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/site-packages/xgboost-0.72-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/mvisaya/.ipython']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/usr/local/lib/python36.zip',\n",
       " '/usr/local/lib/python3.6',\n",
       " '/usr/local/lib/python3.6/lib-dynload',\n",
       " '/usr/local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/site-packages/xgboost-0.72-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/mvisaya/.ipython']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfw(datasets_dir): \n",
    "\n",
    "    if os.path.isdir(os.path.join(datasets_dir,'lfw')):\n",
    "        print('LFW already downloaded.')\n",
    "        return\n",
    "\n",
    "    if not os.path.isdir(datasets_dir):\n",
    "        os.makedirs(datasets_dir)\n",
    "\n",
    "    print('Downloading LFW.')\n",
    "\n",
    "    url = 'http://vis-www.cs.umass.edu/lfw/lfw.tgz'\n",
    "    urllib.request.urlretrieve(url, os.path.join(datasets_dir,'lfw.tgz'))\n",
    "\n",
    "    tar = tarfile.open(os.path.join(datasets_dir,'lfw.tgz'))\n",
    "    tar.extractall(path=os.path.join(datasets_dir,'lfw/'))\n",
    "\n",
    "    os.rename(os.path.join(datasets_dir,'lfw/lfw/'), os.path.join(datasets_dir,'lfw/lfw_original/'))\n",
    "\n",
    "\n",
    "    lfw_dir = os.path.join(datasets_dir,'lfw/lfw_original/')\n",
    "    people_dir = os.listdir(lfw_dir)\n",
    "\n",
    "\n",
    "    num_per_class = 20\n",
    "\n",
    "    new_dir = os.path.join(datasets_dir,'lfw/lfw_'+str(num_per_class))\n",
    "\n",
    "    if not os.path.isdir(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "\n",
    "    for p in people_dir:\n",
    "        imgs = os.listdir(os.path.join(lfw_dir,p))\n",
    "        if len(imgs) >= num_per_class:\n",
    "            shutil.copytree(os.path.join(lfw_dir,p),os.path.join(new_dir,p))\n",
    "\n",
    "    print('LFW successfully downloaded and preprocessed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFW already downloaded.\n"
     ]
    }
   ],
   "source": [
    "get_lfw('./data')\n",
    "data_dir = \"./data/lfw/lfw_20/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[] #unbalanced dataset\n",
    "eqimages=[]; #balanced but small dataset\n",
    "imgs_per_class=np.zeros(len(classes))\n",
    "for i in os.listdir(data_dir):\n",
    "    for j in os.listdir(os.path.join(data_dir,i)):\n",
    "        images.append(os.path.join(data_dir,i,j))\n",
    "        \n",
    "classes=[]\n",
    "classes_to_idx={}\n",
    "j=0;\n",
    "\n",
    "\n",
    "for i in images:\n",
    "    name=i.split('/')[4];\n",
    "    if name not in classes_to_idx:\n",
    "        classes.append(name)\n",
    "        classes_to_idx[name]=j\n",
    "        j+=1\n",
    "\n",
    "for k in images:\n",
    "    name=k.split('/')[4];\n",
    "    name_idx=classes_to_idx[name]\n",
    "    if imgs_per_class[name_idx]<20:\n",
    "        eqimages.append(k)\n",
    "        imgs_per_class[name_idx]+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-2ffe7850c6b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0meqimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meqimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainset_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainset_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainset_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "images=np.random.permutation(images)\n",
    "eqimages=np.random.permutation(eqimages)\n",
    "trainset_len=.8*(len(images))\n",
    "trainset=images[:trainset_len];\n",
    "testset=images[trainset_len:]\n",
    "print(len(trainset));print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFW(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_list, classes_list, transform=None):\n",
    "        self.classes_to_idx=classes_list\n",
    "        self.img_list=img_list\n",
    "        self.transform=transform;\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list);\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=self.img_list[idx]\n",
    "        sample=io.imread(img)\n",
    "        label=self.classes_to_idx[img.split('/')[4]]\n",
    "        if self.transform is not None:\n",
    "            sample=self.transform(sample)\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.ToTensor()\n",
    "trainset=LFW(eqimages,classes_to_idx,transform=transform)\n",
    "testset=LFW(images,classes_to_idx,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainset.__len__(),\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=150,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(a):\n",
    "    y=a.view(a.shape[0],-1)\n",
    "    return y\n",
    "def accuracy(preds,targs,training=False):\n",
    "    t=torch.from_numpy(preds)\n",
    "    correct = (torch.eq(t,targs)).sum().item()\n",
    "    accuracy=100*(correct/len(preds))\n",
    "    sys.stdout.write(\"\\033[1;31m\")\n",
    "    if training is False:\n",
    "        print('overall testing accuracy: ',accuracy)\n",
    "    else:\n",
    "        print('overall training accuracy: ',accuracy)\n",
    "    sys.stdout.write(\"\\033[0;0m\")    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "components=180\n",
    "pca=PCA(n_components=components)\n",
    "scaling = MinMaxScaler(feature_range=(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "C_range = np.logspace(-2,2,5) #[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n",
    "gamma_range = np.logspace(-3, 1, 5) #[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01]\n",
    "\n",
    "for c in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        svcrbf=svm.SVC(C=c,kernel='rbf',gamma=gamma)\n",
    "        svc=make_pipeline(pca,scaling,svcrbf)\n",
    "        classifiers.append([gamma,c,svc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainaccuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-fe42a92ee253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtraininputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassif_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassif_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraintargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrainaccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassif_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraintargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mclassif_idx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainaccuracies' is not defined"
     ]
    }
   ],
   "source": [
    "train_accuracies=[]\n",
    "classif_idx=0;\n",
    "for j in range(10):\n",
    "    for data in trainloader:\n",
    "        traininputs,traintargets=data;\n",
    "        traininputs=flatten(traininputs)\n",
    "        classifiers[classif_idx][2]=classifiers[classif_idx][2].fit(traininputs,traintargets)\n",
    "        train_accuracies.append(accuracy(classifiers[classif_idx][2].predict(traininputs),traintargets,training=True))\n",
    "        classif_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_accuracies=[]\n",
    "for data in testloader:\n",
    "    testinputs, testtargets=data;\n",
    "    testinputs=flatten(testinputs)\n",
    "for i in classifiers:\n",
    "    x=accuracy(i[2].predict(testinputs),testtargets)\n",
    "    testing_accuracies.append(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
