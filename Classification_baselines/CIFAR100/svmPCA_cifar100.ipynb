{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "device=torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        res = pickle.load(fo, encoding='bytes')\n",
    "    return res\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "#training data\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, \n",
    "                                         download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=300,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valtrainloader=trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainset.__len__(),\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "#test data\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=testset.__len__(),\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "meta = unpickle('datasets/cifar-100-python/meta')\n",
    "\n",
    "fine_label_names = [t.decode('utf8') for t in meta[b'fine_label_names']]\n",
    "\n",
    "train = unpickle('datasets/cifar-100-python/train')\n",
    "\n",
    "filenames = [t.decode('utf8') for t in train[b'filenames']]\n",
    "fine_labels = train[b'fine_labels']\n",
    "data = train[b'data']\n",
    "classes=fine_label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataloader,transform_list):\n",
    "    for data in dataloader:\n",
    "        x,y=data\n",
    "    x=x.view(x.shape[0],-1)\n",
    "    for i in transform_list:\n",
    "        i.fit(x)\n",
    "        x=i.transform(x)\n",
    "    y=y.numpy()\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcrbf=svm.SVC(kernel='rbf',gamma=.1,C=1)\n",
    "parameters={'gamma': [1e-2, 1e-1,1],'C': [.1,1,10]}\n",
    "for data in trainloader:\n",
    "    traininputs,traintargets=data;\n",
    "    traininputs=flatten(traininputs)\n",
    "    traintargets=traintargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=180) #isolates the most important image features\n",
    "scaling = MinMaxScaler(feature_range=(-1,1)) #normalizes features between -1 and 1\n",
    "pip=make_pipeline(pca,scaling,svcrbf)\n",
    "\n",
    "tlist=[]\n",
    "tlist.append(pca);tlist.append(scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip.fit(traininputs,traintargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(traininputs)\n",
    "traininputs=pca.transform(traininputs)\n",
    "scaling.fit(traininputs);\n",
    "traininputs=scaling.transform(traininputs)\n",
    "type(traininputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c8b440fc7c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraini\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraintargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "traini=torch.from_numpy(traininputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traininputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(traini));print(type(traintargets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=traini.numpy()\n",
    "b=traintargets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.01, 0.1, 1], 'C': [0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc=GridSearchCV(svcrbf, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc.fit(traininputs,traintargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testinputs,testtargets=process(testloader,tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=clf.predict(testinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "[440.41998974 424.45138351 478.85944112 410.06473041 316.68031462\n",
      " 456.58601793 288.13716388 349.31616648 463.06717809]\n",
      "std_fit_time\n",
      "[ 1.08146599  1.20750973 29.32461559  0.82350787  0.52982706  1.14757614\n",
      "  0.39982894  0.72883102  1.54844006]\n",
      "mean_score_time\n",
      "[178.72021635 163.55401174 179.88715418 164.98846332 166.63075987\n",
      " 165.80191517 163.63871789 164.7410988  166.751791  ]\n",
      "std_score_time\n",
      "[11.86617793  0.43277718 14.93605932  0.69756003  2.60520886  0.81057945\n",
      "  0.47005187  0.9253255   1.52683554]\n",
      "param_C\n",
      "[0.1 0.1 0.1 1 1 1 10 10 10]\n",
      "param_gamma\n",
      "[0.01 0.1 1 0.01 0.1 1 0.01 0.1 1]\n",
      "params\n",
      "[{'C': 0.1, 'gamma': 0.01}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 1}, {'C': 1, 'gamma': 0.01}, {'C': 1, 'gamma': 0.1}, {'C': 1, 'gamma': 1}, {'C': 10, 'gamma': 0.01}, {'C': 10, 'gamma': 0.1}, {'C': 10, 'gamma': 1}]\n",
      "split0_test_score\n",
      "[0.13083832 0.13964072 0.02982036 0.15934132 0.20592814 0.14844311\n",
      " 0.19071856 0.22497006 0.16215569]\n",
      "split1_test_score\n",
      "[0.13251497 0.14077844 0.03311377 0.16113772 0.20317365 0.14856287\n",
      " 0.1908982  0.21952096 0.16149701]\n",
      "split2_test_score\n",
      "[0.12692771 0.13939759 0.03180723 0.15716867 0.19873494 0.13879518\n",
      " 0.18638554 0.21536145 0.15379518]\n",
      "mean_test_score\n",
      "[0.1301  0.13994 0.03158 0.15922 0.20262 0.14528 0.18934 0.21996 0.15916]\n",
      "std_test_score\n",
      "[0.00233903 0.00060199 0.00135537 0.00162182 0.0029612  0.00457197\n",
      " 0.00208415 0.00393303 0.00379169]\n",
      "rank_test_score\n",
      "[8 7 9 4 2 6 3 1 5]\n",
      "split0_train_score\n",
      "[0.16852853 0.1936036  0.22072072 0.21204204 0.43918919 0.98132132\n",
      " 0.3357958  0.92624625 0.99975976]\n",
      "split1_train_score\n",
      "[0.17168168 0.1924024  0.22255255 0.21243243 0.43438438 0.98129129\n",
      " 0.33219219 0.92726727 0.99966967]\n",
      "split2_train_score\n",
      "[0.17008982 0.19637725 0.22092814 0.2104491  0.43979042 0.98113772\n",
      " 0.33886228 0.92640719 0.99991018]\n",
      "mean_train_score\n",
      "[0.17010001 0.19412775 0.22140047 0.21164119 0.437788   0.98125011\n",
      " 0.33561675 0.92664023 0.99977987]\n",
      "std_train_score\n",
      "[1.28728955e-03 1.66451032e-03 8.19033050e-04 8.57869693e-04\n",
      " 2.41920186e-03 8.04102817e-05 2.72599150e-03 4.48221899e-04\n",
      " 9.92121246e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "for i in clf.cv_results_:\n",
    "    print(i)\n",
    "    print(clf.cv_results_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=clf.best_params_['C']\n",
    "C=1\n",
    "gamma=clf.best_params_['gamma']\n",
    "valinputs,valtargets=process(valtrainloader,tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finsvc=svm.SVC(kernel='rbf',C=C,gamma=gamma)\n",
    "finsvc.fit(valinputs,valtargets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "finpreds=finsvc.predict(testinputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifiers = []\n",
    "C_range = np.logspace(-2,2,5) #[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n",
    "gamma_range = np.logspace(-3, 1, 5) #[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01]\n",
    "\n",
    "for c in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        svcrbf=svm.SVC(C=c,kernel='rbf',gamma=gamma)\n",
    "        svc=make_pipeline(pca,scaling,svcrbf)\n",
    "        classifiers.append([gamma,c,svc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classif_idx=0;\n",
    "for j in range(5):\n",
    "    for data in trainloader:\n",
    "        traininputs,traintargets=data;\n",
    "        traininputs=flatten(traininputs)\n",
    "        classifiers[classif_idx][2]=classifiers[classif_idx][2].fit(traininputs,traintargets)\n",
    "        classif_idx+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds,targs,training=False):\n",
    "    t=torch.from_numpy(preds)\n",
    "    correct = (torch.eq(t,targs)).sum().item()\n",
    "    accuracy=100*(correct/len(preds))\n",
    "    sys.stdout.write(\"\\033[1;31m\")\n",
    "    if training is False:\n",
    "        print('Overall Testing Accuracy: ',accuracy)\n",
    "    else:\n",
    "        print('Overall Training Accuracy: ',accuracy)\n",
    "    sys.stdout.write(\"\\033[0;0m\")    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tars=torch.from_numpy(testtargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mOverall Testing Accuracy:  5.2\n",
      "\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "x=accuracy(finpreds,tars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_accuracies=[]\n",
    "for data in testloader:\n",
    "    testinputs, testtargets=data;\n",
    "    testinputs=flatten(testinputs)\n",
    "for i in classifiers:\n",
    "    x=accuracy(i[2].predict(testinputs),testtargets)\n",
    "    testing_accuracies.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_svm=svm.SVC(C=1,gamma=.1,kernel='rbf')\n",
    "fin_svc=make_pipeline(pca,scaling,val_svm)\n",
    "for data in valtrainloader:\n",
    "    fininputs,fintargets=data;\n",
    "    fininputs=flatten(fininputs);\n",
    "fin_svc.fit(fininputs,fintargets)\n",
    "x=accuracy(fin_svc.predict(testinputs),testtargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try: rbf kernel, c/gamma values, pca/svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "classaccuracy=np.zeros(len(classes))\n",
    "ntargets=testtargets.cpu().numpy()\n",
    "for i in range(len(ntargets)):\n",
    "    if TestPredictions[i]==ntargets[i]:\n",
    "        classaccuracy[ntargets[i]]=classaccuracy[ntargets[i]]+1\n",
    "classaccuracy=classaccuracy/10\n",
    "for i in range(len(classes)):\n",
    "    print('class accuracy:',classes[i],',',classaccuracy[i],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(TestPredictions,ntargets)\n",
    "print(classes)\n",
    "print(cm);type(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
