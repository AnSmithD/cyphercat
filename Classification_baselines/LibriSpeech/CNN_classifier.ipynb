{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 (default, Jul  6 2018, 19:12:46) \n",
      "[GCC 5.4.0 20160609]\n",
      "Pytorch: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#audioviz\n",
    "import librosa as libr\n",
    "import librosa.display as display\n",
    "import IPython.display\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seconds = 3\n",
    "n_epochs = 50\n",
    "sampling_rate = 16000\n",
    "number_of_mels =128\n",
    "all_data = ['train-clean-100']\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech preprocessing\n",
    "Buidling tensorToMFCC transformation for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorToMFCC:\n",
    "    def __call__(self, y):\n",
    "#         y = y.numpy()\n",
    "        dims = y.shape\n",
    "        y = libr.feature.melspectrogram(np.reshape(y, (dims[1],)), 16000, n_mels=number_of_mels,\n",
    "                               fmax=8000)\n",
    "        y = libr.feature.mfcc(S = libr.power_to_db(y))\n",
    "        y = torch.from_numpy(y)                           \n",
    "        return y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform  = tensorToMFCC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LibriSpeechDataSet\n",
    "Load personalized data set, inspred by this [repository](https://github.com/oscarknagg/voicemap/tree/pytorch-python-3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, './../../Utils')\n",
    "from datasets import LibriSpeechDataset\n",
    "from datasets import Libri_preload_and_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising LibriSpeechDataset with minimum length = 3s and subsets = ['train-clean-100']\n",
      "Finished indexing data. 27949 usable files found.\n",
      "Finished splitting data.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/'\n",
    "\n",
    "splits = [0.8, 0.2] #input fraction of data you want partitioned\n",
    "attacking = True\n",
    "\n",
    "if sum(splits) != 1:\n",
    "    print('error: splits do not sum to 1.')\n",
    "\n",
    "#Splits data into 2 sets of speakers for target & shadow network, into above defined train:test splits\n",
    "dfs = Libri_preload_and_split(path,all_data,n_seconds,pad=False,cache=True,splits=splits, attacking = attacking)    \n",
    "\n",
    "#target train & test\n",
    "valid_sequence_train = LibriSpeechDataset(path, df = dfs[0], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_test = LibriSpeechDataset(path, df = dfs[1], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "#shadow train & test\n",
    "valid_sequence_train_shadow = LibriSpeechDataset(path, df = dfs[2], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)\n",
    "\n",
    "valid_sequence_test_shadow = LibriSpeechDataset(path, df = dfs[3], seconds = n_seconds, downsampling=1, \n",
    "                                    transform = transform, stochastic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders for data for target model & shadow model \n",
    "train_loader = DataLoader(valid_sequence_train,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "train_loader_shadow = DataLoader(valid_sequence_train_shadow,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "test_loader = DataLoader(valid_sequence_test,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "test_loader_shadow = DataLoader(valid_sequence_test_shadow,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording, speaker  = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 94])\n",
      "11119\n"
     ]
    }
   ],
   "source": [
    "print(recording.shape)\n",
    "print(valid_sequence_train.num_speakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyphercat utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0,'../../Utils/')\n",
    "from train import *\n",
    "from metrics import * \n",
    "import models\n",
    "from data_downloaders import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, n_input, n_out, kernel_size):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            nn.Conv1d(n_input, n_out, kernel_size, padding=1),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn_block(x)\n",
    "\n",
    "\n",
    "class CNN_classifier(nn.Module):\n",
    "    def __init__(self, in_size, n_hidden, n_classes):\n",
    "        super(CNN_classifier, self).__init__()\n",
    "        self.down_path = nn.ModuleList()\n",
    "        self.down_path.append(ConvBlock(in_size, 2*in_size, 3))\n",
    "        self.down_path.append(ConvBlock(2*in_size, 4*in_size, 3))\n",
    "        self.down_path.append(ConvBlock(4*in_size, 8*in_size, 3))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8*in_size, n_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(n_hidden, n_classes)\n",
    "    def forward(self, x):\n",
    "        for down in self.down_path:\n",
    "            x = down(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return self.out(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 23])\n"
     ]
    }
   ],
   "source": [
    "test = ConvBlock(20, 40, 3)\n",
    "aa = test(recording)\n",
    "print(aa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_classifier(\n",
       "  (down_path): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (cnn_block): Sequential(\n",
       "        (0): Conv1d(20, 40, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (cnn_block): Sequential(\n",
       "        (0): Conv1d(40, 80, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (cnn_block): Sequential(\n",
       "        (0): Conv1d(80, 160, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=160, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (out): Linear(in_features=512, out_features=251, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = CNN_classifier(20, 512, 251)\n",
    "classifier.apply(models.weights_init)\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 251])\n"
     ]
    }
   ],
   "source": [
    "test = classifier(recording.to(device))\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(classifier.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/50][0/348] loss = 5.586255\n",
      "[0/50][1/348] loss = 5.478024\n",
      "[0/50][2/348] loss = 5.595171\n",
      "[0/50][3/348] loss = 5.578467\n",
      "[0/50][4/348] loss = 5.228079\n",
      "[0/50][5/348] loss = 5.350735\n",
      "[0/50][6/348] loss = 5.235791\n",
      "[0/50][7/348] loss = 5.285726\n",
      "[0/50][8/348] loss = 5.284833\n",
      "[0/50][9/348] loss = 4.950645\n",
      "[0/50][10/348] loss = 5.233456\n",
      "[0/50][11/348] loss = 5.076006\n",
      "[0/50][12/348] loss = 5.140486\n",
      "[0/50][13/348] loss = 5.047959\n",
      "[0/50][14/348] loss = 5.209031\n",
      "[0/50][15/348] loss = 5.046748\n",
      "[0/50][16/348] loss = 4.765276\n",
      "[0/50][17/348] loss = 4.769247\n",
      "[0/50][18/348] loss = 4.976702\n",
      "[0/50][19/348] loss = 4.817549\n",
      "[0/50][20/348] loss = 4.690091\n",
      "[0/50][21/348] loss = 4.933263\n",
      "[0/50][22/348] loss = 4.714959\n",
      "[0/50][23/348] loss = 4.430823\n",
      "[0/50][24/348] loss = 4.860175\n",
      "[0/50][25/348] loss = 4.775699\n",
      "[0/50][26/348] loss = 4.612775\n",
      "[0/50][27/348] loss = 4.510980\n",
      "[0/50][28/348] loss = 4.345355\n",
      "[0/50][29/348] loss = 4.629667\n",
      "[0/50][30/348] loss = 4.524089\n",
      "[0/50][31/348] loss = 4.336950\n",
      "[0/50][32/348] loss = 4.327579\n",
      "[0/50][33/348] loss = 4.498133\n",
      "[0/50][34/348] loss = 4.494181\n",
      "[0/50][35/348] loss = 4.473460\n",
      "[0/50][36/348] loss = 4.296615\n",
      "[0/50][37/348] loss = 4.337960\n",
      "[0/50][38/348] loss = 4.472274\n",
      "[0/50][39/348] loss = 4.150973\n",
      "[0/50][40/348] loss = 4.066344\n",
      "[0/50][41/348] loss = 4.271228\n",
      "[0/50][42/348] loss = 4.054580\n",
      "[0/50][43/348] loss = 4.123904\n",
      "[0/50][44/348] loss = 4.207880\n",
      "[0/50][45/348] loss = 4.090198\n",
      "[0/50][46/348] loss = 3.897175\n",
      "[0/50][47/348] loss = 3.942279\n",
      "[0/50][48/348] loss = 4.120296\n",
      "[0/50][49/348] loss = 3.927402\n",
      "[0/50][50/348] loss = 3.972855\n",
      "[0/50][51/348] loss = 3.848548\n",
      "[0/50][52/348] loss = 4.034446\n",
      "[0/50][53/348] loss = 3.695456\n",
      "[0/50][54/348] loss = 3.630848\n",
      "[0/50][55/348] loss = 3.717508\n",
      "[0/50][56/348] loss = 3.715161\n",
      "[0/50][57/348] loss = 3.939896\n",
      "[0/50][58/348] loss = 3.697922\n",
      "[0/50][59/348] loss = 3.629426\n",
      "[0/50][60/348] loss = 3.733863\n",
      "[0/50][61/348] loss = 3.721773\n",
      "[0/50][62/348] loss = 3.238855\n",
      "[0/50][63/348] loss = 3.704746\n",
      "[0/50][64/348] loss = 3.452314\n",
      "[0/50][65/348] loss = 3.131253\n",
      "[0/50][66/348] loss = 3.470033\n",
      "[0/50][67/348] loss = 3.261550\n",
      "[0/50][68/348] loss = 3.401951\n",
      "[0/50][69/348] loss = 3.350634\n",
      "[0/50][70/348] loss = 3.318655\n",
      "[0/50][71/348] loss = 3.258066\n",
      "[0/50][72/348] loss = 3.514390\n",
      "[0/50][73/348] loss = 3.170806\n",
      "[0/50][74/348] loss = 3.291245\n",
      "[0/50][75/348] loss = 3.279717\n",
      "[0/50][76/348] loss = 3.180405\n",
      "[0/50][77/348] loss = 3.172022\n",
      "[0/50][78/348] loss = 2.848184\n",
      "[0/50][79/348] loss = 3.045537\n",
      "[0/50][80/348] loss = 2.901973\n",
      "[0/50][81/348] loss = 3.027251\n",
      "[0/50][82/348] loss = 3.030985\n",
      "[0/50][83/348] loss = 2.940548\n",
      "[0/50][84/348] loss = 2.990491\n",
      "[0/50][85/348] loss = 3.064746\n",
      "[0/50][86/348] loss = 2.686819\n",
      "[0/50][87/348] loss = 2.905342\n",
      "[0/50][88/348] loss = 3.036556\n",
      "[0/50][89/348] loss = 3.347872\n",
      "[0/50][90/348] loss = 2.986708\n",
      "[0/50][91/348] loss = 2.907813\n",
      "[0/50][92/348] loss = 3.025386\n",
      "[0/50][93/348] loss = 2.803196\n",
      "[0/50][94/348] loss = 2.492984\n",
      "[0/50][95/348] loss = 2.416646\n",
      "[0/50][96/348] loss = 2.783681\n",
      "[0/50][97/348] loss = 2.592698\n",
      "[0/50][98/348] loss = 2.490347\n",
      "[0/50][99/348] loss = 2.495929\n",
      "[0/50][100/348] loss = 2.450439\n",
      "[0/50][101/348] loss = 2.638924\n",
      "[0/50][102/348] loss = 2.504381\n",
      "[0/50][103/348] loss = 2.642372\n",
      "[0/50][104/348] loss = 2.092156\n",
      "[0/50][105/348] loss = 2.651336\n",
      "[0/50][106/348] loss = 2.449756\n",
      "[0/50][107/348] loss = 2.207965\n",
      "[0/50][108/348] loss = 2.268908\n",
      "[0/50][109/348] loss = 2.474359\n",
      "[0/50][110/348] loss = 2.123833\n",
      "[0/50][111/348] loss = 2.009574\n",
      "[0/50][112/348] loss = 2.372133\n",
      "[0/50][113/348] loss = 2.682651\n",
      "[0/50][114/348] loss = 2.177651\n",
      "[0/50][115/348] loss = 2.685963\n",
      "[0/50][116/348] loss = 2.382651\n",
      "[0/50][117/348] loss = 2.069022\n",
      "[0/50][118/348] loss = 2.490448\n",
      "[0/50][119/348] loss = 2.396763\n",
      "[0/50][120/348] loss = 2.196170\n",
      "[0/50][121/348] loss = 2.226491\n",
      "[0/50][122/348] loss = 2.233548\n",
      "[0/50][123/348] loss = 1.957638\n",
      "[0/50][124/348] loss = 2.486669\n",
      "[0/50][125/348] loss = 1.989629\n",
      "[0/50][126/348] loss = 2.544251\n",
      "[0/50][127/348] loss = 2.296270\n",
      "[0/50][128/348] loss = 2.029037\n",
      "[0/50][129/348] loss = 2.103940\n",
      "[0/50][130/348] loss = 2.307752\n",
      "[0/50][131/348] loss = 2.136320\n",
      "[0/50][132/348] loss = 2.213588\n",
      "[0/50][133/348] loss = 1.806290\n",
      "[0/50][134/348] loss = 1.798492\n",
      "[0/50][135/348] loss = 1.598726\n",
      "[0/50][136/348] loss = 2.252476\n",
      "[0/50][137/348] loss = 2.177299\n",
      "[0/50][138/348] loss = 2.096107\n",
      "[0/50][139/348] loss = 1.775827\n",
      "[0/50][140/348] loss = 2.042675\n",
      "[0/50][141/348] loss = 1.725204\n",
      "[0/50][142/348] loss = 2.284804\n",
      "[0/50][143/348] loss = 1.782022\n",
      "[0/50][144/348] loss = 1.818771\n",
      "[0/50][145/348] loss = 1.718968\n",
      "[0/50][146/348] loss = 2.188178\n",
      "[0/50][147/348] loss = 1.648310\n",
      "[0/50][148/348] loss = 1.777385\n",
      "[0/50][149/348] loss = 1.864800\n",
      "[0/50][150/348] loss = 1.381002\n",
      "[0/50][151/348] loss = 1.837663\n",
      "[0/50][152/348] loss = 1.592871\n",
      "[0/50][153/348] loss = 1.814695\n",
      "[0/50][154/348] loss = 1.650350\n",
      "[0/50][155/348] loss = 1.517004\n",
      "[0/50][156/348] loss = 1.799165\n",
      "[0/50][157/348] loss = 2.180878\n",
      "[0/50][158/348] loss = 1.985734\n",
      "[0/50][159/348] loss = 1.398684\n",
      "[0/50][160/348] loss = 1.979234\n",
      "[0/50][161/348] loss = 1.405837\n",
      "[0/50][162/348] loss = 1.507443\n",
      "[0/50][163/348] loss = 1.616841\n",
      "[0/50][164/348] loss = 1.693416\n",
      "[0/50][165/348] loss = 1.956389\n",
      "[0/50][166/348] loss = 1.581118\n",
      "[0/50][167/348] loss = 1.701358\n",
      "[0/50][168/348] loss = 1.604042\n",
      "[0/50][169/348] loss = 1.474181\n",
      "[0/50][170/348] loss = 1.278244\n",
      "[0/50][171/348] loss = 1.883263\n",
      "[0/50][172/348] loss = 1.357358\n",
      "[0/50][173/348] loss = 1.244651\n",
      "[0/50][174/348] loss = 1.553486\n",
      "[0/50][175/348] loss = 1.456227\n",
      "[0/50][176/348] loss = 1.269624\n",
      "[0/50][177/348] loss = 1.726731\n",
      "[0/50][178/348] loss = 1.581428\n",
      "[0/50][179/348] loss = 1.559568\n",
      "[0/50][180/348] loss = 2.303307\n",
      "[0/50][181/348] loss = 1.333689\n",
      "[0/50][182/348] loss = 1.849005\n",
      "[0/50][183/348] loss = 1.642797\n",
      "[0/50][184/348] loss = 1.510096\n",
      "[0/50][185/348] loss = 1.747150\n",
      "[0/50][186/348] loss = 1.283150\n",
      "[0/50][187/348] loss = 1.319975\n",
      "[0/50][188/348] loss = 1.134637\n",
      "[0/50][189/348] loss = 1.128893\n",
      "[0/50][190/348] loss = 1.030328\n",
      "[0/50][191/348] loss = 1.591473\n",
      "[0/50][192/348] loss = 1.117879\n",
      "[0/50][193/348] loss = 1.508142\n",
      "[0/50][194/348] loss = 1.607434\n",
      "[0/50][195/348] loss = 1.647958\n",
      "[0/50][196/348] loss = 1.572965\n",
      "[0/50][197/348] loss = 1.374209\n",
      "[0/50][198/348] loss = 1.200804\n",
      "[0/50][199/348] loss = 1.345660\n",
      "[0/50][200/348] loss = 1.220145\n",
      "[0/50][201/348] loss = 1.070320\n",
      "[0/50][202/348] loss = 1.148182\n",
      "[0/50][203/348] loss = 1.404036\n",
      "[0/50][204/348] loss = 1.467046\n",
      "[0/50][205/348] loss = 1.063553\n",
      "[0/50][206/348] loss = 1.151847\n",
      "[0/50][207/348] loss = 1.025100\n",
      "[0/50][208/348] loss = 1.576244\n",
      "[0/50][209/348] loss = 1.457906\n",
      "[0/50][210/348] loss = 1.342278\n",
      "[0/50][211/348] loss = 1.112254\n",
      "[0/50][212/348] loss = 1.531142\n",
      "[0/50][213/348] loss = 1.161341\n",
      "[0/50][214/348] loss = 1.300712\n",
      "[0/50][215/348] loss = 1.093941\n",
      "[0/50][216/348] loss = 1.225308\n",
      "[0/50][217/348] loss = 1.396496\n",
      "[0/50][218/348] loss = 0.966228\n",
      "[0/50][219/348] loss = 1.224106\n",
      "[0/50][220/348] loss = 1.626258\n",
      "[0/50][221/348] loss = 1.071619\n",
      "[0/50][222/348] loss = 1.076884\n",
      "[0/50][223/348] loss = 0.834254\n",
      "[0/50][224/348] loss = 1.000095\n",
      "[0/50][225/348] loss = 1.075258\n",
      "[0/50][226/348] loss = 0.923555\n",
      "[0/50][227/348] loss = 1.066465\n",
      "[0/50][228/348] loss = 0.706184\n",
      "[0/50][229/348] loss = 1.662066\n",
      "[0/50][230/348] loss = 1.169415\n",
      "[0/50][231/348] loss = 1.031207\n",
      "[0/50][232/348] loss = 1.018108\n",
      "[0/50][233/348] loss = 1.108806\n",
      "[0/50][234/348] loss = 0.772604\n",
      "[0/50][235/348] loss = 0.809000\n",
      "[0/50][236/348] loss = 0.838786\n",
      "[0/50][237/348] loss = 0.849977\n",
      "[0/50][238/348] loss = 1.212580\n",
      "[0/50][239/348] loss = 1.172139\n",
      "[0/50][240/348] loss = 1.134197\n",
      "[0/50][241/348] loss = 1.048010\n",
      "[0/50][242/348] loss = 1.176226\n",
      "[0/50][243/348] loss = 0.811623\n",
      "[0/50][244/348] loss = 1.239981\n",
      "[0/50][245/348] loss = 0.937814\n",
      "[0/50][246/348] loss = 1.274109\n",
      "[0/50][247/348] loss = 1.054235\n",
      "[0/50][248/348] loss = 0.855907\n",
      "[0/50][249/348] loss = 0.912671\n",
      "[0/50][250/348] loss = 0.955601\n",
      "[0/50][251/348] loss = 0.996548\n",
      "[0/50][252/348] loss = 1.208726\n",
      "[0/50][253/348] loss = 1.103237\n",
      "[0/50][254/348] loss = 0.665689\n",
      "[0/50][255/348] loss = 0.761689\n",
      "[0/50][256/348] loss = 0.809016\n",
      "[0/50][257/348] loss = 0.674990\n",
      "[0/50][258/348] loss = 1.270357\n",
      "[0/50][259/348] loss = 1.108730\n",
      "[0/50][260/348] loss = 0.776395\n",
      "[0/50][261/348] loss = 0.862872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/50][262/348] loss = 1.120486\n",
      "[0/50][263/348] loss = 0.738738\n",
      "[0/50][264/348] loss = 0.941837\n",
      "[0/50][265/348] loss = 0.966072\n",
      "[0/50][266/348] loss = 1.086259\n",
      "[0/50][267/348] loss = 1.405377\n",
      "[0/50][268/348] loss = 0.863021\n",
      "[0/50][269/348] loss = 1.051419\n",
      "[0/50][270/348] loss = 0.687109\n",
      "[0/50][271/348] loss = 1.040060\n",
      "[0/50][272/348] loss = 0.728692\n",
      "[0/50][273/348] loss = 0.778808\n",
      "[0/50][274/348] loss = 1.083838\n",
      "[0/50][275/348] loss = 0.930679\n",
      "[0/50][276/348] loss = 1.123107\n",
      "[0/50][277/348] loss = 1.136647\n",
      "[0/50][278/348] loss = 0.811882\n",
      "[0/50][279/348] loss = 0.885093\n",
      "[0/50][280/348] loss = 0.934221\n",
      "[0/50][281/348] loss = 0.772202\n",
      "[0/50][282/348] loss = 1.088836\n",
      "[0/50][283/348] loss = 0.713348\n",
      "[0/50][284/348] loss = 1.146482\n",
      "[0/50][285/348] loss = 0.903576\n",
      "[0/50][286/348] loss = 0.907262\n",
      "[0/50][287/348] loss = 0.818058\n",
      "[0/50][288/348] loss = 0.596741\n",
      "[0/50][289/348] loss = 0.736157\n",
      "[0/50][290/348] loss = 0.762501\n",
      "[0/50][291/348] loss = 0.962372\n",
      "[0/50][292/348] loss = 0.717012\n",
      "[0/50][293/348] loss = 0.887688\n",
      "[0/50][294/348] loss = 0.585518\n",
      "[0/50][295/348] loss = 0.566308\n",
      "[0/50][296/348] loss = 0.861028\n",
      "[0/50][297/348] loss = 1.017942\n",
      "[0/50][298/348] loss = 0.971847\n",
      "[0/50][299/348] loss = 0.915383\n",
      "[0/50][300/348] loss = 0.869456\n",
      "[0/50][301/348] loss = 1.074309\n",
      "[0/50][302/348] loss = 0.903606\n",
      "[0/50][303/348] loss = 0.911576\n",
      "[0/50][304/348] loss = 0.773768\n",
      "[0/50][305/348] loss = 1.072828\n",
      "[0/50][306/348] loss = 0.942911\n",
      "[0/50][307/348] loss = 1.104950\n",
      "[0/50][308/348] loss = 0.781063\n",
      "[0/50][309/348] loss = 0.999996\n",
      "[0/50][310/348] loss = 0.820508\n",
      "[0/50][311/348] loss = 0.709692\n",
      "[0/50][312/348] loss = 1.063407\n",
      "[0/50][313/348] loss = 1.042535\n",
      "[0/50][314/348] loss = 0.958167\n",
      "[0/50][315/348] loss = 0.997532\n",
      "[0/50][316/348] loss = 0.904572\n",
      "[0/50][317/348] loss = 0.754687\n",
      "[0/50][318/348] loss = 0.736395\n",
      "[0/50][319/348] loss = 0.838901\n",
      "[0/50][320/348] loss = 0.596283\n",
      "[0/50][321/348] loss = 0.874780\n",
      "[0/50][322/348] loss = 0.619186\n",
      "[0/50][323/348] loss = 0.587055\n",
      "[0/50][324/348] loss = 1.025081\n",
      "[0/50][325/348] loss = 0.583705\n",
      "[0/50][326/348] loss = 1.046448\n",
      "[0/50][327/348] loss = 1.090327\n",
      "[0/50][328/348] loss = 0.813436\n",
      "[0/50][329/348] loss = 0.823326\n",
      "[0/50][330/348] loss = 0.785868\n",
      "[0/50][331/348] loss = 1.323839\n",
      "[0/50][332/348] loss = 0.595104\n",
      "[0/50][333/348] loss = 1.112203\n",
      "[0/50][334/348] loss = 0.560288\n",
      "[0/50][335/348] loss = 0.813099\n",
      "[0/50][336/348] loss = 0.907018\n",
      "[0/50][337/348] loss = 0.810232\n",
      "[0/50][338/348] loss = 0.564968\n",
      "[0/50][339/348] loss = 0.464723\n",
      "[0/50][340/348] loss = 0.818915\n",
      "[0/50][341/348] loss = 0.978906\n",
      "[0/50][342/348] loss = 1.085715\n",
      "[0/50][343/348] loss = 0.805380\n",
      "[0/50][344/348] loss = 0.762015\n",
      "[0/50][345/348] loss = 0.678638\n",
      "[0/50][346/348] loss = 0.902455\n",
      "[0/50][347/348] loss = 0.445751\n",
      "[0/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 77.15 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 62.12 %\n",
      "\n",
      "\n",
      "[1/50][0/348] loss = 0.800851\n",
      "[1/50][1/348] loss = 0.801393\n",
      "[1/50][2/348] loss = 1.003435\n",
      "[1/50][3/348] loss = 0.683824\n",
      "[1/50][4/348] loss = 0.704196\n",
      "[1/50][5/348] loss = 0.610112\n",
      "[1/50][6/348] loss = 0.767307\n",
      "[1/50][7/348] loss = 0.599396\n",
      "[1/50][8/348] loss = 0.497865\n",
      "[1/50][9/348] loss = 0.556625\n",
      "[1/50][10/348] loss = 0.892056\n",
      "[1/50][11/348] loss = 0.569854\n",
      "[1/50][12/348] loss = 0.769255\n",
      "[1/50][13/348] loss = 0.426035\n",
      "[1/50][14/348] loss = 0.666067\n",
      "[1/50][15/348] loss = 0.473823\n",
      "[1/50][16/348] loss = 0.706026\n",
      "[1/50][17/348] loss = 0.515122\n",
      "[1/50][18/348] loss = 0.554871\n",
      "[1/50][19/348] loss = 0.402501\n",
      "[1/50][20/348] loss = 0.500691\n",
      "[1/50][21/348] loss = 0.414573\n",
      "[1/50][22/348] loss = 0.709650\n",
      "[1/50][23/348] loss = 0.377905\n",
      "[1/50][24/348] loss = 0.397114\n",
      "[1/50][25/348] loss = 0.435341\n",
      "[1/50][26/348] loss = 0.626267\n",
      "[1/50][27/348] loss = 0.654941\n",
      "[1/50][28/348] loss = 0.706082\n",
      "[1/50][29/348] loss = 0.757161\n",
      "[1/50][30/348] loss = 0.413704\n",
      "[1/50][31/348] loss = 0.474128\n",
      "[1/50][32/348] loss = 0.925800\n",
      "[1/50][33/348] loss = 0.633820\n",
      "[1/50][34/348] loss = 0.473913\n",
      "[1/50][35/348] loss = 0.743337\n",
      "[1/50][36/348] loss = 0.454886\n",
      "[1/50][37/348] loss = 0.372396\n",
      "[1/50][38/348] loss = 0.594830\n",
      "[1/50][39/348] loss = 0.546570\n",
      "[1/50][40/348] loss = 0.691674\n",
      "[1/50][41/348] loss = 0.686749\n",
      "[1/50][42/348] loss = 0.631878\n",
      "[1/50][43/348] loss = 0.349482\n",
      "[1/50][44/348] loss = 0.623029\n",
      "[1/50][45/348] loss = 0.523570\n",
      "[1/50][46/348] loss = 0.644678\n",
      "[1/50][47/348] loss = 0.784739\n",
      "[1/50][48/348] loss = 0.496308\n",
      "[1/50][49/348] loss = 0.688530\n",
      "[1/50][50/348] loss = 0.619888\n",
      "[1/50][51/348] loss = 0.647661\n",
      "[1/50][52/348] loss = 0.409600\n",
      "[1/50][53/348] loss = 0.500501\n",
      "[1/50][54/348] loss = 0.404917\n",
      "[1/50][55/348] loss = 0.619335\n",
      "[1/50][56/348] loss = 0.552507\n",
      "[1/50][57/348] loss = 0.525455\n",
      "[1/50][58/348] loss = 0.611723\n",
      "[1/50][59/348] loss = 0.494716\n",
      "[1/50][60/348] loss = 0.816737\n",
      "[1/50][61/348] loss = 0.476227\n",
      "[1/50][62/348] loss = 0.556206\n",
      "[1/50][63/348] loss = 0.571492\n",
      "[1/50][64/348] loss = 0.474001\n",
      "[1/50][65/348] loss = 0.398436\n",
      "[1/50][66/348] loss = 0.555507\n",
      "[1/50][67/348] loss = 0.594912\n",
      "[1/50][68/348] loss = 0.432138\n",
      "[1/50][69/348] loss = 0.491938\n",
      "[1/50][70/348] loss = 0.457203\n",
      "[1/50][71/348] loss = 0.482266\n",
      "[1/50][72/348] loss = 0.423370\n",
      "[1/50][73/348] loss = 1.025729\n",
      "[1/50][74/348] loss = 0.271194\n",
      "[1/50][75/348] loss = 0.663880\n",
      "[1/50][76/348] loss = 0.488272\n",
      "[1/50][77/348] loss = 0.323070\n",
      "[1/50][78/348] loss = 0.905193\n",
      "[1/50][79/348] loss = 0.504573\n",
      "[1/50][80/348] loss = 0.378955\n",
      "[1/50][81/348] loss = 0.520432\n",
      "[1/50][82/348] loss = 0.298539\n",
      "[1/50][83/348] loss = 0.375127\n",
      "[1/50][84/348] loss = 0.636508\n",
      "[1/50][85/348] loss = 1.260662\n",
      "[1/50][86/348] loss = 0.503950\n",
      "[1/50][87/348] loss = 0.838142\n",
      "[1/50][88/348] loss = 0.405115\n",
      "[1/50][89/348] loss = 0.442157\n",
      "[1/50][90/348] loss = 0.318189\n",
      "[1/50][91/348] loss = 0.376139\n",
      "[1/50][92/348] loss = 0.584322\n",
      "[1/50][93/348] loss = 0.332937\n",
      "[1/50][94/348] loss = 0.576666\n",
      "[1/50][95/348] loss = 0.749217\n",
      "[1/50][96/348] loss = 0.776831\n",
      "[1/50][97/348] loss = 0.338220\n",
      "[1/50][98/348] loss = 0.461535\n",
      "[1/50][99/348] loss = 0.356166\n",
      "[1/50][100/348] loss = 0.454357\n",
      "[1/50][101/348] loss = 0.500954\n",
      "[1/50][102/348] loss = 0.595944\n",
      "[1/50][103/348] loss = 0.950117\n",
      "[1/50][104/348] loss = 0.634336\n",
      "[1/50][105/348] loss = 0.338733\n",
      "[1/50][106/348] loss = 0.634359\n",
      "[1/50][107/348] loss = 0.563681\n",
      "[1/50][108/348] loss = 0.800988\n",
      "[1/50][109/348] loss = 0.613568\n",
      "[1/50][110/348] loss = 0.762176\n",
      "[1/50][111/348] loss = 0.473244\n",
      "[1/50][112/348] loss = 0.782389\n",
      "[1/50][113/348] loss = 0.583956\n",
      "[1/50][114/348] loss = 0.642040\n",
      "[1/50][115/348] loss = 0.518994\n",
      "[1/50][116/348] loss = 0.734412\n",
      "[1/50][117/348] loss = 0.715849\n",
      "[1/50][118/348] loss = 0.679971\n",
      "[1/50][119/348] loss = 0.333307\n",
      "[1/50][120/348] loss = 0.394501\n",
      "[1/50][121/348] loss = 0.716334\n",
      "[1/50][122/348] loss = 0.446875\n",
      "[1/50][123/348] loss = 0.672716\n",
      "[1/50][124/348] loss = 0.308250\n",
      "[1/50][125/348] loss = 0.414879\n",
      "[1/50][126/348] loss = 0.677548\n",
      "[1/50][127/348] loss = 0.641046\n",
      "[1/50][128/348] loss = 0.385277\n",
      "[1/50][129/348] loss = 0.444456\n",
      "[1/50][130/348] loss = 0.518474\n",
      "[1/50][131/348] loss = 0.454679\n",
      "[1/50][132/348] loss = 0.536554\n",
      "[1/50][133/348] loss = 0.451303\n",
      "[1/50][134/348] loss = 0.347072\n",
      "[1/50][135/348] loss = 0.728514\n",
      "[1/50][136/348] loss = 0.362729\n",
      "[1/50][137/348] loss = 0.451403\n",
      "[1/50][138/348] loss = 0.405915\n",
      "[1/50][139/348] loss = 0.370998\n",
      "[1/50][140/348] loss = 0.351466\n",
      "[1/50][141/348] loss = 0.926304\n",
      "[1/50][142/348] loss = 0.409889\n",
      "[1/50][143/348] loss = 0.563982\n",
      "[1/50][144/348] loss = 0.400956\n",
      "[1/50][145/348] loss = 0.329812\n",
      "[1/50][146/348] loss = 0.548040\n",
      "[1/50][147/348] loss = 1.002198\n",
      "[1/50][148/348] loss = 0.496568\n",
      "[1/50][149/348] loss = 0.438796\n",
      "[1/50][150/348] loss = 0.406715\n",
      "[1/50][151/348] loss = 0.372392\n",
      "[1/50][152/348] loss = 0.391899\n",
      "[1/50][153/348] loss = 0.593053\n",
      "[1/50][154/348] loss = 0.334230\n",
      "[1/50][155/348] loss = 0.302214\n",
      "[1/50][156/348] loss = 0.297802\n",
      "[1/50][157/348] loss = 0.596341\n",
      "[1/50][158/348] loss = 0.493854\n",
      "[1/50][159/348] loss = 0.498281\n",
      "[1/50][160/348] loss = 0.481752\n",
      "[1/50][161/348] loss = 0.450390\n",
      "[1/50][162/348] loss = 0.784582\n",
      "[1/50][163/348] loss = 0.314259\n",
      "[1/50][164/348] loss = 0.419242\n",
      "[1/50][165/348] loss = 0.527473\n",
      "[1/50][166/348] loss = 0.489504\n",
      "[1/50][167/348] loss = 0.459743\n",
      "[1/50][168/348] loss = 0.357545\n",
      "[1/50][169/348] loss = 0.665681\n",
      "[1/50][170/348] loss = 0.313038\n",
      "[1/50][171/348] loss = 0.602630\n",
      "[1/50][172/348] loss = 0.602606\n",
      "[1/50][173/348] loss = 0.369645\n",
      "[1/50][174/348] loss = 0.395138\n",
      "[1/50][175/348] loss = 0.482474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50][176/348] loss = 0.734603\n",
      "[1/50][177/348] loss = 0.472056\n",
      "[1/50][178/348] loss = 0.154414\n",
      "[1/50][179/348] loss = 0.386338\n",
      "[1/50][180/348] loss = 0.330879\n",
      "[1/50][181/348] loss = 0.605994\n",
      "[1/50][182/348] loss = 0.347330\n",
      "[1/50][183/348] loss = 0.334586\n",
      "[1/50][184/348] loss = 0.513511\n",
      "[1/50][185/348] loss = 0.994189\n",
      "[1/50][186/348] loss = 0.444179\n",
      "[1/50][187/348] loss = 0.769594\n",
      "[1/50][188/348] loss = 0.536125\n",
      "[1/50][189/348] loss = 0.473065\n",
      "[1/50][190/348] loss = 0.218396\n",
      "[1/50][191/348] loss = 0.358592\n",
      "[1/50][192/348] loss = 0.229709\n",
      "[1/50][193/348] loss = 0.490615\n",
      "[1/50][194/348] loss = 0.519312\n",
      "[1/50][195/348] loss = 0.358689\n",
      "[1/50][196/348] loss = 0.219078\n",
      "[1/50][197/348] loss = 0.435008\n",
      "[1/50][198/348] loss = 0.376231\n",
      "[1/50][199/348] loss = 0.738716\n",
      "[1/50][200/348] loss = 0.409248\n",
      "[1/50][201/348] loss = 0.649930\n",
      "[1/50][202/348] loss = 0.159860\n",
      "[1/50][203/348] loss = 0.546454\n",
      "[1/50][204/348] loss = 0.487226\n",
      "[1/50][205/348] loss = 0.241960\n",
      "[1/50][206/348] loss = 0.491554\n",
      "[1/50][207/348] loss = 0.255686\n",
      "[1/50][208/348] loss = 0.475530\n",
      "[1/50][209/348] loss = 0.383389\n",
      "[1/50][210/348] loss = 0.543216\n",
      "[1/50][211/348] loss = 0.257322\n",
      "[1/50][212/348] loss = 0.832656\n",
      "[1/50][213/348] loss = 0.999895\n",
      "[1/50][214/348] loss = 0.691366\n",
      "[1/50][215/348] loss = 0.319037\n",
      "[1/50][216/348] loss = 0.427878\n",
      "[1/50][217/348] loss = 0.264465\n",
      "[1/50][218/348] loss = 0.327369\n",
      "[1/50][219/348] loss = 0.759156\n",
      "[1/50][220/348] loss = 0.247142\n",
      "[1/50][221/348] loss = 0.825993\n",
      "[1/50][222/348] loss = 0.591684\n",
      "[1/50][223/348] loss = 0.275480\n",
      "[1/50][224/348] loss = 0.622267\n",
      "[1/50][225/348] loss = 0.269111\n",
      "[1/50][226/348] loss = 0.262893\n",
      "[1/50][227/348] loss = 0.932061\n",
      "[1/50][228/348] loss = 0.435590\n",
      "[1/50][229/348] loss = 0.342127\n",
      "[1/50][230/348] loss = 0.407736\n",
      "[1/50][231/348] loss = 0.590851\n",
      "[1/50][232/348] loss = 0.568513\n",
      "[1/50][233/348] loss = 0.437740\n",
      "[1/50][234/348] loss = 0.487368\n",
      "[1/50][235/348] loss = 0.380521\n",
      "[1/50][236/348] loss = 0.353100\n",
      "[1/50][237/348] loss = 0.462767\n",
      "[1/50][238/348] loss = 0.146894\n",
      "[1/50][239/348] loss = 0.377509\n",
      "[1/50][240/348] loss = 0.527511\n",
      "[1/50][241/348] loss = 0.560778\n",
      "[1/50][242/348] loss = 0.359996\n",
      "[1/50][243/348] loss = 0.262477\n",
      "[1/50][244/348] loss = 0.366047\n",
      "[1/50][245/348] loss = 0.387905\n",
      "[1/50][246/348] loss = 0.312441\n",
      "[1/50][247/348] loss = 0.354038\n",
      "[1/50][248/348] loss = 0.425540\n",
      "[1/50][249/348] loss = 0.224101\n",
      "[1/50][250/348] loss = 0.418028\n",
      "[1/50][251/348] loss = 0.290614\n",
      "[1/50][252/348] loss = 0.398815\n",
      "[1/50][253/348] loss = 0.374533\n",
      "[1/50][254/348] loss = 0.398651\n",
      "[1/50][255/348] loss = 0.675146\n",
      "[1/50][256/348] loss = 0.241290\n",
      "[1/50][257/348] loss = 0.198283\n",
      "[1/50][258/348] loss = 0.281778\n",
      "[1/50][259/348] loss = 0.509809\n",
      "[1/50][260/348] loss = 0.484420\n",
      "[1/50][261/348] loss = 0.279011\n",
      "[1/50][262/348] loss = 0.605686\n",
      "[1/50][263/348] loss = 0.712320\n",
      "[1/50][264/348] loss = 0.265437\n",
      "[1/50][265/348] loss = 0.520436\n",
      "[1/50][266/348] loss = 0.392960\n",
      "[1/50][267/348] loss = 0.617267\n",
      "[1/50][268/348] loss = 0.397619\n",
      "[1/50][269/348] loss = 0.229659\n",
      "[1/50][270/348] loss = 0.261809\n",
      "[1/50][271/348] loss = 0.564760\n",
      "[1/50][272/348] loss = 0.272597\n",
      "[1/50][273/348] loss = 0.494887\n",
      "[1/50][274/348] loss = 0.847640\n",
      "[1/50][275/348] loss = 0.137536\n",
      "[1/50][276/348] loss = 0.127012\n",
      "[1/50][277/348] loss = 0.418749\n",
      "[1/50][278/348] loss = 0.449304\n",
      "[1/50][279/348] loss = 0.507502\n",
      "[1/50][280/348] loss = 0.365603\n",
      "[1/50][281/348] loss = 0.380638\n",
      "[1/50][282/348] loss = 0.365374\n",
      "[1/50][283/348] loss = 0.198710\n",
      "[1/50][284/348] loss = 0.468805\n",
      "[1/50][285/348] loss = 0.225614\n",
      "[1/50][286/348] loss = 0.463259\n",
      "[1/50][287/348] loss = 0.350053\n",
      "[1/50][288/348] loss = 0.402073\n",
      "[1/50][289/348] loss = 0.322385\n",
      "[1/50][290/348] loss = 0.717184\n",
      "[1/50][291/348] loss = 0.247838\n",
      "[1/50][292/348] loss = 0.247985\n",
      "[1/50][293/348] loss = 0.251464\n",
      "[1/50][294/348] loss = 0.434021\n",
      "[1/50][295/348] loss = 0.685282\n",
      "[1/50][296/348] loss = 0.365783\n",
      "[1/50][297/348] loss = 0.371253\n",
      "[1/50][298/348] loss = 0.476096\n",
      "[1/50][299/348] loss = 0.865390\n",
      "[1/50][300/348] loss = 0.587276\n",
      "[1/50][301/348] loss = 0.345377\n",
      "[1/50][302/348] loss = 0.339771\n",
      "[1/50][303/348] loss = 0.288119\n",
      "[1/50][304/348] loss = 0.771044\n",
      "[1/50][305/348] loss = 0.316984\n",
      "[1/50][306/348] loss = 0.437774\n",
      "[1/50][307/348] loss = 0.346120\n",
      "[1/50][308/348] loss = 0.243522\n",
      "[1/50][309/348] loss = 0.416722\n",
      "[1/50][310/348] loss = 0.356844\n",
      "[1/50][311/348] loss = 0.450734\n",
      "[1/50][312/348] loss = 0.228237\n",
      "[1/50][313/348] loss = 0.496661\n",
      "[1/50][314/348] loss = 0.476512\n",
      "[1/50][315/348] loss = 0.482804\n",
      "[1/50][316/348] loss = 0.315047\n",
      "[1/50][317/348] loss = 0.302230\n",
      "[1/50][318/348] loss = 0.655446\n",
      "[1/50][319/348] loss = 0.539707\n",
      "[1/50][320/348] loss = 0.216361\n",
      "[1/50][321/348] loss = 0.463360\n",
      "[1/50][322/348] loss = 0.201011\n",
      "[1/50][323/348] loss = 0.384980\n",
      "[1/50][324/348] loss = 0.295175\n",
      "[1/50][325/348] loss = 0.492381\n",
      "[1/50][326/348] loss = 0.577105\n",
      "[1/50][327/348] loss = 0.180546\n",
      "[1/50][328/348] loss = 0.682051\n",
      "[1/50][329/348] loss = 0.453476\n",
      "[1/50][330/348] loss = 0.328219\n",
      "[1/50][331/348] loss = 0.614019\n",
      "[1/50][332/348] loss = 0.380735\n",
      "[1/50][333/348] loss = 0.323096\n",
      "[1/50][334/348] loss = 0.183351\n",
      "[1/50][335/348] loss = 0.713453\n",
      "[1/50][336/348] loss = 0.370103\n",
      "[1/50][337/348] loss = 0.284352\n",
      "[1/50][338/348] loss = 0.516706\n",
      "[1/50][339/348] loss = 0.433472\n",
      "[1/50][340/348] loss = 0.318405\n",
      "[1/50][341/348] loss = 0.166346\n",
      "[1/50][342/348] loss = 0.231348\n",
      "[1/50][343/348] loss = 0.299035\n",
      "[1/50][344/348] loss = 0.408484\n",
      "[1/50][345/348] loss = 0.505184\n",
      "[1/50][346/348] loss = 0.336362\n",
      "[1/50][347/348] loss = 0.361595\n",
      "[1/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 93.44 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 79.88 %\n",
      "\n",
      "\n",
      "[2/50][0/348] loss = 0.250426\n",
      "[2/50][1/348] loss = 0.224357\n",
      "[2/50][2/348] loss = 0.617579\n",
      "[2/50][3/348] loss = 0.104218\n",
      "[2/50][4/348] loss = 0.440089\n",
      "[2/50][5/348] loss = 0.400102\n",
      "[2/50][6/348] loss = 0.409606\n",
      "[2/50][7/348] loss = 0.135110\n",
      "[2/50][8/348] loss = 0.443419\n",
      "[2/50][9/348] loss = 0.197091\n",
      "[2/50][10/348] loss = 0.338347\n",
      "[2/50][11/348] loss = 0.527395\n",
      "[2/50][12/348] loss = 0.269024\n",
      "[2/50][13/348] loss = 0.480670\n",
      "[2/50][14/348] loss = 0.194338\n",
      "[2/50][15/348] loss = 0.438821\n",
      "[2/50][16/348] loss = 0.207681\n",
      "[2/50][17/348] loss = 0.249855\n",
      "[2/50][18/348] loss = 0.120066\n",
      "[2/50][19/348] loss = 0.104836\n",
      "[2/50][20/348] loss = 0.172558\n",
      "[2/50][21/348] loss = 0.257897\n",
      "[2/50][22/348] loss = 0.313229\n",
      "[2/50][23/348] loss = 0.323322\n",
      "[2/50][24/348] loss = 0.558855\n",
      "[2/50][25/348] loss = 0.538680\n",
      "[2/50][26/348] loss = 0.178346\n",
      "[2/50][27/348] loss = 0.506652\n",
      "[2/50][28/348] loss = 0.229088\n",
      "[2/50][29/348] loss = 0.239031\n",
      "[2/50][30/348] loss = 0.254722\n",
      "[2/50][31/348] loss = 0.340601\n",
      "[2/50][32/348] loss = 0.271141\n",
      "[2/50][33/348] loss = 0.208018\n",
      "[2/50][34/348] loss = 0.535073\n",
      "[2/50][35/348] loss = 0.157229\n",
      "[2/50][36/348] loss = 0.210431\n",
      "[2/50][37/348] loss = 0.361697\n",
      "[2/50][38/348] loss = 0.217291\n",
      "[2/50][39/348] loss = 0.256795\n",
      "[2/50][40/348] loss = 0.191969\n",
      "[2/50][41/348] loss = 0.239264\n",
      "[2/50][42/348] loss = 0.208921\n",
      "[2/50][43/348] loss = 0.236938\n",
      "[2/50][44/348] loss = 0.191482\n",
      "[2/50][45/348] loss = 0.217026\n",
      "[2/50][46/348] loss = 0.154128\n",
      "[2/50][47/348] loss = 0.237245\n",
      "[2/50][48/348] loss = 0.404426\n",
      "[2/50][49/348] loss = 0.294404\n",
      "[2/50][50/348] loss = 0.281275\n",
      "[2/50][51/348] loss = 0.159026\n",
      "[2/50][52/348] loss = 0.325214\n",
      "[2/50][53/348] loss = 0.142850\n",
      "[2/50][54/348] loss = 0.107813\n",
      "[2/50][55/348] loss = 0.271348\n",
      "[2/50][56/348] loss = 0.212766\n",
      "[2/50][57/348] loss = 0.135024\n",
      "[2/50][58/348] loss = 0.380452\n",
      "[2/50][59/348] loss = 0.394574\n",
      "[2/50][60/348] loss = 0.246033\n",
      "[2/50][61/348] loss = 0.220537\n",
      "[2/50][62/348] loss = 0.342050\n",
      "[2/50][63/348] loss = 0.206146\n",
      "[2/50][64/348] loss = 0.254283\n",
      "[2/50][65/348] loss = 0.420259\n",
      "[2/50][66/348] loss = 0.368739\n",
      "[2/50][67/348] loss = 0.421189\n",
      "[2/50][68/348] loss = 0.280196\n",
      "[2/50][69/348] loss = 0.216483\n",
      "[2/50][70/348] loss = 0.234165\n",
      "[2/50][71/348] loss = 0.169858\n",
      "[2/50][72/348] loss = 0.432887\n",
      "[2/50][73/348] loss = 0.116744\n",
      "[2/50][74/348] loss = 0.793379\n",
      "[2/50][75/348] loss = 0.584927\n",
      "[2/50][76/348] loss = 0.288244\n",
      "[2/50][77/348] loss = 0.373285\n",
      "[2/50][78/348] loss = 0.380027\n",
      "[2/50][79/348] loss = 0.193508\n",
      "[2/50][80/348] loss = 0.211687\n",
      "[2/50][81/348] loss = 0.294458\n",
      "[2/50][82/348] loss = 0.334591\n",
      "[2/50][83/348] loss = 0.260507\n",
      "[2/50][84/348] loss = 0.241206\n",
      "[2/50][85/348] loss = 0.333203\n",
      "[2/50][86/348] loss = 0.340377\n",
      "[2/50][87/348] loss = 0.218429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/50][88/348] loss = 0.143684\n",
      "[2/50][89/348] loss = 0.123254\n",
      "[2/50][90/348] loss = 0.131277\n",
      "[2/50][91/348] loss = 0.562762\n",
      "[2/50][92/348] loss = 0.259545\n",
      "[2/50][93/348] loss = 0.288579\n",
      "[2/50][94/348] loss = 0.254491\n",
      "[2/50][95/348] loss = 0.169820\n",
      "[2/50][96/348] loss = 0.270001\n",
      "[2/50][97/348] loss = 0.210294\n",
      "[2/50][98/348] loss = 0.300122\n",
      "[2/50][99/348] loss = 0.382144\n",
      "[2/50][100/348] loss = 0.241360\n",
      "[2/50][101/348] loss = 0.132424\n",
      "[2/50][102/348] loss = 0.233596\n",
      "[2/50][103/348] loss = 0.236835\n",
      "[2/50][104/348] loss = 0.276956\n",
      "[2/50][105/348] loss = 0.167178\n",
      "[2/50][106/348] loss = 0.287888\n",
      "[2/50][107/348] loss = 0.231881\n",
      "[2/50][108/348] loss = 0.385026\n",
      "[2/50][109/348] loss = 0.109140\n",
      "[2/50][110/348] loss = 0.422172\n",
      "[2/50][111/348] loss = 0.497567\n",
      "[2/50][112/348] loss = 0.247833\n",
      "[2/50][113/348] loss = 0.374779\n",
      "[2/50][114/348] loss = 0.370563\n",
      "[2/50][115/348] loss = 0.374974\n",
      "[2/50][116/348] loss = 0.196394\n",
      "[2/50][117/348] loss = 0.206517\n",
      "[2/50][118/348] loss = 0.204667\n",
      "[2/50][119/348] loss = 0.451584\n",
      "[2/50][120/348] loss = 0.202839\n",
      "[2/50][121/348] loss = 0.332750\n",
      "[2/50][122/348] loss = 0.422165\n",
      "[2/50][123/348] loss = 0.335576\n",
      "[2/50][124/348] loss = 0.380793\n",
      "[2/50][125/348] loss = 0.331471\n",
      "[2/50][126/348] loss = 0.444931\n",
      "[2/50][127/348] loss = 0.167517\n",
      "[2/50][128/348] loss = 0.393476\n",
      "[2/50][129/348] loss = 0.645841\n",
      "[2/50][130/348] loss = 0.213475\n",
      "[2/50][131/348] loss = 0.220034\n",
      "[2/50][132/348] loss = 0.448584\n",
      "[2/50][133/348] loss = 0.329574\n",
      "[2/50][134/348] loss = 0.309563\n",
      "[2/50][135/348] loss = 0.254414\n",
      "[2/50][136/348] loss = 0.191037\n",
      "[2/50][137/348] loss = 0.212409\n",
      "[2/50][138/348] loss = 0.355231\n",
      "[2/50][139/348] loss = 0.600370\n",
      "[2/50][140/348] loss = 0.303623\n",
      "[2/50][141/348] loss = 0.279693\n",
      "[2/50][142/348] loss = 0.378138\n",
      "[2/50][143/348] loss = 0.293005\n",
      "[2/50][144/348] loss = 0.432157\n",
      "[2/50][145/348] loss = 0.396190\n",
      "[2/50][146/348] loss = 0.211891\n",
      "[2/50][147/348] loss = 0.422277\n",
      "[2/50][148/348] loss = 0.442267\n",
      "[2/50][149/348] loss = 0.299379\n",
      "[2/50][150/348] loss = 0.541031\n",
      "[2/50][151/348] loss = 0.396026\n",
      "[2/50][152/348] loss = 0.145418\n",
      "[2/50][153/348] loss = 0.514669\n",
      "[2/50][154/348] loss = 0.256553\n",
      "[2/50][155/348] loss = 0.517572\n",
      "[2/50][156/348] loss = 0.386046\n",
      "[2/50][157/348] loss = 0.142378\n",
      "[2/50][158/348] loss = 0.234801\n",
      "[2/50][159/348] loss = 0.358823\n",
      "[2/50][160/348] loss = 0.167824\n",
      "[2/50][161/348] loss = 0.172002\n",
      "[2/50][162/348] loss = 0.540186\n",
      "[2/50][163/348] loss = 0.426343\n",
      "[2/50][164/348] loss = 0.293833\n",
      "[2/50][165/348] loss = 0.410578\n",
      "[2/50][166/348] loss = 0.497506\n",
      "[2/50][167/348] loss = 0.270122\n",
      "[2/50][168/348] loss = 0.289706\n",
      "[2/50][169/348] loss = 0.589724\n",
      "[2/50][170/348] loss = 0.135468\n",
      "[2/50][171/348] loss = 0.592953\n",
      "[2/50][172/348] loss = 0.379620\n",
      "[2/50][173/348] loss = 0.294745\n",
      "[2/50][174/348] loss = 0.822136\n",
      "[2/50][175/348] loss = 0.151816\n",
      "[2/50][176/348] loss = 0.094617\n",
      "[2/50][177/348] loss = 0.326249\n",
      "[2/50][178/348] loss = 0.345845\n",
      "[2/50][179/348] loss = 0.091344\n",
      "[2/50][180/348] loss = 0.158687\n",
      "[2/50][181/348] loss = 0.488164\n",
      "[2/50][182/348] loss = 0.267360\n",
      "[2/50][183/348] loss = 0.344749\n",
      "[2/50][184/348] loss = 0.398993\n",
      "[2/50][185/348] loss = 0.259986\n",
      "[2/50][186/348] loss = 0.194603\n",
      "[2/50][187/348] loss = 0.117836\n",
      "[2/50][188/348] loss = 0.559530\n",
      "[2/50][189/348] loss = 0.331998\n",
      "[2/50][190/348] loss = 0.445936\n",
      "[2/50][191/348] loss = 0.495130\n",
      "[2/50][192/348] loss = 0.207303\n",
      "[2/50][193/348] loss = 0.261401\n",
      "[2/50][194/348] loss = 0.245844\n",
      "[2/50][195/348] loss = 0.283818\n",
      "[2/50][196/348] loss = 0.221758\n",
      "[2/50][197/348] loss = 0.251081\n",
      "[2/50][198/348] loss = 0.171386\n",
      "[2/50][199/348] loss = 0.241735\n",
      "[2/50][200/348] loss = 0.180965\n",
      "[2/50][201/348] loss = 0.130473\n",
      "[2/50][202/348] loss = 0.171415\n",
      "[2/50][203/348] loss = 0.074116\n",
      "[2/50][204/348] loss = 0.304531\n",
      "[2/50][205/348] loss = 0.360188\n",
      "[2/50][206/348] loss = 0.403681\n",
      "[2/50][207/348] loss = 0.562794\n",
      "[2/50][208/348] loss = 0.583556\n",
      "[2/50][209/348] loss = 0.138416\n",
      "[2/50][210/348] loss = 0.244448\n",
      "[2/50][211/348] loss = 0.142403\n",
      "[2/50][212/348] loss = 0.601426\n",
      "[2/50][213/348] loss = 0.149546\n",
      "[2/50][214/348] loss = 0.412093\n",
      "[2/50][215/348] loss = 0.241716\n",
      "[2/50][216/348] loss = 0.232934\n",
      "[2/50][217/348] loss = 0.121824\n",
      "[2/50][218/348] loss = 0.383074\n",
      "[2/50][219/348] loss = 0.375717\n",
      "[2/50][220/348] loss = 0.453941\n",
      "[2/50][221/348] loss = 0.382995\n",
      "[2/50][222/348] loss = 0.557448\n",
      "[2/50][223/348] loss = 0.377456\n",
      "[2/50][224/348] loss = 0.286449\n",
      "[2/50][225/348] loss = 0.462723\n",
      "[2/50][226/348] loss = 0.242797\n",
      "[2/50][227/348] loss = 0.476061\n",
      "[2/50][228/348] loss = 0.358048\n",
      "[2/50][229/348] loss = 0.399800\n",
      "[2/50][230/348] loss = 0.312216\n",
      "[2/50][231/348] loss = 0.079460\n",
      "[2/50][232/348] loss = 0.467383\n",
      "[2/50][233/348] loss = 0.199995\n",
      "[2/50][234/348] loss = 0.285169\n",
      "[2/50][235/348] loss = 0.416618\n",
      "[2/50][236/348] loss = 0.098396\n",
      "[2/50][237/348] loss = 0.322915\n",
      "[2/50][238/348] loss = 0.238303\n",
      "[2/50][239/348] loss = 0.508252\n",
      "[2/50][240/348] loss = 0.216829\n",
      "[2/50][241/348] loss = 0.243056\n",
      "[2/50][242/348] loss = 0.399587\n",
      "[2/50][243/348] loss = 0.110013\n",
      "[2/50][244/348] loss = 0.402244\n",
      "[2/50][245/348] loss = 0.342145\n",
      "[2/50][246/348] loss = 0.226565\n",
      "[2/50][247/348] loss = 0.418583\n",
      "[2/50][248/348] loss = 0.148888\n",
      "[2/50][249/348] loss = 0.124178\n",
      "[2/50][250/348] loss = 0.236234\n",
      "[2/50][251/348] loss = 0.276879\n",
      "[2/50][252/348] loss = 0.418573\n",
      "[2/50][253/348] loss = 0.478927\n",
      "[2/50][254/348] loss = 0.142245\n",
      "[2/50][255/348] loss = 0.185593\n",
      "[2/50][256/348] loss = 0.133158\n",
      "[2/50][257/348] loss = 0.326127\n",
      "[2/50][258/348] loss = 0.564109\n",
      "[2/50][259/348] loss = 0.231999\n",
      "[2/50][260/348] loss = 0.256980\n",
      "[2/50][261/348] loss = 0.143698\n",
      "[2/50][262/348] loss = 0.310321\n",
      "[2/50][263/348] loss = 0.191028\n",
      "[2/50][264/348] loss = 0.226714\n",
      "[2/50][265/348] loss = 0.121369\n",
      "[2/50][266/348] loss = 0.259047\n",
      "[2/50][267/348] loss = 0.674445\n",
      "[2/50][268/348] loss = 0.369684\n",
      "[2/50][269/348] loss = 0.254943\n",
      "[2/50][270/348] loss = 0.424796\n",
      "[2/50][271/348] loss = 0.317592\n",
      "[2/50][272/348] loss = 0.416780\n",
      "[2/50][273/348] loss = 0.157125\n",
      "[2/50][274/348] loss = 0.361113\n",
      "[2/50][275/348] loss = 0.302910\n",
      "[2/50][276/348] loss = 0.175391\n",
      "[2/50][277/348] loss = 0.245096\n",
      "[2/50][278/348] loss = 0.258401\n",
      "[2/50][279/348] loss = 0.397942\n",
      "[2/50][280/348] loss = 0.231223\n",
      "[2/50][281/348] loss = 0.180131\n",
      "[2/50][282/348] loss = 0.468378\n",
      "[2/50][283/348] loss = 0.307060\n",
      "[2/50][284/348] loss = 0.144438\n",
      "[2/50][285/348] loss = 0.242051\n",
      "[2/50][286/348] loss = 0.388380\n",
      "[2/50][287/348] loss = 0.612418\n",
      "[2/50][288/348] loss = 0.105376\n",
      "[2/50][289/348] loss = 0.545680\n",
      "[2/50][290/348] loss = 0.272429\n",
      "[2/50][291/348] loss = 0.307938\n",
      "[2/50][292/348] loss = 0.386586\n",
      "[2/50][293/348] loss = 0.322291\n",
      "[2/50][294/348] loss = 0.105455\n",
      "[2/50][295/348] loss = 0.328251\n",
      "[2/50][296/348] loss = 0.189563\n",
      "[2/50][297/348] loss = 0.197533\n",
      "[2/50][298/348] loss = 0.293708\n",
      "[2/50][299/348] loss = 0.359729\n",
      "[2/50][300/348] loss = 0.185794\n",
      "[2/50][301/348] loss = 0.399328\n",
      "[2/50][302/348] loss = 0.121032\n",
      "[2/50][303/348] loss = 0.222998\n",
      "[2/50][304/348] loss = 0.239369\n",
      "[2/50][305/348] loss = 0.384315\n",
      "[2/50][306/348] loss = 0.262502\n",
      "[2/50][307/348] loss = 0.116530\n",
      "[2/50][308/348] loss = 0.281464\n",
      "[2/50][309/348] loss = 0.117011\n",
      "[2/50][310/348] loss = 0.201599\n",
      "[2/50][311/348] loss = 0.092427\n",
      "[2/50][312/348] loss = 0.322385\n",
      "[2/50][313/348] loss = 0.421627\n",
      "[2/50][314/348] loss = 0.112378\n",
      "[2/50][315/348] loss = 0.227215\n",
      "[2/50][316/348] loss = 0.263181\n",
      "[2/50][317/348] loss = 0.431001\n",
      "[2/50][318/348] loss = 0.314536\n",
      "[2/50][319/348] loss = 0.430614\n",
      "[2/50][320/348] loss = 0.473341\n",
      "[2/50][321/348] loss = 0.334630\n",
      "[2/50][322/348] loss = 0.266753\n",
      "[2/50][323/348] loss = 0.167684\n",
      "[2/50][324/348] loss = 0.261986\n",
      "[2/50][325/348] loss = 0.342354\n",
      "[2/50][326/348] loss = 0.321522\n",
      "[2/50][327/348] loss = 0.229365\n",
      "[2/50][328/348] loss = 0.258339\n",
      "[2/50][329/348] loss = 0.380182\n",
      "[2/50][330/348] loss = 0.263813\n",
      "[2/50][331/348] loss = 0.388825\n",
      "[2/50][332/348] loss = 0.048220\n",
      "[2/50][333/348] loss = 0.256696\n",
      "[2/50][334/348] loss = 0.450451\n",
      "[2/50][335/348] loss = 0.176292\n",
      "[2/50][336/348] loss = 0.235365\n",
      "[2/50][337/348] loss = 0.352458\n",
      "[2/50][338/348] loss = 0.109430\n",
      "[2/50][339/348] loss = 0.067951\n",
      "[2/50][340/348] loss = 0.105198\n",
      "[2/50][341/348] loss = 0.411393\n",
      "[2/50][342/348] loss = 0.450998\n",
      "[2/50][343/348] loss = 0.252907\n",
      "[2/50][344/348] loss = 0.673981\n",
      "[2/50][345/348] loss = 0.373211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/50][346/348] loss = 0.385855\n",
      "[2/50][347/348] loss = 0.161369\n",
      "[2/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 95.72 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 83.50 %\n",
      "\n",
      "\n",
      "[3/50][0/348] loss = 0.159700\n",
      "[3/50][1/348] loss = 0.203337\n",
      "[3/50][2/348] loss = 0.097027\n",
      "[3/50][3/348] loss = 0.320974\n",
      "[3/50][4/348] loss = 0.248194\n",
      "[3/50][5/348] loss = 0.143427\n",
      "[3/50][6/348] loss = 0.070934\n",
      "[3/50][7/348] loss = 0.175883\n",
      "[3/50][8/348] loss = 0.176306\n",
      "[3/50][9/348] loss = 0.253252\n",
      "[3/50][10/348] loss = 0.298453\n",
      "[3/50][11/348] loss = 0.319702\n",
      "[3/50][12/348] loss = 0.298966\n",
      "[3/50][13/348] loss = 0.208458\n",
      "[3/50][14/348] loss = 0.305464\n",
      "[3/50][15/348] loss = 0.120906\n",
      "[3/50][16/348] loss = 0.287404\n",
      "[3/50][17/348] loss = 0.173400\n",
      "[3/50][18/348] loss = 0.146926\n",
      "[3/50][19/348] loss = 0.252341\n",
      "[3/50][20/348] loss = 0.229045\n",
      "[3/50][21/348] loss = 0.070559\n",
      "[3/50][22/348] loss = 0.075126\n",
      "[3/50][23/348] loss = 0.188714\n",
      "[3/50][24/348] loss = 0.217723\n",
      "[3/50][25/348] loss = 0.228501\n",
      "[3/50][26/348] loss = 0.151244\n",
      "[3/50][27/348] loss = 0.343323\n",
      "[3/50][28/348] loss = 0.366488\n",
      "[3/50][29/348] loss = 0.231560\n",
      "[3/50][30/348] loss = 0.098528\n",
      "[3/50][31/348] loss = 0.186734\n",
      "[3/50][32/348] loss = 0.385276\n",
      "[3/50][33/348] loss = 0.206474\n",
      "[3/50][34/348] loss = 0.124107\n",
      "[3/50][35/348] loss = 0.148351\n",
      "[3/50][36/348] loss = 0.078174\n",
      "[3/50][37/348] loss = 0.395557\n",
      "[3/50][38/348] loss = 0.222100\n",
      "[3/50][39/348] loss = 0.270332\n",
      "[3/50][40/348] loss = 0.182716\n",
      "[3/50][41/348] loss = 0.108100\n",
      "[3/50][42/348] loss = 0.492390\n",
      "[3/50][43/348] loss = 0.032948\n",
      "[3/50][44/348] loss = 0.146877\n",
      "[3/50][45/348] loss = 0.196221\n",
      "[3/50][46/348] loss = 0.292090\n",
      "[3/50][47/348] loss = 0.383154\n",
      "[3/50][48/348] loss = 0.106376\n",
      "[3/50][49/348] loss = 0.231928\n",
      "[3/50][50/348] loss = 0.185973\n",
      "[3/50][51/348] loss = 0.275035\n",
      "[3/50][52/348] loss = 0.144396\n",
      "[3/50][53/348] loss = 0.210884\n",
      "[3/50][54/348] loss = 0.164102\n",
      "[3/50][55/348] loss = 0.057042\n",
      "[3/50][56/348] loss = 0.308767\n",
      "[3/50][57/348] loss = 0.194122\n",
      "[3/50][58/348] loss = 0.311171\n",
      "[3/50][59/348] loss = 0.108810\n",
      "[3/50][60/348] loss = 0.202754\n",
      "[3/50][61/348] loss = 0.129250\n",
      "[3/50][62/348] loss = 0.242191\n",
      "[3/50][63/348] loss = 0.085496\n",
      "[3/50][64/348] loss = 0.121108\n",
      "[3/50][65/348] loss = 0.131707\n",
      "[3/50][66/348] loss = 0.272716\n",
      "[3/50][67/348] loss = 0.089543\n",
      "[3/50][68/348] loss = 0.115645\n",
      "[3/50][69/348] loss = 0.096032\n",
      "[3/50][70/348] loss = 0.179186\n",
      "[3/50][71/348] loss = 0.168922\n",
      "[3/50][72/348] loss = 0.306374\n",
      "[3/50][73/348] loss = 0.075378\n",
      "[3/50][74/348] loss = 0.127447\n",
      "[3/50][75/348] loss = 0.116351\n",
      "[3/50][76/348] loss = 0.134583\n",
      "[3/50][77/348] loss = 0.165134\n",
      "[3/50][78/348] loss = 0.302200\n",
      "[3/50][79/348] loss = 0.123841\n",
      "[3/50][80/348] loss = 0.088861\n",
      "[3/50][81/348] loss = 0.133323\n",
      "[3/50][82/348] loss = 0.191515\n",
      "[3/50][83/348] loss = 0.103812\n",
      "[3/50][84/348] loss = 0.356847\n",
      "[3/50][85/348] loss = 0.143657\n",
      "[3/50][86/348] loss = 0.051762\n",
      "[3/50][87/348] loss = 0.063040\n",
      "[3/50][88/348] loss = 0.098440\n",
      "[3/50][89/348] loss = 0.077387\n",
      "[3/50][90/348] loss = 0.148304\n",
      "[3/50][91/348] loss = 0.155961\n",
      "[3/50][92/348] loss = 0.105961\n",
      "[3/50][93/348] loss = 0.166384\n",
      "[3/50][94/348] loss = 0.206763\n",
      "[3/50][95/348] loss = 0.258010\n",
      "[3/50][96/348] loss = 0.140658\n",
      "[3/50][97/348] loss = 0.169197\n",
      "[3/50][98/348] loss = 0.171854\n",
      "[3/50][99/348] loss = 0.181490\n",
      "[3/50][100/348] loss = 0.055075\n",
      "[3/50][101/348] loss = 0.250656\n",
      "[3/50][102/348] loss = 0.143484\n",
      "[3/50][103/348] loss = 0.118207\n",
      "[3/50][104/348] loss = 0.138993\n",
      "[3/50][105/348] loss = 0.207352\n",
      "[3/50][106/348] loss = 0.068872\n",
      "[3/50][107/348] loss = 0.391168\n",
      "[3/50][108/348] loss = 0.395416\n",
      "[3/50][109/348] loss = 0.305315\n",
      "[3/50][110/348] loss = 0.137905\n",
      "[3/50][111/348] loss = 0.049474\n",
      "[3/50][112/348] loss = 0.251212\n",
      "[3/50][113/348] loss = 0.201495\n",
      "[3/50][114/348] loss = 0.190426\n",
      "[3/50][115/348] loss = 0.069581\n",
      "[3/50][116/348] loss = 0.107790\n",
      "[3/50][117/348] loss = 0.143605\n",
      "[3/50][118/348] loss = 0.107508\n",
      "[3/50][119/348] loss = 0.144524\n",
      "[3/50][120/348] loss = 0.225551\n",
      "[3/50][121/348] loss = 0.150260\n",
      "[3/50][122/348] loss = 0.183764\n",
      "[3/50][123/348] loss = 0.144682\n",
      "[3/50][124/348] loss = 0.106065\n",
      "[3/50][125/348] loss = 0.181738\n",
      "[3/50][126/348] loss = 0.101046\n",
      "[3/50][127/348] loss = 0.069754\n",
      "[3/50][128/348] loss = 0.259726\n",
      "[3/50][129/348] loss = 0.309711\n",
      "[3/50][130/348] loss = 0.234373\n",
      "[3/50][131/348] loss = 0.232008\n",
      "[3/50][132/348] loss = 0.408424\n",
      "[3/50][133/348] loss = 0.279626\n",
      "[3/50][134/348] loss = 0.147586\n",
      "[3/50][135/348] loss = 0.164098\n",
      "[3/50][136/348] loss = 0.304339\n",
      "[3/50][137/348] loss = 0.107089\n",
      "[3/50][138/348] loss = 0.114741\n",
      "[3/50][139/348] loss = 0.302312\n",
      "[3/50][140/348] loss = 0.047771\n",
      "[3/50][141/348] loss = 0.045927\n",
      "[3/50][142/348] loss = 0.177653\n",
      "[3/50][143/348] loss = 0.353505\n",
      "[3/50][144/348] loss = 0.080513\n",
      "[3/50][145/348] loss = 0.512531\n",
      "[3/50][146/348] loss = 0.121975\n",
      "[3/50][147/348] loss = 0.146971\n",
      "[3/50][148/348] loss = 0.270630\n",
      "[3/50][149/348] loss = 0.217483\n",
      "[3/50][150/348] loss = 0.175383\n",
      "[3/50][151/348] loss = 0.065745\n",
      "[3/50][152/348] loss = 0.124453\n",
      "[3/50][153/348] loss = 0.091059\n",
      "[3/50][154/348] loss = 0.062776\n",
      "[3/50][155/348] loss = 0.255991\n",
      "[3/50][156/348] loss = 0.250775\n",
      "[3/50][157/348] loss = 0.311593\n",
      "[3/50][158/348] loss = 0.086884\n",
      "[3/50][159/348] loss = 0.057937\n",
      "[3/50][160/348] loss = 0.219166\n",
      "[3/50][161/348] loss = 0.238838\n",
      "[3/50][162/348] loss = 0.157512\n",
      "[3/50][163/348] loss = 0.084997\n",
      "[3/50][164/348] loss = 0.124306\n",
      "[3/50][165/348] loss = 0.487287\n",
      "[3/50][166/348] loss = 0.390329\n",
      "[3/50][167/348] loss = 0.362824\n",
      "[3/50][168/348] loss = 0.299823\n",
      "[3/50][169/348] loss = 0.124751\n",
      "[3/50][170/348] loss = 0.253719\n",
      "[3/50][171/348] loss = 0.102950\n",
      "[3/50][172/348] loss = 0.128703\n",
      "[3/50][173/348] loss = 0.173584\n",
      "[3/50][174/348] loss = 0.317505\n",
      "[3/50][175/348] loss = 0.261401\n",
      "[3/50][176/348] loss = 0.174695\n",
      "[3/50][177/348] loss = 0.065339\n",
      "[3/50][178/348] loss = 0.120061\n",
      "[3/50][179/348] loss = 0.183090\n",
      "[3/50][180/348] loss = 0.246034\n",
      "[3/50][181/348] loss = 0.157814\n",
      "[3/50][182/348] loss = 0.163837\n",
      "[3/50][183/348] loss = 0.162364\n",
      "[3/50][184/348] loss = 0.251450\n",
      "[3/50][185/348] loss = 0.428071\n",
      "[3/50][186/348] loss = 0.137460\n",
      "[3/50][187/348] loss = 0.179756\n",
      "[3/50][188/348] loss = 0.097600\n",
      "[3/50][189/348] loss = 0.280844\n",
      "[3/50][190/348] loss = 0.151503\n",
      "[3/50][191/348] loss = 0.193089\n",
      "[3/50][192/348] loss = 0.176168\n",
      "[3/50][193/348] loss = 0.165276\n",
      "[3/50][194/348] loss = 0.149768\n",
      "[3/50][195/348] loss = 0.086803\n",
      "[3/50][196/348] loss = 0.052998\n",
      "[3/50][197/348] loss = 0.260977\n",
      "[3/50][198/348] loss = 0.115890\n",
      "[3/50][199/348] loss = 0.247533\n",
      "[3/50][200/348] loss = 0.050252\n",
      "[3/50][201/348] loss = 0.105809\n",
      "[3/50][202/348] loss = 0.217800\n",
      "[3/50][203/348] loss = 0.049174\n",
      "[3/50][204/348] loss = 0.189652\n",
      "[3/50][205/348] loss = 0.227902\n",
      "[3/50][206/348] loss = 0.135466\n",
      "[3/50][207/348] loss = 0.326835\n",
      "[3/50][208/348] loss = 0.157276\n",
      "[3/50][209/348] loss = 0.117009\n",
      "[3/50][210/348] loss = 0.050959\n",
      "[3/50][211/348] loss = 0.059750\n",
      "[3/50][212/348] loss = 0.077350\n",
      "[3/50][213/348] loss = 0.452775\n",
      "[3/50][214/348] loss = 0.099736\n",
      "[3/50][215/348] loss = 0.154029\n",
      "[3/50][216/348] loss = 0.120120\n",
      "[3/50][217/348] loss = 0.146963\n",
      "[3/50][218/348] loss = 0.146023\n",
      "[3/50][219/348] loss = 0.103839\n",
      "[3/50][220/348] loss = 0.134519\n",
      "[3/50][221/348] loss = 0.107691\n",
      "[3/50][222/348] loss = 0.188860\n",
      "[3/50][223/348] loss = 0.305572\n",
      "[3/50][224/348] loss = 0.027318\n",
      "[3/50][225/348] loss = 0.267133\n",
      "[3/50][226/348] loss = 0.096548\n",
      "[3/50][227/348] loss = 0.144932\n",
      "[3/50][228/348] loss = 0.136618\n",
      "[3/50][229/348] loss = 0.056110\n",
      "[3/50][230/348] loss = 0.183582\n",
      "[3/50][231/348] loss = 0.050808\n",
      "[3/50][232/348] loss = 0.113421\n",
      "[3/50][233/348] loss = 0.325761\n",
      "[3/50][234/348] loss = 0.150456\n",
      "[3/50][235/348] loss = 0.143619\n",
      "[3/50][236/348] loss = 0.151227\n",
      "[3/50][237/348] loss = 0.124120\n",
      "[3/50][238/348] loss = 0.254000\n",
      "[3/50][239/348] loss = 0.116296\n",
      "[3/50][240/348] loss = 0.075866\n",
      "[3/50][241/348] loss = 0.077854\n",
      "[3/50][242/348] loss = 0.093582\n",
      "[3/50][243/348] loss = 0.141986\n",
      "[3/50][244/348] loss = 0.159135\n",
      "[3/50][245/348] loss = 0.065001\n",
      "[3/50][246/348] loss = 0.261946\n",
      "[3/50][247/348] loss = 0.156225\n",
      "[3/50][248/348] loss = 0.123870\n",
      "[3/50][249/348] loss = 0.086219\n",
      "[3/50][250/348] loss = 0.159401\n",
      "[3/50][251/348] loss = 0.518495\n",
      "[3/50][252/348] loss = 0.370714\n",
      "[3/50][253/348] loss = 0.280426\n",
      "[3/50][254/348] loss = 0.266304\n",
      "[3/50][255/348] loss = 0.250055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/50][256/348] loss = 0.122270\n",
      "[3/50][257/348] loss = 0.156222\n",
      "[3/50][258/348] loss = 0.171060\n",
      "[3/50][259/348] loss = 0.421910\n",
      "[3/50][260/348] loss = 0.196088\n",
      "[3/50][261/348] loss = 0.321036\n",
      "[3/50][262/348] loss = 0.119613\n",
      "[3/50][263/348] loss = 0.159725\n",
      "[3/50][264/348] loss = 0.363452\n",
      "[3/50][265/348] loss = 0.125471\n",
      "[3/50][266/348] loss = 0.040421\n",
      "[3/50][267/348] loss = 0.125994\n",
      "[3/50][268/348] loss = 0.167488\n",
      "[3/50][269/348] loss = 0.314458\n",
      "[3/50][270/348] loss = 0.180180\n",
      "[3/50][271/348] loss = 0.132160\n",
      "[3/50][272/348] loss = 0.035607\n",
      "[3/50][273/348] loss = 0.214710\n",
      "[3/50][274/348] loss = 0.066033\n",
      "[3/50][275/348] loss = 0.122631\n",
      "[3/50][276/348] loss = 0.483664\n",
      "[3/50][277/348] loss = 0.173421\n",
      "[3/50][278/348] loss = 0.121838\n",
      "[3/50][279/348] loss = 0.069104\n",
      "[3/50][280/348] loss = 0.229877\n",
      "[3/50][281/348] loss = 0.263160\n",
      "[3/50][282/348] loss = 0.360480\n",
      "[3/50][283/348] loss = 0.270337\n",
      "[3/50][284/348] loss = 0.133991\n",
      "[3/50][285/348] loss = 0.318469\n",
      "[3/50][286/348] loss = 0.144661\n",
      "[3/50][287/348] loss = 0.170590\n",
      "[3/50][288/348] loss = 0.205701\n",
      "[3/50][289/348] loss = 0.211023\n",
      "[3/50][290/348] loss = 0.121412\n",
      "[3/50][291/348] loss = 0.108841\n",
      "[3/50][292/348] loss = 0.319694\n",
      "[3/50][293/348] loss = 0.085130\n",
      "[3/50][294/348] loss = 0.223337\n",
      "[3/50][295/348] loss = 0.141351\n",
      "[3/50][296/348] loss = 0.216007\n",
      "[3/50][297/348] loss = 0.309021\n",
      "[3/50][298/348] loss = 0.214334\n",
      "[3/50][299/348] loss = 0.107046\n",
      "[3/50][300/348] loss = 0.051680\n",
      "[3/50][301/348] loss = 0.171755\n",
      "[3/50][302/348] loss = 0.779506\n",
      "[3/50][303/348] loss = 0.191490\n",
      "[3/50][304/348] loss = 0.115769\n",
      "[3/50][305/348] loss = 0.168295\n",
      "[3/50][306/348] loss = 0.220477\n",
      "[3/50][307/348] loss = 0.097905\n",
      "[3/50][308/348] loss = 0.175890\n",
      "[3/50][309/348] loss = 0.123391\n",
      "[3/50][310/348] loss = 0.068938\n",
      "[3/50][311/348] loss = 0.210533\n",
      "[3/50][312/348] loss = 0.218357\n",
      "[3/50][313/348] loss = 0.163349\n",
      "[3/50][314/348] loss = 0.278144\n",
      "[3/50][315/348] loss = 0.231696\n",
      "[3/50][316/348] loss = 0.247552\n",
      "[3/50][317/348] loss = 0.103726\n",
      "[3/50][318/348] loss = 0.294940\n",
      "[3/50][319/348] loss = 0.159699\n",
      "[3/50][320/348] loss = 0.213408\n",
      "[3/50][321/348] loss = 0.123667\n",
      "[3/50][322/348] loss = 0.272959\n",
      "[3/50][323/348] loss = 0.052407\n",
      "[3/50][324/348] loss = 0.160015\n",
      "[3/50][325/348] loss = 0.176501\n",
      "[3/50][326/348] loss = 0.243752\n",
      "[3/50][327/348] loss = 0.357317\n",
      "[3/50][328/348] loss = 0.113980\n",
      "[3/50][329/348] loss = 0.134483\n",
      "[3/50][330/348] loss = 0.083313\n",
      "[3/50][331/348] loss = 0.095596\n",
      "[3/50][332/348] loss = 0.081289\n",
      "[3/50][333/348] loss = 0.231972\n",
      "[3/50][334/348] loss = 0.132210\n",
      "[3/50][335/348] loss = 0.120263\n",
      "[3/50][336/348] loss = 0.122528\n",
      "[3/50][337/348] loss = 0.379194\n",
      "[3/50][338/348] loss = 0.045604\n",
      "[3/50][339/348] loss = 0.316604\n",
      "[3/50][340/348] loss = 0.084371\n",
      "[3/50][341/348] loss = 0.123654\n",
      "[3/50][342/348] loss = 0.048633\n",
      "[3/50][343/348] loss = 0.057896\n",
      "[3/50][344/348] loss = 0.145793\n",
      "[3/50][345/348] loss = 0.446208\n",
      "[3/50][346/348] loss = 0.157737\n",
      "[3/50][347/348] loss = 0.060377\n",
      "[3/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.44 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 84.03 %\n",
      "\n",
      "\n",
      "[4/50][0/348] loss = 0.030213\n",
      "[4/50][1/348] loss = 0.065528\n",
      "[4/50][2/348] loss = 0.082433\n",
      "[4/50][3/348] loss = 0.071377\n",
      "[4/50][4/348] loss = 0.238048\n",
      "[4/50][5/348] loss = 0.161135\n",
      "[4/50][6/348] loss = 0.147395\n",
      "[4/50][7/348] loss = 0.069085\n",
      "[4/50][8/348] loss = 0.123970\n",
      "[4/50][9/348] loss = 0.216897\n",
      "[4/50][10/348] loss = 0.042735\n",
      "[4/50][11/348] loss = 0.041876\n",
      "[4/50][12/348] loss = 0.148014\n",
      "[4/50][13/348] loss = 0.081067\n",
      "[4/50][14/348] loss = 0.144942\n",
      "[4/50][15/348] loss = 0.052111\n",
      "[4/50][16/348] loss = 0.072101\n",
      "[4/50][17/348] loss = 0.066230\n",
      "[4/50][18/348] loss = 0.069812\n",
      "[4/50][19/348] loss = 0.025960\n",
      "[4/50][20/348] loss = 0.340791\n",
      "[4/50][21/348] loss = 0.036797\n",
      "[4/50][22/348] loss = 0.236272\n",
      "[4/50][23/348] loss = 0.042480\n",
      "[4/50][24/348] loss = 0.101986\n",
      "[4/50][25/348] loss = 0.109794\n",
      "[4/50][26/348] loss = 0.204104\n",
      "[4/50][27/348] loss = 0.450921\n",
      "[4/50][28/348] loss = 0.142555\n",
      "[4/50][29/348] loss = 0.094809\n",
      "[4/50][30/348] loss = 0.099567\n",
      "[4/50][31/348] loss = 0.058922\n",
      "[4/50][32/348] loss = 0.078855\n",
      "[4/50][33/348] loss = 0.075566\n",
      "[4/50][34/348] loss = 0.153582\n",
      "[4/50][35/348] loss = 0.088011\n",
      "[4/50][36/348] loss = 0.135470\n",
      "[4/50][37/348] loss = 0.124179\n",
      "[4/50][38/348] loss = 0.136351\n",
      "[4/50][39/348] loss = 0.137482\n",
      "[4/50][40/348] loss = 0.103576\n",
      "[4/50][41/348] loss = 0.139697\n",
      "[4/50][42/348] loss = 0.170903\n",
      "[4/50][43/348] loss = 0.079112\n",
      "[4/50][44/348] loss = 0.179959\n",
      "[4/50][45/348] loss = 0.044641\n",
      "[4/50][46/348] loss = 0.069597\n",
      "[4/50][47/348] loss = 0.090052\n",
      "[4/50][48/348] loss = 0.234092\n",
      "[4/50][49/348] loss = 0.065018\n",
      "[4/50][50/348] loss = 0.056355\n",
      "[4/50][51/348] loss = 0.036449\n",
      "[4/50][52/348] loss = 0.231677\n",
      "[4/50][53/348] loss = 0.078489\n",
      "[4/50][54/348] loss = 0.148655\n",
      "[4/50][55/348] loss = 0.217758\n",
      "[4/50][56/348] loss = 0.149111\n",
      "[4/50][57/348] loss = 0.077126\n",
      "[4/50][58/348] loss = 0.128458\n",
      "[4/50][59/348] loss = 0.102682\n",
      "[4/50][60/348] loss = 0.071912\n",
      "[4/50][61/348] loss = 0.256630\n",
      "[4/50][62/348] loss = 0.080668\n",
      "[4/50][63/348] loss = 0.067694\n",
      "[4/50][64/348] loss = 0.069877\n",
      "[4/50][65/348] loss = 0.119663\n",
      "[4/50][66/348] loss = 0.260257\n",
      "[4/50][67/348] loss = 0.057788\n",
      "[4/50][68/348] loss = 0.042363\n",
      "[4/50][69/348] loss = 0.084853\n",
      "[4/50][70/348] loss = 0.168289\n",
      "[4/50][71/348] loss = 0.070525\n",
      "[4/50][72/348] loss = 0.095602\n",
      "[4/50][73/348] loss = 0.072536\n",
      "[4/50][74/348] loss = 0.066054\n",
      "[4/50][75/348] loss = 0.091233\n",
      "[4/50][76/348] loss = 0.121510\n",
      "[4/50][77/348] loss = 0.066289\n",
      "[4/50][78/348] loss = 0.071024\n",
      "[4/50][79/348] loss = 0.017601\n",
      "[4/50][80/348] loss = 0.036141\n",
      "[4/50][81/348] loss = 0.049652\n",
      "[4/50][82/348] loss = 0.192185\n",
      "[4/50][83/348] loss = 0.082709\n",
      "[4/50][84/348] loss = 0.066792\n",
      "[4/50][85/348] loss = 0.074631\n",
      "[4/50][86/348] loss = 0.064498\n",
      "[4/50][87/348] loss = 0.152599\n",
      "[4/50][88/348] loss = 0.066749\n",
      "[4/50][89/348] loss = 0.309729\n",
      "[4/50][90/348] loss = 0.074047\n",
      "[4/50][91/348] loss = 0.111572\n",
      "[4/50][92/348] loss = 0.115477\n",
      "[4/50][93/348] loss = 0.094625\n",
      "[4/50][94/348] loss = 0.115452\n",
      "[4/50][95/348] loss = 0.134296\n",
      "[4/50][96/348] loss = 0.011307\n",
      "[4/50][97/348] loss = 0.151776\n",
      "[4/50][98/348] loss = 0.057767\n",
      "[4/50][99/348] loss = 0.051878\n",
      "[4/50][100/348] loss = 0.055279\n",
      "[4/50][101/348] loss = 0.193572\n",
      "[4/50][102/348] loss = 0.096737\n",
      "[4/50][103/348] loss = 0.055821\n",
      "[4/50][104/348] loss = 0.231898\n",
      "[4/50][105/348] loss = 0.041711\n",
      "[4/50][106/348] loss = 0.162752\n",
      "[4/50][107/348] loss = 0.112527\n",
      "[4/50][108/348] loss = 0.113231\n",
      "[4/50][109/348] loss = 0.068060\n",
      "[4/50][110/348] loss = 0.106319\n",
      "[4/50][111/348] loss = 0.171202\n",
      "[4/50][112/348] loss = 0.081007\n",
      "[4/50][113/348] loss = 0.194188\n",
      "[4/50][114/348] loss = 0.113085\n",
      "[4/50][115/348] loss = 0.051860\n",
      "[4/50][116/348] loss = 0.017941\n",
      "[4/50][117/348] loss = 0.096657\n",
      "[4/50][118/348] loss = 0.106623\n",
      "[4/50][119/348] loss = 0.175227\n",
      "[4/50][120/348] loss = 0.166202\n",
      "[4/50][121/348] loss = 0.073869\n",
      "[4/50][122/348] loss = 0.093185\n",
      "[4/50][123/348] loss = 0.149135\n",
      "[4/50][124/348] loss = 0.179628\n",
      "[4/50][125/348] loss = 0.029819\n",
      "[4/50][126/348] loss = 0.055264\n",
      "[4/50][127/348] loss = 0.033569\n",
      "[4/50][128/348] loss = 0.069273\n",
      "[4/50][129/348] loss = 0.066828\n",
      "[4/50][130/348] loss = 0.181356\n",
      "[4/50][131/348] loss = 0.078711\n",
      "[4/50][132/348] loss = 0.048695\n",
      "[4/50][133/348] loss = 0.352743\n",
      "[4/50][134/348] loss = 0.046616\n",
      "[4/50][135/348] loss = 0.255998\n",
      "[4/50][136/348] loss = 0.102861\n",
      "[4/50][137/348] loss = 0.032019\n",
      "[4/50][138/348] loss = 0.098532\n",
      "[4/50][139/348] loss = 0.018418\n",
      "[4/50][140/348] loss = 0.160414\n",
      "[4/50][141/348] loss = 0.142551\n",
      "[4/50][142/348] loss = 0.201143\n",
      "[4/50][143/348] loss = 0.036209\n",
      "[4/50][144/348] loss = 0.052589\n",
      "[4/50][145/348] loss = 0.247984\n",
      "[4/50][146/348] loss = 0.168882\n",
      "[4/50][147/348] loss = 0.096928\n",
      "[4/50][148/348] loss = 0.258719\n",
      "[4/50][149/348] loss = 0.114661\n",
      "[4/50][150/348] loss = 0.042786\n",
      "[4/50][151/348] loss = 0.047002\n",
      "[4/50][152/348] loss = 0.076381\n",
      "[4/50][153/348] loss = 0.128731\n",
      "[4/50][154/348] loss = 0.055428\n",
      "[4/50][155/348] loss = 0.274269\n",
      "[4/50][156/348] loss = 0.110584\n",
      "[4/50][157/348] loss = 0.109659\n",
      "[4/50][158/348] loss = 0.182168\n",
      "[4/50][159/348] loss = 0.145546\n",
      "[4/50][160/348] loss = 0.093056\n",
      "[4/50][161/348] loss = 0.047605\n",
      "[4/50][162/348] loss = 0.062477\n",
      "[4/50][163/348] loss = 0.194817\n",
      "[4/50][164/348] loss = 0.207673\n",
      "[4/50][165/348] loss = 0.074373\n",
      "[4/50][166/348] loss = 0.207308\n",
      "[4/50][167/348] loss = 0.062263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/50][168/348] loss = 0.162337\n",
      "[4/50][169/348] loss = 0.020798\n",
      "[4/50][170/348] loss = 0.074372\n",
      "[4/50][171/348] loss = 0.039806\n",
      "[4/50][172/348] loss = 0.047194\n",
      "[4/50][173/348] loss = 0.049869\n",
      "[4/50][174/348] loss = 0.038764\n",
      "[4/50][175/348] loss = 0.044904\n",
      "[4/50][176/348] loss = 0.151385\n",
      "[4/50][177/348] loss = 0.076548\n",
      "[4/50][178/348] loss = 0.182602\n",
      "[4/50][179/348] loss = 0.029093\n",
      "[4/50][180/348] loss = 0.241600\n",
      "[4/50][181/348] loss = 0.214104\n",
      "[4/50][182/348] loss = 0.025405\n",
      "[4/50][183/348] loss = 0.021319\n",
      "[4/50][184/348] loss = 0.091478\n",
      "[4/50][185/348] loss = 0.156092\n",
      "[4/50][186/348] loss = 0.106816\n",
      "[4/50][187/348] loss = 0.118004\n",
      "[4/50][188/348] loss = 0.020913\n",
      "[4/50][189/348] loss = 0.166298\n",
      "[4/50][190/348] loss = 0.225859\n",
      "[4/50][191/348] loss = 0.124357\n",
      "[4/50][192/348] loss = 0.036560\n",
      "[4/50][193/348] loss = 0.034419\n",
      "[4/50][194/348] loss = 0.213247\n",
      "[4/50][195/348] loss = 0.090883\n",
      "[4/50][196/348] loss = 0.075958\n",
      "[4/50][197/348] loss = 0.051722\n",
      "[4/50][198/348] loss = 0.236960\n",
      "[4/50][199/348] loss = 0.152039\n",
      "[4/50][200/348] loss = 0.123212\n",
      "[4/50][201/348] loss = 0.257647\n",
      "[4/50][202/348] loss = 0.352310\n",
      "[4/50][203/348] loss = 0.208164\n",
      "[4/50][204/348] loss = 0.026444\n",
      "[4/50][205/348] loss = 0.045277\n",
      "[4/50][206/348] loss = 0.199816\n",
      "[4/50][207/348] loss = 0.147860\n",
      "[4/50][208/348] loss = 0.116195\n",
      "[4/50][209/348] loss = 0.110259\n",
      "[4/50][210/348] loss = 0.176658\n",
      "[4/50][211/348] loss = 0.155346\n",
      "[4/50][212/348] loss = 0.052499\n",
      "[4/50][213/348] loss = 0.172809\n",
      "[4/50][214/348] loss = 0.126276\n",
      "[4/50][215/348] loss = 0.159876\n",
      "[4/50][216/348] loss = 0.075935\n",
      "[4/50][217/348] loss = 0.188187\n",
      "[4/50][218/348] loss = 0.096710\n",
      "[4/50][219/348] loss = 0.077803\n",
      "[4/50][220/348] loss = 0.113782\n",
      "[4/50][221/348] loss = 0.276638\n",
      "[4/50][222/348] loss = 0.092186\n",
      "[4/50][223/348] loss = 0.064541\n",
      "[4/50][224/348] loss = 0.181867\n",
      "[4/50][225/348] loss = 0.373517\n",
      "[4/50][226/348] loss = 0.372252\n",
      "[4/50][227/348] loss = 0.216876\n",
      "[4/50][228/348] loss = 0.041652\n",
      "[4/50][229/348] loss = 0.132922\n",
      "[4/50][230/348] loss = 0.223309\n",
      "[4/50][231/348] loss = 0.123091\n",
      "[4/50][232/348] loss = 0.142688\n",
      "[4/50][233/348] loss = 0.279469\n",
      "[4/50][234/348] loss = 0.194546\n",
      "[4/50][235/348] loss = 0.066600\n",
      "[4/50][236/348] loss = 0.345811\n",
      "[4/50][237/348] loss = 0.197962\n",
      "[4/50][238/348] loss = 0.167022\n",
      "[4/50][239/348] loss = 0.090856\n",
      "[4/50][240/348] loss = 0.172043\n",
      "[4/50][241/348] loss = 0.111985\n",
      "[4/50][242/348] loss = 0.116330\n",
      "[4/50][243/348] loss = 0.148307\n",
      "[4/50][244/348] loss = 0.270943\n",
      "[4/50][245/348] loss = 0.139436\n",
      "[4/50][246/348] loss = 0.063495\n",
      "[4/50][247/348] loss = 0.188965\n",
      "[4/50][248/348] loss = 0.194741\n",
      "[4/50][249/348] loss = 0.070902\n",
      "[4/50][250/348] loss = 0.308156\n",
      "[4/50][251/348] loss = 0.441398\n",
      "[4/50][252/348] loss = 0.299621\n",
      "[4/50][253/348] loss = 0.295533\n",
      "[4/50][254/348] loss = 0.063068\n",
      "[4/50][255/348] loss = 0.381948\n",
      "[4/50][256/348] loss = 0.119728\n",
      "[4/50][257/348] loss = 0.082955\n",
      "[4/50][258/348] loss = 0.302308\n",
      "[4/50][259/348] loss = 0.191688\n",
      "[4/50][260/348] loss = 0.199531\n",
      "[4/50][261/348] loss = 0.102433\n",
      "[4/50][262/348] loss = 0.280319\n",
      "[4/50][263/348] loss = 0.402648\n",
      "[4/50][264/348] loss = 0.140557\n",
      "[4/50][265/348] loss = 0.042793\n",
      "[4/50][266/348] loss = 0.179274\n",
      "[4/50][267/348] loss = 0.152097\n",
      "[4/50][268/348] loss = 0.597823\n",
      "[4/50][269/348] loss = 0.128361\n",
      "[4/50][270/348] loss = 0.242949\n",
      "[4/50][271/348] loss = 0.175373\n",
      "[4/50][272/348] loss = 0.249979\n",
      "[4/50][273/348] loss = 0.197836\n",
      "[4/50][274/348] loss = 0.174577\n",
      "[4/50][275/348] loss = 0.268458\n",
      "[4/50][276/348] loss = 0.132904\n",
      "[4/50][277/348] loss = 0.310095\n",
      "[4/50][278/348] loss = 0.235819\n",
      "[4/50][279/348] loss = 0.131925\n",
      "[4/50][280/348] loss = 0.103787\n",
      "[4/50][281/348] loss = 0.381631\n",
      "[4/50][282/348] loss = 0.087084\n",
      "[4/50][283/348] loss = 0.061188\n",
      "[4/50][284/348] loss = 0.103599\n",
      "[4/50][285/348] loss = 0.183641\n",
      "[4/50][286/348] loss = 0.285010\n",
      "[4/50][287/348] loss = 0.220000\n",
      "[4/50][288/348] loss = 0.161186\n",
      "[4/50][289/348] loss = 0.294059\n",
      "[4/50][290/348] loss = 0.758724\n",
      "[4/50][291/348] loss = 0.055792\n",
      "[4/50][292/348] loss = 0.138276\n",
      "[4/50][293/348] loss = 0.148443\n",
      "[4/50][294/348] loss = 0.102208\n",
      "[4/50][295/348] loss = 0.049985\n",
      "[4/50][296/348] loss = 0.051710\n",
      "[4/50][297/348] loss = 0.171144\n",
      "[4/50][298/348] loss = 0.142592\n",
      "[4/50][299/348] loss = 0.211952\n",
      "[4/50][300/348] loss = 0.295936\n",
      "[4/50][301/348] loss = 0.164912\n",
      "[4/50][302/348] loss = 0.178003\n",
      "[4/50][303/348] loss = 0.091522\n",
      "[4/50][304/348] loss = 0.030561\n",
      "[4/50][305/348] loss = 0.123445\n",
      "[4/50][306/348] loss = 0.273034\n",
      "[4/50][307/348] loss = 0.591855\n",
      "[4/50][308/348] loss = 0.064851\n",
      "[4/50][309/348] loss = 0.149101\n",
      "[4/50][310/348] loss = 0.160009\n",
      "[4/50][311/348] loss = 0.066020\n",
      "[4/50][312/348] loss = 0.256708\n",
      "[4/50][313/348] loss = 0.072564\n",
      "[4/50][314/348] loss = 0.473569\n",
      "[4/50][315/348] loss = 0.111820\n",
      "[4/50][316/348] loss = 0.114548\n",
      "[4/50][317/348] loss = 0.202685\n",
      "[4/50][318/348] loss = 0.113589\n",
      "[4/50][319/348] loss = 0.104456\n",
      "[4/50][320/348] loss = 0.307745\n",
      "[4/50][321/348] loss = 0.460646\n",
      "[4/50][322/348] loss = 0.292926\n",
      "[4/50][323/348] loss = 0.253398\n",
      "[4/50][324/348] loss = 0.038864\n",
      "[4/50][325/348] loss = 0.051411\n",
      "[4/50][326/348] loss = 0.093062\n",
      "[4/50][327/348] loss = 0.098527\n",
      "[4/50][328/348] loss = 0.091693\n",
      "[4/50][329/348] loss = 0.102155\n",
      "[4/50][330/348] loss = 0.109454\n",
      "[4/50][331/348] loss = 0.132283\n",
      "[4/50][332/348] loss = 0.092630\n",
      "[4/50][333/348] loss = 0.190386\n",
      "[4/50][334/348] loss = 0.135461\n",
      "[4/50][335/348] loss = 0.193610\n",
      "[4/50][336/348] loss = 0.045867\n",
      "[4/50][337/348] loss = 0.103814\n",
      "[4/50][338/348] loss = 0.282089\n",
      "[4/50][339/348] loss = 0.248400\n",
      "[4/50][340/348] loss = 0.092477\n",
      "[4/50][341/348] loss = 0.178893\n",
      "[4/50][342/348] loss = 0.116744\n",
      "[4/50][343/348] loss = 0.300542\n",
      "[4/50][344/348] loss = 0.135562\n",
      "[4/50][345/348] loss = 0.075922\n",
      "[4/50][346/348] loss = 0.196304\n",
      "[4/50][347/348] loss = 0.335767\n",
      "[4/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.79 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 88.01 %\n",
      "\n",
      "\n",
      "[5/50][0/348] loss = 0.144884\n",
      "[5/50][1/348] loss = 0.074542\n",
      "[5/50][2/348] loss = 0.069474\n",
      "[5/50][3/348] loss = 0.150663\n",
      "[5/50][4/348] loss = 0.130001\n",
      "[5/50][5/348] loss = 0.041621\n",
      "[5/50][6/348] loss = 0.047107\n",
      "[5/50][7/348] loss = 0.211308\n",
      "[5/50][8/348] loss = 0.064201\n",
      "[5/50][9/348] loss = 0.271048\n",
      "[5/50][10/348] loss = 0.333528\n",
      "[5/50][11/348] loss = 0.077352\n",
      "[5/50][12/348] loss = 0.239030\n",
      "[5/50][13/348] loss = 0.214722\n",
      "[5/50][14/348] loss = 0.134922\n",
      "[5/50][15/348] loss = 0.109338\n",
      "[5/50][16/348] loss = 0.099171\n",
      "[5/50][17/348] loss = 0.035510\n",
      "[5/50][18/348] loss = 0.034501\n",
      "[5/50][19/348] loss = 0.095954\n",
      "[5/50][20/348] loss = 0.012778\n",
      "[5/50][21/348] loss = 0.037862\n",
      "[5/50][22/348] loss = 0.026049\n",
      "[5/50][23/348] loss = 0.058444\n",
      "[5/50][24/348] loss = 0.046358\n",
      "[5/50][25/348] loss = 0.133701\n",
      "[5/50][26/348] loss = 0.054630\n",
      "[5/50][27/348] loss = 0.071845\n",
      "[5/50][28/348] loss = 0.097910\n",
      "[5/50][29/348] loss = 0.040141\n",
      "[5/50][30/348] loss = 0.133872\n",
      "[5/50][31/348] loss = 0.063746\n",
      "[5/50][32/348] loss = 0.100234\n",
      "[5/50][33/348] loss = 0.043658\n",
      "[5/50][34/348] loss = 0.034794\n",
      "[5/50][35/348] loss = 0.166382\n",
      "[5/50][36/348] loss = 0.146436\n",
      "[5/50][37/348] loss = 0.038316\n",
      "[5/50][38/348] loss = 0.217239\n",
      "[5/50][39/348] loss = 0.114681\n",
      "[5/50][40/348] loss = 0.224074\n",
      "[5/50][41/348] loss = 0.177451\n",
      "[5/50][42/348] loss = 0.183090\n",
      "[5/50][43/348] loss = 0.066352\n",
      "[5/50][44/348] loss = 0.066725\n",
      "[5/50][45/348] loss = 0.066416\n",
      "[5/50][46/348] loss = 0.267380\n",
      "[5/50][47/348] loss = 0.124187\n",
      "[5/50][48/348] loss = 0.123452\n",
      "[5/50][49/348] loss = 0.046190\n",
      "[5/50][50/348] loss = 0.079495\n",
      "[5/50][51/348] loss = 0.030673\n",
      "[5/50][52/348] loss = 0.142205\n",
      "[5/50][53/348] loss = 0.172340\n",
      "[5/50][54/348] loss = 0.086190\n",
      "[5/50][55/348] loss = 0.196931\n",
      "[5/50][56/348] loss = 0.045714\n",
      "[5/50][57/348] loss = 0.264937\n",
      "[5/50][58/348] loss = 0.190339\n",
      "[5/50][59/348] loss = 0.073881\n",
      "[5/50][60/348] loss = 0.076947\n",
      "[5/50][61/348] loss = 0.452944\n",
      "[5/50][62/348] loss = 0.013740\n",
      "[5/50][63/348] loss = 0.092969\n",
      "[5/50][64/348] loss = 0.079220\n",
      "[5/50][65/348] loss = 0.088909\n",
      "[5/50][66/348] loss = 0.231649\n",
      "[5/50][67/348] loss = 0.046102\n",
      "[5/50][68/348] loss = 0.109902\n",
      "[5/50][69/348] loss = 0.036271\n",
      "[5/50][70/348] loss = 0.043348\n",
      "[5/50][71/348] loss = 0.118723\n",
      "[5/50][72/348] loss = 0.089731\n",
      "[5/50][73/348] loss = 0.038296\n",
      "[5/50][74/348] loss = 0.244000\n",
      "[5/50][75/348] loss = 0.157148\n",
      "[5/50][76/348] loss = 0.099108\n",
      "[5/50][77/348] loss = 0.233826\n",
      "[5/50][78/348] loss = 0.186226\n",
      "[5/50][79/348] loss = 0.318212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/50][80/348] loss = 0.164463\n",
      "[5/50][81/348] loss = 0.205239\n",
      "[5/50][82/348] loss = 0.112582\n",
      "[5/50][83/348] loss = 0.251886\n",
      "[5/50][84/348] loss = 0.308658\n",
      "[5/50][85/348] loss = 0.227748\n",
      "[5/50][86/348] loss = 0.076018\n",
      "[5/50][87/348] loss = 0.091063\n",
      "[5/50][88/348] loss = 0.082427\n",
      "[5/50][89/348] loss = 0.056587\n",
      "[5/50][90/348] loss = 0.019521\n",
      "[5/50][91/348] loss = 0.071949\n",
      "[5/50][92/348] loss = 0.122923\n",
      "[5/50][93/348] loss = 0.068090\n",
      "[5/50][94/348] loss = 0.174459\n",
      "[5/50][95/348] loss = 0.030445\n",
      "[5/50][96/348] loss = 0.093201\n",
      "[5/50][97/348] loss = 0.051051\n",
      "[5/50][98/348] loss = 0.160557\n",
      "[5/50][99/348] loss = 0.119776\n",
      "[5/50][100/348] loss = 0.230640\n",
      "[5/50][101/348] loss = 0.082672\n",
      "[5/50][102/348] loss = 0.070067\n",
      "[5/50][103/348] loss = 0.048818\n",
      "[5/50][104/348] loss = 0.103243\n",
      "[5/50][105/348] loss = 0.289066\n",
      "[5/50][106/348] loss = 0.075405\n",
      "[5/50][107/348] loss = 0.024680\n",
      "[5/50][108/348] loss = 0.047196\n",
      "[5/50][109/348] loss = 0.195081\n",
      "[5/50][110/348] loss = 0.102819\n",
      "[5/50][111/348] loss = 0.202308\n",
      "[5/50][112/348] loss = 0.164357\n",
      "[5/50][113/348] loss = 0.102021\n",
      "[5/50][114/348] loss = 0.042159\n",
      "[5/50][115/348] loss = 0.315409\n",
      "[5/50][116/348] loss = 0.035176\n",
      "[5/50][117/348] loss = 0.146600\n",
      "[5/50][118/348] loss = 0.080541\n",
      "[5/50][119/348] loss = 0.069158\n",
      "[5/50][120/348] loss = 0.123483\n",
      "[5/50][121/348] loss = 0.080607\n",
      "[5/50][122/348] loss = 0.083463\n",
      "[5/50][123/348] loss = 0.094822\n",
      "[5/50][124/348] loss = 0.115898\n",
      "[5/50][125/348] loss = 0.034184\n",
      "[5/50][126/348] loss = 0.154281\n",
      "[5/50][127/348] loss = 0.277871\n",
      "[5/50][128/348] loss = 0.138706\n",
      "[5/50][129/348] loss = 0.106002\n",
      "[5/50][130/348] loss = 0.121526\n",
      "[5/50][131/348] loss = 0.313555\n",
      "[5/50][132/348] loss = 0.046428\n",
      "[5/50][133/348] loss = 0.177805\n",
      "[5/50][134/348] loss = 0.083176\n",
      "[5/50][135/348] loss = 0.093620\n",
      "[5/50][136/348] loss = 0.359425\n",
      "[5/50][137/348] loss = 0.284945\n",
      "[5/50][138/348] loss = 0.034744\n",
      "[5/50][139/348] loss = 0.239752\n",
      "[5/50][140/348] loss = 0.023494\n",
      "[5/50][141/348] loss = 0.264087\n",
      "[5/50][142/348] loss = 0.070024\n",
      "[5/50][143/348] loss = 0.115386\n",
      "[5/50][144/348] loss = 0.092828\n",
      "[5/50][145/348] loss = 0.057073\n",
      "[5/50][146/348] loss = 0.137061\n",
      "[5/50][147/348] loss = 0.268195\n",
      "[5/50][148/348] loss = 0.042697\n",
      "[5/50][149/348] loss = 0.140297\n",
      "[5/50][150/348] loss = 0.064675\n",
      "[5/50][151/348] loss = 0.142771\n",
      "[5/50][152/348] loss = 0.069006\n",
      "[5/50][153/348] loss = 0.222515\n",
      "[5/50][154/348] loss = 0.189494\n",
      "[5/50][155/348] loss = 0.061618\n",
      "[5/50][156/348] loss = 0.049899\n",
      "[5/50][157/348] loss = 0.027848\n",
      "[5/50][158/348] loss = 0.141976\n",
      "[5/50][159/348] loss = 0.142433\n",
      "[5/50][160/348] loss = 0.130139\n",
      "[5/50][161/348] loss = 0.043719\n",
      "[5/50][162/348] loss = 0.153265\n",
      "[5/50][163/348] loss = 0.017456\n",
      "[5/50][164/348] loss = 0.096913\n",
      "[5/50][165/348] loss = 0.042065\n",
      "[5/50][166/348] loss = 0.048078\n",
      "[5/50][167/348] loss = 0.116803\n",
      "[5/50][168/348] loss = 0.146334\n",
      "[5/50][169/348] loss = 0.063877\n",
      "[5/50][170/348] loss = 0.101501\n",
      "[5/50][171/348] loss = 0.073321\n",
      "[5/50][172/348] loss = 0.388751\n",
      "[5/50][173/348] loss = 0.043155\n",
      "[5/50][174/348] loss = 0.074994\n",
      "[5/50][175/348] loss = 0.028052\n",
      "[5/50][176/348] loss = 0.231787\n",
      "[5/50][177/348] loss = 0.050547\n",
      "[5/50][178/348] loss = 0.147268\n",
      "[5/50][179/348] loss = 0.080075\n",
      "[5/50][180/348] loss = 0.282028\n",
      "[5/50][181/348] loss = 0.093786\n",
      "[5/50][182/348] loss = 0.053822\n",
      "[5/50][183/348] loss = 0.024722\n",
      "[5/50][184/348] loss = 0.081887\n",
      "[5/50][185/348] loss = 0.202719\n",
      "[5/50][186/348] loss = 0.055664\n",
      "[5/50][187/348] loss = 0.118579\n",
      "[5/50][188/348] loss = 0.064279\n",
      "[5/50][189/348] loss = 0.032227\n",
      "[5/50][190/348] loss = 0.026006\n",
      "[5/50][191/348] loss = 0.070368\n",
      "[5/50][192/348] loss = 0.086646\n",
      "[5/50][193/348] loss = 0.135051\n",
      "[5/50][194/348] loss = 0.035868\n",
      "[5/50][195/348] loss = 0.108805\n",
      "[5/50][196/348] loss = 0.176364\n",
      "[5/50][197/348] loss = 0.038047\n",
      "[5/50][198/348] loss = 0.057774\n",
      "[5/50][199/348] loss = 0.265353\n",
      "[5/50][200/348] loss = 0.168378\n",
      "[5/50][201/348] loss = 0.044347\n",
      "[5/50][202/348] loss = 0.174916\n",
      "[5/50][203/348] loss = 0.189365\n",
      "[5/50][204/348] loss = 0.262372\n",
      "[5/50][205/348] loss = 0.081677\n",
      "[5/50][206/348] loss = 0.215300\n",
      "[5/50][207/348] loss = 0.009223\n",
      "[5/50][208/348] loss = 0.082868\n",
      "[5/50][209/348] loss = 0.240893\n",
      "[5/50][210/348] loss = 0.148807\n",
      "[5/50][211/348] loss = 0.225365\n",
      "[5/50][212/348] loss = 0.104496\n",
      "[5/50][213/348] loss = 0.337088\n",
      "[5/50][214/348] loss = 0.140229\n",
      "[5/50][215/348] loss = 0.019621\n",
      "[5/50][216/348] loss = 0.105997\n",
      "[5/50][217/348] loss = 0.138372\n",
      "[5/50][218/348] loss = 0.164250\n",
      "[5/50][219/348] loss = 0.118120\n",
      "[5/50][220/348] loss = 0.018957\n",
      "[5/50][221/348] loss = 0.192778\n",
      "[5/50][222/348] loss = 0.089892\n",
      "[5/50][223/348] loss = 0.109951\n",
      "[5/50][224/348] loss = 0.251113\n",
      "[5/50][225/348] loss = 0.221345\n",
      "[5/50][226/348] loss = 0.204905\n",
      "[5/50][227/348] loss = 0.029015\n",
      "[5/50][228/348] loss = 0.140132\n",
      "[5/50][229/348] loss = 0.017554\n",
      "[5/50][230/348] loss = 0.083333\n",
      "[5/50][231/348] loss = 0.040035\n",
      "[5/50][232/348] loss = 0.019837\n",
      "[5/50][233/348] loss = 0.294974\n",
      "[5/50][234/348] loss = 0.052728\n",
      "[5/50][235/348] loss = 0.175792\n",
      "[5/50][236/348] loss = 0.051740\n",
      "[5/50][237/348] loss = 0.187483\n",
      "[5/50][238/348] loss = 0.118969\n",
      "[5/50][239/348] loss = 0.032098\n",
      "[5/50][240/348] loss = 0.063657\n",
      "[5/50][241/348] loss = 0.126923\n",
      "[5/50][242/348] loss = 0.017132\n",
      "[5/50][243/348] loss = 0.175370\n",
      "[5/50][244/348] loss = 0.144820\n",
      "[5/50][245/348] loss = 0.155925\n",
      "[5/50][246/348] loss = 0.066280\n",
      "[5/50][247/348] loss = 0.036276\n",
      "[5/50][248/348] loss = 0.033618\n",
      "[5/50][249/348] loss = 0.121663\n",
      "[5/50][250/348] loss = 0.060704\n",
      "[5/50][251/348] loss = 0.344470\n",
      "[5/50][252/348] loss = 0.168058\n",
      "[5/50][253/348] loss = 0.201278\n",
      "[5/50][254/348] loss = 0.060277\n",
      "[5/50][255/348] loss = 0.093145\n",
      "[5/50][256/348] loss = 0.041134\n",
      "[5/50][257/348] loss = 0.049452\n",
      "[5/50][258/348] loss = 0.018351\n",
      "[5/50][259/348] loss = 0.315035\n",
      "[5/50][260/348] loss = 0.109991\n",
      "[5/50][261/348] loss = 0.066662\n",
      "[5/50][262/348] loss = 0.089134\n",
      "[5/50][263/348] loss = 0.276187\n",
      "[5/50][264/348] loss = 0.054155\n",
      "[5/50][265/348] loss = 0.102103\n",
      "[5/50][266/348] loss = 0.078007\n",
      "[5/50][267/348] loss = 0.092893\n",
      "[5/50][268/348] loss = 0.129871\n",
      "[5/50][269/348] loss = 0.112012\n",
      "[5/50][270/348] loss = 0.127474\n",
      "[5/50][271/348] loss = 0.094936\n",
      "[5/50][272/348] loss = 0.054991\n",
      "[5/50][273/348] loss = 0.124810\n",
      "[5/50][274/348] loss = 0.013899\n",
      "[5/50][275/348] loss = 0.215476\n",
      "[5/50][276/348] loss = 0.065050\n",
      "[5/50][277/348] loss = 0.073962\n",
      "[5/50][278/348] loss = 0.198715\n",
      "[5/50][279/348] loss = 0.428549\n",
      "[5/50][280/348] loss = 0.130286\n",
      "[5/50][281/348] loss = 0.018535\n",
      "[5/50][282/348] loss = 0.011808\n",
      "[5/50][283/348] loss = 0.206441\n",
      "[5/50][284/348] loss = 0.082665\n",
      "[5/50][285/348] loss = 0.183227\n",
      "[5/50][286/348] loss = 0.051850\n",
      "[5/50][287/348] loss = 0.104118\n",
      "[5/50][288/348] loss = 0.240657\n",
      "[5/50][289/348] loss = 0.135420\n",
      "[5/50][290/348] loss = 0.228123\n",
      "[5/50][291/348] loss = 0.051849\n",
      "[5/50][292/348] loss = 0.280697\n",
      "[5/50][293/348] loss = 0.068069\n",
      "[5/50][294/348] loss = 0.123504\n",
      "[5/50][295/348] loss = 0.115737\n",
      "[5/50][296/348] loss = 0.182623\n",
      "[5/50][297/348] loss = 0.121190\n",
      "[5/50][298/348] loss = 0.255179\n",
      "[5/50][299/348] loss = 0.234328\n",
      "[5/50][300/348] loss = 0.353154\n",
      "[5/50][301/348] loss = 0.022175\n",
      "[5/50][302/348] loss = 0.294455\n",
      "[5/50][303/348] loss = 0.297909\n",
      "[5/50][304/348] loss = 0.298333\n",
      "[5/50][305/348] loss = 0.173540\n",
      "[5/50][306/348] loss = 0.130949\n",
      "[5/50][307/348] loss = 0.068931\n",
      "[5/50][308/348] loss = 0.083983\n",
      "[5/50][309/348] loss = 0.159505\n",
      "[5/50][310/348] loss = 0.177611\n",
      "[5/50][311/348] loss = 0.142127\n",
      "[5/50][312/348] loss = 0.052517\n",
      "[5/50][313/348] loss = 0.358642\n",
      "[5/50][314/348] loss = 0.103821\n",
      "[5/50][315/348] loss = 0.098297\n",
      "[5/50][316/348] loss = 0.080519\n",
      "[5/50][317/348] loss = 0.240111\n",
      "[5/50][318/348] loss = 0.165650\n",
      "[5/50][319/348] loss = 0.069922\n",
      "[5/50][320/348] loss = 0.067743\n",
      "[5/50][321/348] loss = 0.032507\n",
      "[5/50][322/348] loss = 0.286272\n",
      "[5/50][323/348] loss = 0.564334\n",
      "[5/50][324/348] loss = 0.060281\n",
      "[5/50][325/348] loss = 0.049266\n",
      "[5/50][326/348] loss = 0.132903\n",
      "[5/50][327/348] loss = 0.016899\n",
      "[5/50][328/348] loss = 0.050067\n",
      "[5/50][329/348] loss = 0.228273\n",
      "[5/50][330/348] loss = 0.116054\n",
      "[5/50][331/348] loss = 0.071633\n",
      "[5/50][332/348] loss = 0.037121\n",
      "[5/50][333/348] loss = 0.137167\n",
      "[5/50][334/348] loss = 0.197469\n",
      "[5/50][335/348] loss = 0.020837\n",
      "[5/50][336/348] loss = 0.083805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/50][337/348] loss = 0.107153\n",
      "[5/50][338/348] loss = 0.027441\n",
      "[5/50][339/348] loss = 0.110935\n",
      "[5/50][340/348] loss = 0.139759\n",
      "[5/50][341/348] loss = 0.054007\n",
      "[5/50][342/348] loss = 0.032128\n",
      "[5/50][343/348] loss = 0.170382\n",
      "[5/50][344/348] loss = 0.143894\n",
      "[5/50][345/348] loss = 0.091443\n",
      "[5/50][346/348] loss = 0.015203\n",
      "[5/50][347/348] loss = 0.042676\n",
      "[5/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.52 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 88.22 %\n",
      "\n",
      "\n",
      "[6/50][0/348] loss = 0.087023\n",
      "[6/50][1/348] loss = 0.036184\n",
      "[6/50][2/348] loss = 0.067683\n",
      "[6/50][3/348] loss = 0.080063\n",
      "[6/50][4/348] loss = 0.012813\n",
      "[6/50][5/348] loss = 0.041550\n",
      "[6/50][6/348] loss = 0.036509\n",
      "[6/50][7/348] loss = 0.220870\n",
      "[6/50][8/348] loss = 0.128177\n",
      "[6/50][9/348] loss = 0.199819\n",
      "[6/50][10/348] loss = 0.021669\n",
      "[6/50][11/348] loss = 0.192583\n",
      "[6/50][12/348] loss = 0.124093\n",
      "[6/50][13/348] loss = 0.136415\n",
      "[6/50][14/348] loss = 0.125953\n",
      "[6/50][15/348] loss = 0.034406\n",
      "[6/50][16/348] loss = 0.064639\n",
      "[6/50][17/348] loss = 0.181523\n",
      "[6/50][18/348] loss = 0.145346\n",
      "[6/50][19/348] loss = 0.012435\n",
      "[6/50][20/348] loss = 0.013068\n",
      "[6/50][21/348] loss = 0.051072\n",
      "[6/50][22/348] loss = 0.057316\n",
      "[6/50][23/348] loss = 0.082686\n",
      "[6/50][24/348] loss = 0.027469\n",
      "[6/50][25/348] loss = 0.033308\n",
      "[6/50][26/348] loss = 0.015709\n",
      "[6/50][27/348] loss = 0.057064\n",
      "[6/50][28/348] loss = 0.061488\n",
      "[6/50][29/348] loss = 0.115651\n",
      "[6/50][30/348] loss = 0.008813\n",
      "[6/50][31/348] loss = 0.056196\n",
      "[6/50][32/348] loss = 0.061370\n",
      "[6/50][33/348] loss = 0.134665\n",
      "[6/50][34/348] loss = 0.067672\n",
      "[6/50][35/348] loss = 0.072285\n",
      "[6/50][36/348] loss = 0.164531\n",
      "[6/50][37/348] loss = 0.053116\n",
      "[6/50][38/348] loss = 0.099730\n",
      "[6/50][39/348] loss = 0.038021\n",
      "[6/50][40/348] loss = 0.043261\n",
      "[6/50][41/348] loss = 0.125915\n",
      "[6/50][42/348] loss = 0.031926\n",
      "[6/50][43/348] loss = 0.070593\n",
      "[6/50][44/348] loss = 0.015437\n",
      "[6/50][45/348] loss = 0.039746\n",
      "[6/50][46/348] loss = 0.025328\n",
      "[6/50][47/348] loss = 0.033005\n",
      "[6/50][48/348] loss = 0.032639\n",
      "[6/50][49/348] loss = 0.104330\n",
      "[6/50][50/348] loss = 0.099731\n",
      "[6/50][51/348] loss = 0.193324\n",
      "[6/50][52/348] loss = 0.064549\n",
      "[6/50][53/348] loss = 0.038663\n",
      "[6/50][54/348] loss = 0.128949\n",
      "[6/50][55/348] loss = 0.033904\n",
      "[6/50][56/348] loss = 0.030135\n",
      "[6/50][57/348] loss = 0.015047\n",
      "[6/50][58/348] loss = 0.127639\n",
      "[6/50][59/348] loss = 0.150433\n",
      "[6/50][60/348] loss = 0.044129\n",
      "[6/50][61/348] loss = 0.289776\n",
      "[6/50][62/348] loss = 0.074997\n",
      "[6/50][63/348] loss = 0.017134\n",
      "[6/50][64/348] loss = 0.094748\n",
      "[6/50][65/348] loss = 0.237009\n",
      "[6/50][66/348] loss = 0.017532\n",
      "[6/50][67/348] loss = 0.100751\n",
      "[6/50][68/348] loss = 0.028291\n",
      "[6/50][69/348] loss = 0.023477\n",
      "[6/50][70/348] loss = 0.040792\n",
      "[6/50][71/348] loss = 0.019866\n",
      "[6/50][72/348] loss = 0.122076\n",
      "[6/50][73/348] loss = 0.034188\n",
      "[6/50][74/348] loss = 0.028537\n",
      "[6/50][75/348] loss = 0.208788\n",
      "[6/50][76/348] loss = 0.035257\n",
      "[6/50][77/348] loss = 0.029020\n",
      "[6/50][78/348] loss = 0.051567\n",
      "[6/50][79/348] loss = 0.007629\n",
      "[6/50][80/348] loss = 0.160090\n",
      "[6/50][81/348] loss = 0.035291\n",
      "[6/50][82/348] loss = 0.040214\n",
      "[6/50][83/348] loss = 0.085647\n",
      "[6/50][84/348] loss = 0.106811\n",
      "[6/50][85/348] loss = 0.152247\n",
      "[6/50][86/348] loss = 0.081187\n",
      "[6/50][87/348] loss = 0.146055\n",
      "[6/50][88/348] loss = 0.030024\n",
      "[6/50][89/348] loss = 0.021706\n",
      "[6/50][90/348] loss = 0.011222\n",
      "[6/50][91/348] loss = 0.051823\n",
      "[6/50][92/348] loss = 0.063746\n",
      "[6/50][93/348] loss = 0.044427\n",
      "[6/50][94/348] loss = 0.077096\n",
      "[6/50][95/348] loss = 0.036543\n",
      "[6/50][96/348] loss = 0.159719\n",
      "[6/50][97/348] loss = 0.085326\n",
      "[6/50][98/348] loss = 0.077057\n",
      "[6/50][99/348] loss = 0.111278\n",
      "[6/50][100/348] loss = 0.029107\n",
      "[6/50][101/348] loss = 0.015475\n",
      "[6/50][102/348] loss = 0.042709\n",
      "[6/50][103/348] loss = 0.044473\n",
      "[6/50][104/348] loss = 0.107349\n",
      "[6/50][105/348] loss = 0.054884\n",
      "[6/50][106/348] loss = 0.223667\n",
      "[6/50][107/348] loss = 0.087853\n",
      "[6/50][108/348] loss = 0.097934\n",
      "[6/50][109/348] loss = 0.077840\n",
      "[6/50][110/348] loss = 0.132023\n",
      "[6/50][111/348] loss = 0.166622\n",
      "[6/50][112/348] loss = 0.027080\n",
      "[6/50][113/348] loss = 0.051923\n",
      "[6/50][114/348] loss = 0.112051\n",
      "[6/50][115/348] loss = 0.018005\n",
      "[6/50][116/348] loss = 0.141259\n",
      "[6/50][117/348] loss = 0.078612\n",
      "[6/50][118/348] loss = 0.127506\n",
      "[6/50][119/348] loss = 0.059425\n",
      "[6/50][120/348] loss = 0.021820\n",
      "[6/50][121/348] loss = 0.076156\n",
      "[6/50][122/348] loss = 0.037885\n",
      "[6/50][123/348] loss = 0.105432\n",
      "[6/50][124/348] loss = 0.108800\n",
      "[6/50][125/348] loss = 0.032421\n",
      "[6/50][126/348] loss = 0.013513\n",
      "[6/50][127/348] loss = 0.126737\n",
      "[6/50][128/348] loss = 0.031012\n",
      "[6/50][129/348] loss = 0.024272\n",
      "[6/50][130/348] loss = 0.098005\n",
      "[6/50][131/348] loss = 0.203242\n",
      "[6/50][132/348] loss = 0.036019\n",
      "[6/50][133/348] loss = 0.430087\n",
      "[6/50][134/348] loss = 0.046557\n",
      "[6/50][135/348] loss = 0.079867\n",
      "[6/50][136/348] loss = 0.090959\n",
      "[6/50][137/348] loss = 0.072218\n",
      "[6/50][138/348] loss = 0.044927\n",
      "[6/50][139/348] loss = 0.072499\n",
      "[6/50][140/348] loss = 0.041089\n",
      "[6/50][141/348] loss = 0.250656\n",
      "[6/50][142/348] loss = 0.175532\n",
      "[6/50][143/348] loss = 0.224292\n",
      "[6/50][144/348] loss = 0.124585\n",
      "[6/50][145/348] loss = 0.069006\n",
      "[6/50][146/348] loss = 0.074298\n",
      "[6/50][147/348] loss = 0.079300\n",
      "[6/50][148/348] loss = 0.035974\n",
      "[6/50][149/348] loss = 0.040763\n",
      "[6/50][150/348] loss = 0.442190\n",
      "[6/50][151/348] loss = 0.083150\n",
      "[6/50][152/348] loss = 0.121900\n",
      "[6/50][153/348] loss = 0.154859\n",
      "[6/50][154/348] loss = 0.015300\n",
      "[6/50][155/348] loss = 0.043974\n",
      "[6/50][156/348] loss = 0.149306\n",
      "[6/50][157/348] loss = 0.133631\n",
      "[6/50][158/348] loss = 0.123076\n",
      "[6/50][159/348] loss = 0.051220\n",
      "[6/50][160/348] loss = 0.241436\n",
      "[6/50][161/348] loss = 0.043436\n",
      "[6/50][162/348] loss = 0.140645\n",
      "[6/50][163/348] loss = 0.148147\n",
      "[6/50][164/348] loss = 0.059098\n",
      "[6/50][165/348] loss = 0.170036\n",
      "[6/50][166/348] loss = 0.015426\n",
      "[6/50][167/348] loss = 0.082309\n",
      "[6/50][168/348] loss = 0.024607\n",
      "[6/50][169/348] loss = 0.015229\n",
      "[6/50][170/348] loss = 0.051213\n",
      "[6/50][171/348] loss = 0.025051\n",
      "[6/50][172/348] loss = 0.027723\n",
      "[6/50][173/348] loss = 0.130119\n",
      "[6/50][174/348] loss = 0.036650\n",
      "[6/50][175/348] loss = 0.277819\n",
      "[6/50][176/348] loss = 0.042420\n",
      "[6/50][177/348] loss = 0.029792\n",
      "[6/50][178/348] loss = 0.147877\n",
      "[6/50][179/348] loss = 0.156003\n",
      "[6/50][180/348] loss = 0.137959\n",
      "[6/50][181/348] loss = 0.021361\n",
      "[6/50][182/348] loss = 0.131781\n",
      "[6/50][183/348] loss = 0.072548\n",
      "[6/50][184/348] loss = 0.020937\n",
      "[6/50][185/348] loss = 0.172594\n",
      "[6/50][186/348] loss = 0.052672\n",
      "[6/50][187/348] loss = 0.287905\n",
      "[6/50][188/348] loss = 0.063025\n",
      "[6/50][189/348] loss = 0.121351\n",
      "[6/50][190/348] loss = 0.025842\n",
      "[6/50][191/348] loss = 0.032865\n",
      "[6/50][192/348] loss = 0.041436\n",
      "[6/50][193/348] loss = 0.155704\n",
      "[6/50][194/348] loss = 0.023912\n",
      "[6/50][195/348] loss = 0.108797\n",
      "[6/50][196/348] loss = 0.038880\n",
      "[6/50][197/348] loss = 0.086169\n",
      "[6/50][198/348] loss = 0.118797\n",
      "[6/50][199/348] loss = 0.044859\n",
      "[6/50][200/348] loss = 0.089440\n",
      "[6/50][201/348] loss = 0.169777\n",
      "[6/50][202/348] loss = 0.141338\n",
      "[6/50][203/348] loss = 0.186282\n",
      "[6/50][204/348] loss = 0.153419\n",
      "[6/50][205/348] loss = 0.055968\n",
      "[6/50][206/348] loss = 0.198030\n",
      "[6/50][207/348] loss = 0.165005\n",
      "[6/50][208/348] loss = 0.057651\n",
      "[6/50][209/348] loss = 0.099169\n",
      "[6/50][210/348] loss = 0.105652\n",
      "[6/50][211/348] loss = 0.098605\n",
      "[6/50][212/348] loss = 0.019135\n",
      "[6/50][213/348] loss = 0.303448\n",
      "[6/50][214/348] loss = 0.054641\n",
      "[6/50][215/348] loss = 0.059419\n",
      "[6/50][216/348] loss = 0.235427\n",
      "[6/50][217/348] loss = 0.091885\n",
      "[6/50][218/348] loss = 0.079995\n",
      "[6/50][219/348] loss = 0.230727\n",
      "[6/50][220/348] loss = 0.019383\n",
      "[6/50][221/348] loss = 0.134655\n",
      "[6/50][222/348] loss = 0.055179\n",
      "[6/50][223/348] loss = 0.045234\n",
      "[6/50][224/348] loss = 0.224803\n",
      "[6/50][225/348] loss = 0.177963\n",
      "[6/50][226/348] loss = 0.028317\n",
      "[6/50][227/348] loss = 0.060803\n",
      "[6/50][228/348] loss = 0.053766\n",
      "[6/50][229/348] loss = 0.191849\n",
      "[6/50][230/348] loss = 0.280218\n",
      "[6/50][231/348] loss = 0.196555\n",
      "[6/50][232/348] loss = 0.026766\n",
      "[6/50][233/348] loss = 0.043756\n",
      "[6/50][234/348] loss = 0.024650\n",
      "[6/50][235/348] loss = 0.024264\n",
      "[6/50][236/348] loss = 0.096057\n",
      "[6/50][237/348] loss = 0.183153\n",
      "[6/50][238/348] loss = 0.124452\n",
      "[6/50][239/348] loss = 0.013584\n",
      "[6/50][240/348] loss = 0.018977\n",
      "[6/50][241/348] loss = 0.087144\n",
      "[6/50][242/348] loss = 0.030720\n",
      "[6/50][243/348] loss = 0.050832\n",
      "[6/50][244/348] loss = 0.064422\n",
      "[6/50][245/348] loss = 0.051692\n",
      "[6/50][246/348] loss = 0.022287\n",
      "[6/50][247/348] loss = 0.075187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/50][248/348] loss = 0.190975\n",
      "[6/50][249/348] loss = 0.146928\n",
      "[6/50][250/348] loss = 0.090708\n",
      "[6/50][251/348] loss = 0.061237\n",
      "[6/50][252/348] loss = 0.025062\n",
      "[6/50][253/348] loss = 0.120249\n",
      "[6/50][254/348] loss = 0.089731\n",
      "[6/50][255/348] loss = 0.045164\n",
      "[6/50][256/348] loss = 0.064258\n",
      "[6/50][257/348] loss = 0.162256\n",
      "[6/50][258/348] loss = 0.061239\n",
      "[6/50][259/348] loss = 0.116462\n",
      "[6/50][260/348] loss = 0.050904\n",
      "[6/50][261/348] loss = 0.067773\n",
      "[6/50][262/348] loss = 0.038619\n",
      "[6/50][263/348] loss = 0.116284\n",
      "[6/50][264/348] loss = 0.047295\n",
      "[6/50][265/348] loss = 0.119826\n",
      "[6/50][266/348] loss = 0.283696\n",
      "[6/50][267/348] loss = 0.087162\n",
      "[6/50][268/348] loss = 0.161157\n",
      "[6/50][269/348] loss = 0.049828\n",
      "[6/50][270/348] loss = 0.024165\n",
      "[6/50][271/348] loss = 0.039224\n",
      "[6/50][272/348] loss = 0.050593\n",
      "[6/50][273/348] loss = 0.038739\n",
      "[6/50][274/348] loss = 0.061340\n",
      "[6/50][275/348] loss = 0.114021\n",
      "[6/50][276/348] loss = 0.094816\n",
      "[6/50][277/348] loss = 0.042253\n",
      "[6/50][278/348] loss = 0.119081\n",
      "[6/50][279/348] loss = 0.045010\n",
      "[6/50][280/348] loss = 0.155211\n",
      "[6/50][281/348] loss = 0.086900\n",
      "[6/50][282/348] loss = 0.240301\n",
      "[6/50][283/348] loss = 0.198570\n",
      "[6/50][284/348] loss = 0.255753\n",
      "[6/50][285/348] loss = 0.086783\n",
      "[6/50][286/348] loss = 0.040006\n",
      "[6/50][287/348] loss = 0.023616\n",
      "[6/50][288/348] loss = 0.094912\n",
      "[6/50][289/348] loss = 0.168658\n",
      "[6/50][290/348] loss = 0.162099\n",
      "[6/50][291/348] loss = 0.270552\n",
      "[6/50][292/348] loss = 0.211246\n",
      "[6/50][293/348] loss = 0.162976\n",
      "[6/50][294/348] loss = 0.069581\n",
      "[6/50][295/348] loss = 0.026214\n",
      "[6/50][296/348] loss = 0.093852\n",
      "[6/50][297/348] loss = 0.175467\n",
      "[6/50][298/348] loss = 0.033686\n",
      "[6/50][299/348] loss = 0.019924\n",
      "[6/50][300/348] loss = 0.079305\n",
      "[6/50][301/348] loss = 0.033565\n",
      "[6/50][302/348] loss = 0.132600\n",
      "[6/50][303/348] loss = 0.248508\n",
      "[6/50][304/348] loss = 0.087389\n",
      "[6/50][305/348] loss = 0.199853\n",
      "[6/50][306/348] loss = 0.236207\n",
      "[6/50][307/348] loss = 0.036492\n",
      "[6/50][308/348] loss = 0.049191\n",
      "[6/50][309/348] loss = 0.068794\n",
      "[6/50][310/348] loss = 0.217311\n",
      "[6/50][311/348] loss = 0.053353\n",
      "[6/50][312/348] loss = 0.357416\n",
      "[6/50][313/348] loss = 0.116374\n",
      "[6/50][314/348] loss = 0.044869\n",
      "[6/50][315/348] loss = 0.118348\n",
      "[6/50][316/348] loss = 0.188351\n",
      "[6/50][317/348] loss = 0.170426\n",
      "[6/50][318/348] loss = 0.051579\n",
      "[6/50][319/348] loss = 0.030232\n",
      "[6/50][320/348] loss = 0.098590\n",
      "[6/50][321/348] loss = 0.232551\n",
      "[6/50][322/348] loss = 0.049467\n",
      "[6/50][323/348] loss = 0.032481\n",
      "[6/50][324/348] loss = 0.016353\n",
      "[6/50][325/348] loss = 0.065990\n",
      "[6/50][326/348] loss = 0.032186\n",
      "[6/50][327/348] loss = 0.031536\n",
      "[6/50][328/348] loss = 0.033804\n",
      "[6/50][329/348] loss = 0.124828\n",
      "[6/50][330/348] loss = 0.046329\n",
      "[6/50][331/348] loss = 0.372658\n",
      "[6/50][332/348] loss = 0.370967\n",
      "[6/50][333/348] loss = 0.085632\n",
      "[6/50][334/348] loss = 0.221490\n",
      "[6/50][335/348] loss = 0.102259\n",
      "[6/50][336/348] loss = 0.141659\n",
      "[6/50][337/348] loss = 0.044069\n",
      "[6/50][338/348] loss = 0.122127\n",
      "[6/50][339/348] loss = 0.147160\n",
      "[6/50][340/348] loss = 0.017447\n",
      "[6/50][341/348] loss = 0.125568\n",
      "[6/50][342/348] loss = 0.053132\n",
      "[6/50][343/348] loss = 0.032389\n",
      "[6/50][344/348] loss = 0.084098\n",
      "[6/50][345/348] loss = 0.053876\n",
      "[6/50][346/348] loss = 0.087063\n",
      "[6/50][347/348] loss = 0.414200\n",
      "[6/50]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.02 %\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 86.70 %\n",
      "\n",
      "\n",
      "[7/50][0/348] loss = 0.094303\n",
      "[7/50][1/348] loss = 0.224053\n",
      "[7/50][2/348] loss = 0.293121\n",
      "[7/50][3/348] loss = 0.019318\n",
      "[7/50][4/348] loss = 0.045065\n",
      "[7/50][5/348] loss = 0.083017\n",
      "[7/50][6/348] loss = 0.125630\n",
      "[7/50][7/348] loss = 0.381341\n",
      "[7/50][8/348] loss = 0.034510\n",
      "[7/50][9/348] loss = 0.132983\n",
      "[7/50][10/348] loss = 0.071843\n",
      "[7/50][11/348] loss = 0.343632\n",
      "[7/50][12/348] loss = 0.027598\n",
      "[7/50][13/348] loss = 0.098309\n",
      "[7/50][14/348] loss = 0.028135\n",
      "[7/50][15/348] loss = 0.072748\n",
      "[7/50][16/348] loss = 0.134657\n",
      "[7/50][17/348] loss = 0.066507\n",
      "[7/50][18/348] loss = 0.059681\n",
      "[7/50][19/348] loss = 0.164479\n",
      "[7/50][20/348] loss = 0.083004\n",
      "[7/50][21/348] loss = 0.152779\n",
      "[7/50][22/348] loss = 0.056805\n",
      "[7/50][23/348] loss = 0.079144\n",
      "[7/50][24/348] loss = 0.112877\n",
      "[7/50][25/348] loss = 0.058140\n",
      "[7/50][26/348] loss = 0.035466\n",
      "[7/50][27/348] loss = 0.063516\n",
      "[7/50][28/348] loss = 0.041592\n",
      "[7/50][29/348] loss = 0.146288\n",
      "[7/50][30/348] loss = 0.030362\n",
      "[7/50][31/348] loss = 0.197110\n",
      "[7/50][32/348] loss = 0.164611\n",
      "[7/50][33/348] loss = 0.108001\n",
      "[7/50][34/348] loss = 0.032339\n",
      "[7/50][35/348] loss = 0.047107\n",
      "[7/50][36/348] loss = 0.096714\n",
      "[7/50][37/348] loss = 0.034619\n",
      "[7/50][38/348] loss = 0.094604\n",
      "[7/50][39/348] loss = 0.026058\n",
      "[7/50][40/348] loss = 0.181814\n",
      "[7/50][41/348] loss = 0.060026\n",
      "[7/50][42/348] loss = 0.197452\n",
      "[7/50][43/348] loss = 0.027717\n",
      "[7/50][44/348] loss = 0.034329\n",
      "[7/50][45/348] loss = 0.021645\n",
      "[7/50][46/348] loss = 0.139275\n",
      "[7/50][47/348] loss = 0.012502\n",
      "[7/50][48/348] loss = 0.218083\n",
      "[7/50][49/348] loss = 0.036161\n",
      "[7/50][50/348] loss = 0.091974\n",
      "[7/50][51/348] loss = 0.091146\n",
      "[7/50][52/348] loss = 0.080654\n",
      "[7/50][53/348] loss = 0.213511\n",
      "[7/50][54/348] loss = 0.015694\n",
      "[7/50][55/348] loss = 0.033107\n",
      "[7/50][56/348] loss = 0.010032\n",
      "[7/50][57/348] loss = 0.187972\n",
      "[7/50][58/348] loss = 0.083939\n",
      "[7/50][59/348] loss = 0.271688\n",
      "[7/50][60/348] loss = 0.061187\n",
      "[7/50][61/348] loss = 0.018887\n",
      "[7/50][62/348] loss = 0.086424\n",
      "[7/50][63/348] loss = 0.088361\n",
      "[7/50][64/348] loss = 0.110476\n",
      "[7/50][65/348] loss = 0.029009\n",
      "[7/50][66/348] loss = 0.092880\n",
      "[7/50][67/348] loss = 0.108223\n",
      "[7/50][68/348] loss = 0.051022\n",
      "[7/50][69/348] loss = 0.011511\n",
      "[7/50][70/348] loss = 0.153434\n",
      "[7/50][71/348] loss = 0.031383\n",
      "[7/50][72/348] loss = 0.107151\n",
      "[7/50][73/348] loss = 0.149674\n",
      "[7/50][74/348] loss = 0.066095\n",
      "[7/50][75/348] loss = 0.015654\n",
      "[7/50][76/348] loss = 0.024844\n",
      "[7/50][77/348] loss = 0.187920\n",
      "[7/50][78/348] loss = 0.028592\n",
      "[7/50][79/348] loss = 0.043024\n",
      "[7/50][80/348] loss = 0.060428\n",
      "[7/50][81/348] loss = 0.200846\n",
      "[7/50][82/348] loss = 0.042323\n",
      "[7/50][83/348] loss = 0.203795\n",
      "[7/50][84/348] loss = 0.045412\n",
      "[7/50][85/348] loss = 0.072018\n",
      "[7/50][86/348] loss = 0.005304\n",
      "[7/50][87/348] loss = 0.116798\n",
      "[7/50][88/348] loss = 0.039715\n",
      "[7/50][89/348] loss = 0.115032\n",
      "[7/50][90/348] loss = 0.091109\n",
      "[7/50][91/348] loss = 0.061255\n",
      "[7/50][92/348] loss = 0.020168\n",
      "[7/50][93/348] loss = 0.026320\n",
      "[7/50][94/348] loss = 0.036440\n",
      "[7/50][95/348] loss = 0.053971\n",
      "[7/50][96/348] loss = 0.051729\n",
      "[7/50][97/348] loss = 0.047798\n",
      "[7/50][98/348] loss = 0.015382\n",
      "[7/50][99/348] loss = 0.047955\n",
      "[7/50][100/348] loss = 0.059020\n",
      "[7/50][101/348] loss = 0.042578\n",
      "[7/50][102/348] loss = 0.036276\n",
      "[7/50][103/348] loss = 0.082316\n",
      "[7/50][104/348] loss = 0.043346\n",
      "[7/50][105/348] loss = 0.011645\n",
      "[7/50][106/348] loss = 0.022015\n",
      "[7/50][107/348] loss = 0.017200\n",
      "[7/50][108/348] loss = 0.009069\n",
      "[7/50][109/348] loss = 0.008510\n",
      "[7/50][110/348] loss = 0.119009\n",
      "[7/50][111/348] loss = 0.048605\n",
      "[7/50][112/348] loss = 0.040943\n",
      "[7/50][113/348] loss = 0.008856\n",
      "[7/50][114/348] loss = 0.028374\n",
      "[7/50][115/348] loss = 0.007658\n",
      "[7/50][116/348] loss = 0.075322\n",
      "[7/50][117/348] loss = 0.013923\n",
      "[7/50][118/348] loss = 0.058180\n",
      "[7/50][119/348] loss = 0.075792\n",
      "[7/50][120/348] loss = 0.027572\n",
      "[7/50][121/348] loss = 0.161776\n",
      "[7/50][122/348] loss = 0.078711\n",
      "[7/50][123/348] loss = 0.063315\n",
      "[7/50][124/348] loss = 0.044066\n",
      "[7/50][125/348] loss = 0.101570\n",
      "[7/50][126/348] loss = 0.002978\n",
      "[7/50][127/348] loss = 0.007837\n",
      "[7/50][128/348] loss = 0.040835\n",
      "[7/50][129/348] loss = 0.065623\n",
      "[7/50][130/348] loss = 0.042313\n",
      "[7/50][131/348] loss = 0.092713\n",
      "[7/50][132/348] loss = 0.021925\n",
      "[7/50][133/348] loss = 0.059846\n",
      "[7/50][134/348] loss = 0.082401\n",
      "[7/50][135/348] loss = 0.013732\n",
      "[7/50][136/348] loss = 0.014646\n",
      "[7/50][137/348] loss = 0.023897\n",
      "[7/50][138/348] loss = 0.073201\n",
      "[7/50][139/348] loss = 0.024944\n",
      "[7/50][140/348] loss = 0.047395\n",
      "[7/50][141/348] loss = 0.032791\n",
      "[7/50][142/348] loss = 0.007767\n",
      "[7/50][143/348] loss = 0.029913\n",
      "[7/50][144/348] loss = 0.036487\n",
      "[7/50][145/348] loss = 0.028536\n",
      "[7/50][146/348] loss = 0.008214\n",
      "[7/50][147/348] loss = 0.105778\n",
      "[7/50][148/348] loss = 0.014584\n",
      "[7/50][149/348] loss = 0.017190\n",
      "[7/50][150/348] loss = 0.027121\n",
      "[7/50][151/348] loss = 0.031555\n",
      "[7/50][152/348] loss = 0.015568\n",
      "[7/50][153/348] loss = 0.015201\n",
      "[7/50][154/348] loss = 0.015745\n",
      "[7/50][155/348] loss = 0.018587\n",
      "[7/50][156/348] loss = 0.075215\n",
      "[7/50][157/348] loss = 0.014532\n",
      "[7/50][158/348] loss = 0.044478\n",
      "[7/50][159/348] loss = 0.038157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/50][160/348] loss = 0.050072\n",
      "[7/50][161/348] loss = 0.176260\n",
      "[7/50][162/348] loss = 0.034505\n",
      "[7/50][163/348] loss = 0.121470\n",
      "[7/50][164/348] loss = 0.021818\n",
      "[7/50][165/348] loss = 0.028297\n",
      "[7/50][166/348] loss = 0.032431\n",
      "[7/50][167/348] loss = 0.054663\n",
      "[7/50][168/348] loss = 0.016441\n",
      "[7/50][169/348] loss = 0.019711\n",
      "[7/50][170/348] loss = 0.017531\n",
      "[7/50][171/348] loss = 0.006695\n",
      "[7/50][172/348] loss = 0.003802\n",
      "[7/50][173/348] loss = 0.088119\n",
      "[7/50][174/348] loss = 0.050218\n",
      "[7/50][175/348] loss = 0.072933\n",
      "[7/50][176/348] loss = 0.048718\n"
     ]
    }
   ],
   "source": [
    "train(classifier, train_loader, test_loader, optimizer, criterion, 50, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Set-up\n",
    "- Audio fetures MFCC\n",
    "- 5 eposh training\n",
    "- 3 second recordings\n",
    "- Adam optimizer\n",
    "- lr = 0.001\n",
    "### Performance\n",
    "- 95.71 accuracu traiing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': 5,\n",
    "            'arch': 'CNN_voice_classifier',\n",
    "            'state_dict': classifier.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, False, filename = 'model_weights/CNN_voice_classifier_5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
