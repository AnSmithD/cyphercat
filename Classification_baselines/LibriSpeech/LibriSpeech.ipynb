{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libri speech Classification baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 (default, Jun 21 2018, 23:07:39) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# General\n",
    "import sys \n",
    "import os\n",
    "from os import path, makedirs\n",
    "import shutil\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "sys.path.insert(0, '../../Utils')\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# For LibriSpeech download\n",
    "import codecs\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import requests\n",
    "import subprocess\n",
    "import tarfile\n",
    "import unicodedata\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# For PyBrain approach\n",
    "import soundfile as sf            # To read .flac files.   \n",
    "import speech_recognition as sr   # pip install SpeechRecognition.\n",
    "from pybrain.datasets                import ClassificationDataSet\n",
    "from pybrain.supervised.trainers     import BackpropTrainer\n",
    "from pybrain.tools.customxml.networkreader import NetworkReader\n",
    "from pybrain.tools.customxml.networkwriter import NetworkWriter\n",
    "\n",
    "#visualization imports:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Python: %s\" % sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frames and frequencies\n",
    "durationCheck = 10.      # Only consider files with 10 or more seconds of audio.\n",
    "deltaT        = 0.2      # Audio frame size is 0.2 seconds.\n",
    "noisy         = 0.1      # This sets the limit for static, i.e. pauses in speech.\n",
    "lim1 = 10; lim2 = 410    # Lower and upper frequencies. \n",
    "                         # For the above parameters and 16 kHz sampling, this range is about 50 - 2000 Hz. \n",
    "# Path names   \n",
    "audioType  = \".flac\"               # Flac files. \n",
    "datapath   = \"data/LibriSpeech/\"        # Path where audio files are located.\n",
    "trainSet   = \"train-speakerID/\"        # Training set.\n",
    "cvSet      = \"cv-speakerID/\"           # Cross-Validation set.\n",
    "tstSet     = \"test-speakerID/\"         # Test set. \n",
    "stem       = \"nn\"                  # Output network filename stem.    \n",
    "\n",
    "numSpeakers = 10 #make this an even #\n",
    "\n",
    "if numSpeakers == 10:\n",
    "    # These are the speakers.\n",
    "    # Female: 19, 32, 39, 40, 83\n",
    "    # Male: 26, 27, 78, 405, 196\n",
    "    speakers = [\"19/\",\n",
    "                \"26/\",\n",
    "                \"32/\",\n",
    "                \"27/\",\n",
    "                \"39/\",\n",
    "                \"78/\",\n",
    "                \"40/\",\n",
    "                \"405/\", \n",
    "                \"83/\",\n",
    "                \"196/\"]\n",
    "\n",
    "maxminFile = \"min_max_values\" + str(numSpeakers) + \".dat\"  # File to store max and min values for each frequency bin.\n",
    "outfolder  = \"networks\" + str(numSpeakers) + \"/\"           # Folder to store trained networks.\n",
    "\n",
    "if not os.path.isdir(outfolder):\n",
    "    os.mkdir(outfolder)\n",
    "\n",
    "numFeatures = lim2-lim1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleOutputs   = 1       # Only 1 kind of output, i.e. each sample is one speaker.\n",
    "numHiddenNodes    = 10      # Nodes per hidden layer.\n",
    "numHiddenLayers   = 5       # 5 layers.\n",
    "numTrainingEpochs = 0      # Train 'n' epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True            # Set up a network.\n",
    "first = False            # We already have a network.\n",
    "nnFile = \"nn79.xml\"      # Most recent. Starting file name to read from.\n",
    "st = 80                  # Starting file to write to.\n",
    "\n",
    "#CV settings\n",
    "lastN = 79 #the last network there is an XML file for in the networks directory\n",
    "firstN = 60 #first network to start with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LibriSpeech data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Librivox data set (55GB) into data/ if not already present...\n",
      "Found archive \"data/train-clean-100.tar.gz\" - not downloading.\n",
      "Found archive \"data/train-clean-360.tar.gz\" - not downloading.\n",
      "Found archive \"data/dev-clean.tar.gz\" - not downloading.\n",
      "Found archive \"data/dev-other.tar.gz\" - not downloading.\n",
      "Found archive \"data/test-clean.tar.gz\" - not downloading.\n",
      "Found archive \"data/test-other.tar.gz\" - not downloading.\n",
      "Extracting librivox data if not already extracted...\n"
     ]
    }
   ],
   "source": [
    "#all the code for data loading that isn't needed for visualization:\n",
    "from LS_UTILS import Data_load\n",
    "Data_load._download_and_preprocess_data('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load speaker metadata and select speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1. load data from text to pandaframe\n",
    "\n",
    "# Note: before running this, change \n",
    "# 60   | M | train-clean-100  | 20.18 | |CBW| Simon\n",
    "# to\n",
    "# 60   | M | train-clean-100  | 20.18 | CBW Simon\n",
    "df = pd.read_table('data/LibriSpeech/SPEAKERS.TXT',header = 11,sep = '|')\n",
    "df.columns = ['id','sex','subset','minutes','name']\n",
    "train25 = df[df['subset']== ' train-clean-100  ']\n",
    "train25.plot.scatter('id','minutes')\n",
    "plt.title('Distribution of speaking times',size = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# potential speakers: 187\n"
     ]
    }
   ],
   "source": [
    "# 2. Pick a gender balanced group of speakers w/long speaking times, and print their names\n",
    "\n",
    "train25 = train25[train25['minutes'] >= 25]\n",
    "print('# potential speakers:',len(train25))\n",
    "\n",
    "df_speaker = train25[train25['sex']==' M '][0:numSpeakers//2]\n",
    "df_speaker = df_speaker.append(train25[train25['sex']==' F '][0:numSpeakers//2]).sort_index()\n",
    "\n",
    "speakers = df_speaker['id'].values\n",
    "speakers = [str(i)+'/' for i in speakers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data from individual speakers into train, test & cross-validation folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the code for data splitting that isn't needed for visualization:\n",
    "from LS_UTILS import Move_data\n",
    "Move_data.main(speakers,datapath,trainSet,cvSet,tstSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyBrain Neural Net approach\n",
    "\n",
    "  below ~15 cells adapted from https://github.com/aravindnatarajan/SpeakerRecognition\n",
    "\n",
    "  Speaker Identification. Data comes from http://www.openslr.org/12/\n",
    "  \n",
    "  Task: Given 't' seconds of speech, identify the speaker.\n",
    "  \n",
    "  10-class classification: 5 male and 5 female speakers.\n",
    "  \n",
    "  Training on about 10 minutes of speech per speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the code for networks that isn't needed for visualization:\n",
    "from LS_UTILS import Network_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for speaker: 19/\n",
      "Getting data for speaker: 26/\n",
      "Getting data for speaker: 39/\n",
      "Getting data for speaker: 40/\n"
     ]
    }
   ],
   "source": [
    "# Get data,\n",
    "# as well as locations where speaker 'i' ends, and speaker 'j' begins.\n",
    "trnX,trnY,trnIdx = Network_funcs.getDataSpeakers(trainSet,speakers,datapath,audioType,durationCheck,deltaT,lim1,\n",
    "                                                 lim2,numFeatures,noisy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Xdim,ydim',np.shape(trnX), np.shape(trnY)    )\n",
    "trnRows = np.shape(trnX)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots.\n",
    "# Frequency index from 0...400 represent a range from 50 - 2000 Hz.\n",
    "# Time index from 0 to 150 represent a range from 0 - 30 seconds.\n",
    "plt.title(\"Speaker #1 (ID# 19/, Female), 30 seconds\")\n",
    "plt.xlabel(\"Time Index\")\n",
    "plt.ylabel(\"Frequency Index\")\n",
    "plt.imshow(trnX[trnIdx[0]:trnIdx[0]+150,:].T,origin=\"lower\",aspect=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Speaker #2 (ID# 26/, Male), 30 seconds\")\n",
    "plt.xlabel(\"Time Index\")\n",
    "plt.ylabel(\"Frequency Index\")\n",
    "plt.imshow(trnX[trnIdx[1]:trnIdx[1]+150,:].T,origin=\"lower\",aspect=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find min and max values for each frequency bin using Training data only.\n",
    "# Normalize data to lie in the range (0,1).\n",
    "minArray = []; maxArray = []\n",
    "for i in range(0,numFeatures):\n",
    "  minArray.append(np.min(trnX[:,i]))\n",
    "  maxArray.append(np.max(trnX[:,i]))    \n",
    "\n",
    "f = open(maxminFile, \"w\")\n",
    "for i in range(0,numFeatures):\n",
    "  f.write(str(maxArray[i]) + \" \" + str(minArray[i]) + \"\\n\")\n",
    "f.close()      \n",
    "\n",
    "for i in range(0,trnRows):\n",
    "  for j in range(0,numFeatures):\n",
    "    trnX[i,j] = (trnX[i,j]-minArray[j])/(maxArray[j]-minArray[j])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now, we train the neural network.\n",
    "trndata = ClassificationDataSet(numFeatures, possibleOutputs, nb_classes=numSpeakers)\n",
    "for row in range(0,trnRows):\n",
    "  tempListOut = []; tempListIn = []\n",
    "  tempListOut.append(int(trnY[row]))\n",
    "  for i in range(0,numFeatures): \n",
    "    tempListIn.append(trnX[row,i])\n",
    "    \n",
    "  trndata.addSample(tempListIn,tempListOut)\n",
    "trndata._convertToOneOfMany()\n",
    "\n",
    "if first:    # For the first time, we need to create the neural network.\n",
    "  nn = Network_funcs.setupNetwork(numHiddenNodes,numHiddenLayers,numFeatures,numSpeakers)\n",
    "\n",
    "else:        # We already have a network.\n",
    "  nn = NetworkReader.readFrom(outfolder+nnFile)\n",
    "    \n",
    "trainer = BackpropTrainer(nn, dataset=trndata, momentum=0., verbose=True, weightdecay=0.)  \n",
    "for i in range(numTrainingEpochs): \n",
    "  trainer.trainOnDataset(dataset=trndata)    \n",
    "  if (i+1)%5 == 0:\n",
    "    NetworkWriter.writeToFile(nn, outfolder+stem+str(st)+\".xml\")  # Save the network, to save time.\n",
    "    st += 1\n",
    "    print (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for cross-validation and testing.\n",
    "# We use the cross validation data set to determine the network architecture,\n",
    "# i.e. depth and width of the network, type of activation function, etc.\n",
    "#\n",
    "cvX,cvY,cvIdx = Network_funcs.getDataSpeakers(cvSet,speakers,datapath,audioType,durationCheck,deltaT,lim1,\n",
    "                                                 lim2,numFeatures,noisy)  \n",
    "tstX,tstY,tstIdx = Network_funcs.getDataSpeakers(tstSet,speakers,datapath,audioType,durationCheck,deltaT,lim1,\n",
    "                                                 lim2,numFeatures,noisy)  \n",
    "cvRows = np.shape(cvX)[0]; tstRows = np.shape(tstX)[0]\n",
    "\n",
    "f = open(maxminFile)    # Read the max and min values obtained from the training set.\n",
    "maxi = []; mini = []\n",
    "for lp in range(0,numFeatures):\n",
    "  line = f.readline().split()\n",
    "  maxi.append(float(line[0]))\n",
    "  mini.append(float(line[1]))\n",
    "f.close()\n",
    "\n",
    "# Normalize to put data in the range (0,1).\n",
    "for i in range(0,cvRows):\n",
    "  for j in range(0,numFeatures):\n",
    "    cvX[i,j] = (cvX[i,j]-mini[j])/(maxi[j]-mini[j])  \n",
    "\n",
    "for i in range(0,tstRows):\n",
    "  for j in range(0,numFeatures):\n",
    "    tstX[i,j] = (tstX[i,j]-mini[j])/(maxi[j]-mini[j])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance on the CV set, as a function of training epoch.\n",
    "# We stop when we see signs of overfitting.\n",
    "# Performance on the CV set is also used to determine the neural network architecture.\n",
    "#\n",
    "\n",
    "print(\"CV Set - Performance on 0.2 seconds of data.\")\n",
    "X = []; Y = []\n",
    "for q in range(firstN,lastN+1):\n",
    "  net = outfolder+stem+str(q)+\".xml\"\n",
    "  nn = [NetworkReader.readFrom(net)]\n",
    "  st = 1\n",
    "  A,c = Network_funcs.tstClassifier(nn,cvX,cvY,cvIdx,st,numSpeakers,numFeatures)\n",
    "#   if q%5 == 0:\n",
    "  print(net,st*deltaT,np.mean(A))\n",
    "  X.append((q+1)*5)\n",
    "  Y.append(np.mean(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training accuracy (after CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Set - Performance on 0.2 seconds of data.\")\n",
    "X = []; Y = []\n",
    "for q in range(firstN,lastN+1):\n",
    "  net = outfolder+stem+str(q)+\".xml\"\n",
    "  nn = [NetworkReader.readFrom(net)]\n",
    "  st = 1\n",
    "  A,c = Network_funcs.tstClassifier(nn,trnX,trnY,trnIdx,st,numSpeakers,numFeatures)\n",
    "#   if q%5 == 0:\n",
    "  print(net,st*deltaT,np.mean(A))\n",
    "  X.append((q+1)*5)\n",
    "  Y.append(np.mean(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The network is trained using performance on the CV set.\n",
    "#  Therefore, we cannot report perfomance on the CV set anymore.\n",
    "#  So, we use the other hold-out data set, i.e. the Test set.\n",
    "#\n",
    "print(\"Test Set - Performance on 0.2 seconds of data.\")\n",
    "X = []; Y = []\n",
    "for q in range(firstN),lastN):\n",
    "  net = outfolder+stem+str(q)+\".xml\"\n",
    "  nn = [NetworkReader.readFrom(net)]\n",
    "  st = 1\n",
    "  A,c = tstClassifier(nn,tstX,tstY,tstIdx,st)\n",
    "#   if q%5 == 0:\n",
    "  print(net,st*deltaT,np.mean(A))\n",
    "  X.append((q+1)*5)\n",
    "  Y.append(np.mean(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training epoch index\")\n",
    "plt.ylabel(\"Accuracy averaged over 10 speakers\")\n",
    "plt.title(\"Performance on the test set with 0.2 seconds of speech\")\n",
    "plt.plot(X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Accuracy for t = 0.2,0.4,0.6,0.8,1.0,... 3 seconds.\n",
    "#\n",
    "print(\"Test Set: Accuracy (averaged over speakers) for t = 0.2,0.4,0.6,... seconds\")\n",
    "# Use 5 classifiers - the accuracy improves a little with an ensemble of networks.\n",
    "# For better results, use networks that were initialized with different random seeds.\n",
    "nets = [\"nn19.xml\", \"nn39.xml\", \"nn47.xml\", \"nn23.xml\", \"nn18.xml\"]\n",
    "nets = [\"nn5.xml\", \"nn10.xml\", \"nn15.xml\", \"nn20.xml\", \"nn29.xml\"]\n",
    "nets = [\"nn5.xml\", \"nn9.xml\", \"nn14.xml\", \"nn19.xml\",\"nn24.xml\"]\n",
    "nns = [NetworkReader.readFrom(outfolder+net) for net in nets]\n",
    "X = []; Y = []\n",
    "maxT = 3.   # 3 seconds.\n",
    "for st in range(1,int(maxT/deltaT)+1):\n",
    "  A,c = tstClassifier(nns,tstX,tstY,tstIdx,st)\n",
    "  print(st*deltaT,np.mean(A))\n",
    "  X.append(st*deltaT)\n",
    "  Y.append(np.mean(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X,Y)\n",
    "plt.xlabel(\"Number of seconds of speech\")\n",
    "plt.ylabel(\"Accuracy averaged over 10 speakers\")\n",
    "plt.title(\"Classifier performance on the test set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier notes:\n",
    "10: each 20 files were started from a new seed\n",
    "100: 0-4 is one set; 5-24 another; 25-34; 35-44; 45-54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LibriSpeech Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table with \n",
    "columns = ['Training epochs', '# speakers', 'audio duration', 'Train accuracy', 'Test accuracy']\n",
    "\n",
    "# do this for 10 & 100 speakers\n",
    "# .2 S & 3 S\n",
    "#sufficient training and over-training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the confusion matrix of True/False positives.\n",
    "# First row is speaker 1. The columns are predictions for speaker 1,2,3,...\n",
    "#\n",
    "nns  = [NetworkReader.readFrom(outfolder+net) for net in nets]\n",
    "A,c = tstClassifier(nns,tstX,tstY,tstIdx,1)\n",
    "print(\"Confusion matrix: T = 0.2 s\")\n",
    "print(\"Predicted speaker -->\")\n",
    "print(\"F\\tM\\tF\\tM\\tF\\tM\\tF\\tM\\tF\\tM\\n\")\n",
    "\n",
    "A,c = tstClassifier(nns,tstX,tstY,tstIdx,5)\n",
    "print(c)\n",
    "\n",
    "A,c = tstClassifier(nns,tstX,tstY,tstIdx,10)\n",
    "print(\"F\\tM\\tF\\tM\\tF\\tM\\tF\\tM\\tF\\tM\\n\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [datapath+tstSet+\"19/227/19-227-0016.flac\",\n",
    "           datapath+tstSet+\"26/496/26-496-0021.flac\",\n",
    "           datapath+tstSet+\"405/130895/405-130895-0031.flac\"]\n",
    "\n",
    "expected = [\n",
    "\"\",\n",
    "  \n",
    "\"\",\n",
    "  \n",
    "\"\"\n",
    "]\n",
    "\n",
    "r = sr.Recognizer()\n",
    "i = 0\n",
    "for sample in samples:\n",
    "  with sr.AudioFile(sample) as source:\n",
    "    audio = r.record(source)      \n",
    "    s = r.recognize_google(audio)\n",
    "    print(\"Reading file: \" + sample)\n",
    "    print(\"Expected:\")\n",
    "    print(expected[i])\n",
    "    print(\"\\n\"[:-1])\n",
    "    print(\"Obtained (Google translator):\")\n",
    "    print(s)\n",
    "    print(\"\\n\"[:-1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Approach: Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this to ~/.bashrc for the package to run:\n",
    "#export PYTHONPATH=$PYTHONPATH:/home/nlopatina/nlopatina/voicemap\n",
    "# adapted from https://github.com/oscarknagg/voicemap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from keras.layers import Input, Subtract, Dense, Lambda\n",
    "# from keras.models import Model\n",
    "# import keras.backend as K\n",
    "\n",
    "# def build_siamese_network(encoder, input_shape):\n",
    "#     input_1 = Input(input_shape)\n",
    "#     input_2 = Input(input_shape)\n",
    "    \n",
    "#     # `encoder` is any predefined network that maps a single sample \n",
    "#     # into an embedding space.\n",
    "#     # `encoder` should take an input with shape (None,) + input_shape\n",
    "#     # and produce an output with shape (None, embedding_dim). \n",
    "#     # None indicates the batch dimension.\n",
    "#     encoded_1 = encoder(input_1)\n",
    "#     encoded_2 = encoder(input_2)\n",
    "    \n",
    "#     # Here I calculate the eucliden distance between the two encoded\n",
    "#     # samples though other distances can be used\n",
    "#     embedded_distance = Subtract()([encoded_1, encoded_2])\n",
    "#     embedded_distance = Lambda(\n",
    "#         lambda x: K.sqrt(K.mean(K.square(x), axis=-1,keepdims=True))\n",
    "#     )(embedded_distance)\n",
    "    \n",
    "#     # Add a dense+sigmoid layer here in order to use per-pair, binary \n",
    "#     # similar/dissimilar labels\n",
    "#     output = Dense(1, activation='sigmoid')(embedded_distance)\n",
    "    \n",
    "#     siamese = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    \n",
    "#     return siamese\n",
    "\n",
    "# # adapted from https://medium.com/analytics-vidhya/building-a-speaker-identification-system-from-scratch-with-deep-learning-f4c4aa558a56"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
